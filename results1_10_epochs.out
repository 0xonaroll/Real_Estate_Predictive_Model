Loading Data ...
Initializing Model ...
Configuring Model ...
Training Model ...
Epoch [1/10], Step [1/303], Loss: 3.3319, Training-time: 3.42
Epoch [1/10], Step [2/303], Loss: 3.7376, Training-time: 6.50
Epoch [1/10], Step [3/303], Loss: 3.3438, Training-time: 9.56
Epoch [1/10], Step [4/303], Loss: 3.0609, Training-time: 12.62
Epoch [1/10], Step [5/303], Loss: 2.8260, Training-time: 15.67
Epoch [1/10], Step [6/303], Loss: 2.7244, Training-time: 18.74
Epoch [1/10], Step [7/303], Loss: 3.7666, Training-time: 21.79
Epoch [1/10], Step [8/303], Loss: 4.3279, Training-time: 24.85
Epoch [1/10], Step [9/303], Loss: 6.4524, Training-time: 27.89
Epoch [1/10], Step [10/303], Loss: 5.8953, Training-time: 30.94
Epoch [1/10], Step [11/303], Loss: 5.8060, Training-time: 33.98
Epoch [1/10], Step [12/303], Loss: 5.5540, Training-time: 37.04
Epoch [1/10], Step [13/303], Loss: 5.2041, Training-time: 40.09
Epoch [1/10], Step [14/303], Loss: 14.6859, Training-time: 43.14
Epoch [1/10], Step [15/303], Loss: 13.8473, Training-time: 46.20
Epoch [1/10], Step [16/303], Loss: 13.2233, Training-time: 49.24
Epoch [1/10], Step [17/303], Loss: 12.9190, Training-time: 52.29
Epoch [1/10], Step [18/303], Loss: 12.3336, Training-time: 55.35
Epoch [1/10], Step [19/303], Loss: 11.8106, Training-time: 58.40
Epoch [1/10], Step [20/303], Loss: 11.7071, Training-time: 61.45
Epoch [1/10], Step [21/303], Loss: 11.2781, Training-time: 64.49
Epoch [1/10], Step [22/303], Loss: 10.9453, Training-time: 67.55
Epoch [1/10], Step [23/303], Loss: 10.5506, Training-time: 70.60
Epoch [1/10], Step [24/303], Loss: 10.1948, Training-time: 73.66
Epoch [1/10], Step [25/303], Loss: 9.8707, Training-time: 76.71
Epoch [1/10], Step [26/303], Loss: 9.7477, Training-time: 79.77
Epoch [1/10], Step [27/303], Loss: 9.4450, Training-time: 82.82
Epoch [1/10], Step [28/303], Loss: 9.1543, Training-time: 85.88
Epoch [1/10], Step [29/303], Loss: 9.9397, Training-time: 88.95
Epoch [1/10], Step [30/303], Loss: 9.6668, Training-time: 92.01
Epoch [1/10], Step [31/303], Loss: 9.3955, Training-time: 95.06
Epoch [1/10], Step [32/303], Loss: 9.1441, Training-time: 98.13
Epoch [1/10], Step [33/303], Loss: 8.9192, Training-time: 101.19
Epoch [1/10], Step [34/303], Loss: 8.7428, Training-time: 104.23
Epoch [1/10], Step [35/303], Loss: 8.5168, Training-time: 107.29
Epoch [1/10], Step [36/303], Loss: 8.5656, Training-time: 110.34
Epoch [1/10], Step [37/303], Loss: 8.3887, Training-time: 113.40
Epoch [1/10], Step [38/303], Loss: 8.1942, Training-time: 116.45
Epoch [1/10], Step [39/303], Loss: 8.3708, Training-time: 119.51
Epoch [1/10], Step [40/303], Loss: 8.2606, Training-time: 122.57
Epoch [1/10], Step [41/303], Loss: 8.1315, Training-time: 125.63
Epoch [1/10], Step [42/303], Loss: 8.0441, Training-time: 128.69
Epoch [1/10], Step [43/303], Loss: 7.8829, Training-time: 131.74
Epoch [1/10], Step [44/303], Loss: 7.7884, Training-time: 134.78
Epoch [1/10], Step [45/303], Loss: 7.6983, Training-time: 137.84
Epoch [1/10], Step [46/303], Loss: 7.5642, Training-time: 140.90
Epoch [1/10], Step [47/303], Loss: 7.4627, Training-time: 143.96
Epoch [1/10], Step [48/303], Loss: 7.3209, Training-time: 147.02
Epoch [1/10], Step [49/303], Loss: 7.1836, Training-time: 150.09
Epoch [1/10], Step [50/303], Loss: 7.0560, Training-time: 153.15
Epoch [1/10], Step [51/303], Loss: 6.9306, Training-time: 156.20
Epoch [1/10], Step [52/303], Loss: 6.8219, Training-time: 159.24
Epoch [1/10], Step [53/303], Loss: 6.8649, Training-time: 162.29
Epoch [1/10], Step [54/303], Loss: 8.0258, Training-time: 165.34
Epoch [1/10], Step [55/303], Loss: 7.8876, Training-time: 168.40
Epoch [1/10], Step [56/303], Loss: 7.7837, Training-time: 171.45
Epoch [1/10], Step [57/303], Loss: 7.6953, Training-time: 174.51
Epoch [1/10], Step [58/303], Loss: 7.5683, Training-time: 177.55
Epoch [1/10], Step [59/303], Loss: 7.4550, Training-time: 180.59
Epoch [1/10], Step [60/303], Loss: 7.3490, Training-time: 183.64
Epoch [1/10], Step [61/303], Loss: 7.2412, Training-time: 186.69
Epoch [1/10], Step [62/303], Loss: 7.1632, Training-time: 189.75
Epoch [1/10], Step [63/303], Loss: 7.1326, Training-time: 192.80
Epoch [1/10], Step [64/303], Loss: 7.0818, Training-time: 195.85
Epoch [1/10], Step [65/303], Loss: 6.9970, Training-time: 198.90
Epoch [1/10], Step [66/303], Loss: 6.9075, Training-time: 201.94
Epoch [1/10], Step [67/303], Loss: 6.8465, Training-time: 205.00
Epoch [1/10], Step [68/303], Loss: 6.7602, Training-time: 208.05
Epoch [1/10], Step [69/303], Loss: 6.7273, Training-time: 211.10
Epoch [1/10], Step [70/303], Loss: 6.6669, Training-time: 214.16
Epoch [1/10], Step [71/303], Loss: 6.6190, Training-time: 217.22
Epoch [1/10], Step [72/303], Loss: 6.6974, Training-time: 220.28
Epoch [1/10], Step [73/303], Loss: 6.6341, Training-time: 223.32
Epoch [1/10], Step [74/303], Loss: 6.5535, Training-time: 226.38
Epoch [1/10], Step [75/303], Loss: 6.5174, Training-time: 229.42
Epoch [1/10], Step [76/303], Loss: 6.4478, Training-time: 232.47
Epoch [1/10], Step [77/303], Loss: 6.3743, Training-time: 235.52
Epoch [1/10], Step [78/303], Loss: 6.3033, Training-time: 238.57
Epoch [1/10], Step [79/303], Loss: 6.3183, Training-time: 241.62
Epoch [1/10], Step [80/303], Loss: 6.2797, Training-time: 244.67
Epoch [1/10], Step [81/303], Loss: 6.2298, Training-time: 247.73
Epoch [1/10], Step [82/303], Loss: 6.1631, Training-time: 250.78
Epoch [1/10], Step [83/303], Loss: 6.0955, Training-time: 253.85
Epoch [1/10], Step [84/303], Loss: 6.0842, Training-time: 256.91
Epoch [1/10], Step [85/303], Loss: 6.0304, Training-time: 259.96
Epoch [1/10], Step [86/303], Loss: 6.0114, Training-time: 263.01
Epoch [1/10], Step [87/303], Loss: 5.9637, Training-time: 266.07
Epoch [1/10], Step [88/303], Loss: 5.9170, Training-time: 269.13
Epoch [1/10], Step [89/303], Loss: 5.8702, Training-time: 272.18
Epoch [1/10], Step [90/303], Loss: 5.8108, Training-time: 275.24
Epoch [1/10], Step [91/303], Loss: 5.7803, Training-time: 278.30
Epoch [1/10], Step [92/303], Loss: 5.7877, Training-time: 281.36
Epoch [1/10], Step [93/303], Loss: 5.7399, Training-time: 284.42
Epoch [1/10], Step [94/303], Loss: 5.7004, Training-time: 287.49
Epoch [1/10], Step [95/303], Loss: 5.6527, Training-time: 290.53
Epoch [1/10], Step [96/303], Loss: 5.6640, Training-time: 293.59
Epoch [1/10], Step [97/303], Loss: 5.6112, Training-time: 296.65
Epoch [1/10], Step [98/303], Loss: 5.5913, Training-time: 299.72
Epoch [1/10], Step [99/303], Loss: 5.5556, Training-time: 302.78
Epoch [1/10], Step [100/303], Loss: 5.5322, Training-time: 305.84
Epoch [1/10], Step [101/303], Loss: 5.5032, Training-time: 308.89
Epoch [1/10], Step [102/303], Loss: 5.4563, Training-time: 311.96
Epoch [1/10], Step [103/303], Loss: 5.4108, Training-time: 315.01
Epoch [1/10], Step [104/303], Loss: 5.3684, Training-time: 318.06
Epoch [1/10], Step [105/303], Loss: 5.3501, Training-time: 321.13
Epoch [1/10], Step [106/303], Loss: 5.3177, Training-time: 324.19
Epoch [1/10], Step [107/303], Loss: 5.2817, Training-time: 327.24
Epoch [1/10], Step [108/303], Loss: 5.2390, Training-time: 330.29
Epoch [1/10], Step [109/303], Loss: 5.2073, Training-time: 333.35
Epoch [1/10], Step [110/303], Loss: 5.1752, Training-time: 336.41
Epoch [1/10], Step [111/303], Loss: 5.1458, Training-time: 339.45
Epoch [1/10], Step [112/303], Loss: 5.1250, Training-time: 342.50
Epoch [1/10], Step [113/303], Loss: 5.0837, Training-time: 345.55
Epoch [1/10], Step [114/303], Loss: 5.0425, Training-time: 348.61
Epoch [1/10], Step [115/303], Loss: 5.1412, Training-time: 351.66
Epoch [1/10], Step [116/303], Loss: 5.1177, Training-time: 354.73
Epoch [1/10], Step [117/303], Loss: 5.3891, Training-time: 357.78
Epoch [1/10], Step [118/303], Loss: 5.3610, Training-time: 360.83
Epoch [1/10], Step [119/303], Loss: 5.3271, Training-time: 363.88
Epoch [1/10], Step [120/303], Loss: 5.2928, Training-time: 366.93
Epoch [1/10], Step [121/303], Loss: 5.2550, Training-time: 369.98
Epoch [1/10], Step [122/303], Loss: 5.2293, Training-time: 373.04
Epoch [1/10], Step [123/303], Loss: 5.1961, Training-time: 376.10
Epoch [1/10], Step [124/303], Loss: 5.1635, Training-time: 379.16
Epoch [1/10], Step [125/303], Loss: 5.1315, Training-time: 382.21
Epoch [1/10], Step [126/303], Loss: 5.0975, Training-time: 385.25
Epoch [1/10], Step [127/303], Loss: 5.0800, Training-time: 388.30
Epoch [1/10], Step [128/303], Loss: 5.1678, Training-time: 391.34
Epoch [1/10], Step [129/303], Loss: 5.1615, Training-time: 394.40
Epoch [1/10], Step [130/303], Loss: 5.1948, Training-time: 397.45
Epoch [1/10], Step [131/303], Loss: 5.1753, Training-time: 400.50
Epoch [1/10], Step [132/303], Loss: 5.1454, Training-time: 403.56
Epoch [1/10], Step [133/303], Loss: 5.1150, Training-time: 406.61
Epoch [1/10], Step [134/303], Loss: 5.0813, Training-time: 409.66
Epoch [1/10], Step [135/303], Loss: 5.1026, Training-time: 412.73
Epoch [1/10], Step [136/303], Loss: 5.0892, Training-time: 415.79
Epoch [1/10], Step [137/303], Loss: 5.0682, Training-time: 418.85
Epoch [1/10], Step [138/303], Loss: 5.2102, Training-time: 421.92
Epoch [1/10], Step [139/303], Loss: 5.2940, Training-time: 424.98
Epoch [1/10], Step [140/303], Loss: 5.2653, Training-time: 428.04
Epoch [1/10], Step [141/303], Loss: 5.3027, Training-time: 431.10
Epoch [1/10], Step [142/303], Loss: 5.2823, Training-time: 434.16
Epoch [1/10], Step [143/303], Loss: 5.2522, Training-time: 437.22
Epoch [1/10], Step [144/303], Loss: 5.2209, Training-time: 440.28
Epoch [1/10], Step [145/303], Loss: 5.2138, Training-time: 443.34
Epoch [1/10], Step [146/303], Loss: 5.1830, Training-time: 446.39
Epoch [1/10], Step [147/303], Loss: 5.1534, Training-time: 449.45
Epoch [1/10], Step [148/303], Loss: 5.1920, Training-time: 452.50
Epoch [1/10], Step [149/303], Loss: 5.2158, Training-time: 455.57
Epoch [1/10], Step [150/303], Loss: 5.2651, Training-time: 458.60
Epoch [1/10], Step [151/303], Loss: 5.2429, Training-time: 461.66
Epoch [1/10], Step [152/303], Loss: 5.2159, Training-time: 464.71
Epoch [1/10], Step [153/303], Loss: 5.1857, Training-time: 467.76
Epoch [1/10], Step [154/303], Loss: 5.1834, Training-time: 470.80
Epoch [1/10], Step [155/303], Loss: 5.1790, Training-time: 473.86
Epoch [1/10], Step [156/303], Loss: 5.1604, Training-time: 476.91
Epoch [1/10], Step [157/303], Loss: 5.1526, Training-time: 479.97
Epoch [1/10], Step [158/303], Loss: 5.1628, Training-time: 483.00
Epoch [1/10], Step [159/303], Loss: 5.1464, Training-time: 486.06
Epoch [1/10], Step [160/303], Loss: 5.1203, Training-time: 489.12
Epoch [1/10], Step [161/303], Loss: 5.0951, Training-time: 492.16
Epoch [1/10], Step [162/303], Loss: 5.0893, Training-time: 495.21
Epoch [1/10], Step [163/303], Loss: 5.0684, Training-time: 498.27
Epoch [1/10], Step [164/303], Loss: 5.0673, Training-time: 501.32
Epoch [1/10], Step [165/303], Loss: 5.0497, Training-time: 504.37
Epoch [1/10], Step [166/303], Loss: 5.0355, Training-time: 507.43
Epoch [1/10], Step [167/303], Loss: 5.0279, Training-time: 510.49
Epoch [1/10], Step [168/303], Loss: 5.0765, Training-time: 513.55
Epoch [1/10], Step [169/303], Loss: 5.0533, Training-time: 516.60
Epoch [1/10], Step [170/303], Loss: 5.0441, Training-time: 519.65
Epoch [1/10], Step [171/303], Loss: 5.0258, Training-time: 522.70
Epoch [1/10], Step [172/303], Loss: 5.0069, Training-time: 525.76
Epoch [1/10], Step [173/303], Loss: 5.0209, Training-time: 528.81
Epoch [1/10], Step [174/303], Loss: 5.0070, Training-time: 531.87
Epoch [1/10], Step [175/303], Loss: 5.0042, Training-time: 534.92
Epoch [1/10], Step [176/303], Loss: 5.1118, Training-time: 537.97
Epoch [1/10], Step [177/303], Loss: 5.4422, Training-time: 541.03
Epoch [1/10], Step [178/303], Loss: 5.4286, Training-time: 544.08
Epoch [1/10], Step [179/303], Loss: 5.4763, Training-time: 547.14
Epoch [1/10], Step [180/303], Loss: 5.4537, Training-time: 550.19
Epoch [1/10], Step [181/303], Loss: 5.4473, Training-time: 553.25
Epoch [1/10], Step [182/303], Loss: 5.4430, Training-time: 556.31
Epoch [1/10], Step [183/303], Loss: 5.4214, Training-time: 559.37
Epoch [1/10], Step [184/303], Loss: 5.4050, Training-time: 562.43
Epoch [1/10], Step [185/303], Loss: 5.4467, Training-time: 565.49
Epoch [1/10], Step [186/303], Loss: 5.4362, Training-time: 568.56
Epoch [1/10], Step [187/303], Loss: 5.4142, Training-time: 571.62
Epoch [1/10], Step [188/303], Loss: 5.3999, Training-time: 574.67
Epoch [1/10], Step [189/303], Loss: 5.4111, Training-time: 577.73
Epoch [1/10], Step [190/303], Loss: 5.3987, Training-time: 580.78
Epoch [1/10], Step [191/303], Loss: 5.3747, Training-time: 583.83
Epoch [1/10], Step [192/303], Loss: 5.3515, Training-time: 586.87
Epoch [1/10], Step [193/303], Loss: 5.3306, Training-time: 589.93
Epoch [1/10], Step [194/303], Loss: 5.3250, Training-time: 592.98
Epoch [1/10], Step [195/303], Loss: 5.3086, Training-time: 596.04
Epoch [1/10], Step [196/303], Loss: 5.4631, Training-time: 599.09
Epoch [1/10], Step [197/303], Loss: 5.4421, Training-time: 602.14
Epoch [1/10], Step [198/303], Loss: 5.4207, Training-time: 605.20
Epoch [1/10], Step [199/303], Loss: 5.4048, Training-time: 608.26
Epoch [1/10], Step [200/303], Loss: 5.3907, Training-time: 611.31
Epoch [1/10], Step [201/303], Loss: 5.3700, Training-time: 614.37
Epoch [1/10], Step [202/303], Loss: 5.3967, Training-time: 617.42
Epoch [1/10], Step [203/303], Loss: 5.3939, Training-time: 620.48
Epoch [1/10], Step [204/303], Loss: 5.3809, Training-time: 623.54
Epoch [1/10], Step [205/303], Loss: 5.3594, Training-time: 626.59
Epoch [1/10], Step [206/303], Loss: 5.3374, Training-time: 629.65
Epoch [1/10], Step [207/303], Loss: 5.3406, Training-time: 632.71
Epoch [1/10], Step [208/303], Loss: 5.3190, Training-time: 635.78
Epoch [1/10], Step [209/303], Loss: 5.2971, Training-time: 638.83
Epoch [1/10], Step [210/303], Loss: 5.2752, Training-time: 641.88
Epoch [1/10], Step [211/303], Loss: 5.3016, Training-time: 644.94
Epoch [1/10], Step [212/303], Loss: 5.2798, Training-time: 648.01
Epoch [1/10], Step [213/303], Loss: 5.2640, Training-time: 651.06
Epoch [1/10], Step [214/303], Loss: 5.2427, Training-time: 654.10
Epoch [1/10], Step [215/303], Loss: 5.2247, Training-time: 657.16
Epoch [1/10], Step [216/303], Loss: 5.2153, Training-time: 660.21
Epoch [1/10], Step [217/303], Loss: 5.1945, Training-time: 663.26
Epoch [1/10], Step [218/303], Loss: 5.1918, Training-time: 666.32
Epoch [1/10], Step [219/303], Loss: 5.2898, Training-time: 669.38
Epoch [1/10], Step [220/303], Loss: 5.2771, Training-time: 672.43
Epoch [1/10], Step [221/303], Loss: 5.2558, Training-time: 675.48
Epoch [1/10], Step [222/303], Loss: 5.2348, Training-time: 678.54
Epoch [1/10], Step [223/303], Loss: 5.2165, Training-time: 681.60
Epoch [1/10], Step [224/303], Loss: 5.1965, Training-time: 684.65
Epoch [1/10], Step [225/303], Loss: 5.1826, Training-time: 687.71
Epoch [1/10], Step [226/303], Loss: 5.1706, Training-time: 690.76
Epoch [1/10], Step [227/303], Loss: 5.1569, Training-time: 693.81
Epoch [1/10], Step [228/303], Loss: 5.1469, Training-time: 696.87
Epoch [1/10], Step [229/303], Loss: 5.1306, Training-time: 699.93
Epoch [1/10], Step [230/303], Loss: 5.1110, Training-time: 702.98
Epoch [1/10], Step [231/303], Loss: 8.8429, Training-time: 706.04
Epoch [1/10], Step [232/303], Loss: 8.8110, Training-time: 709.10
Epoch [1/10], Step [233/303], Loss: 8.9390, Training-time: 712.17
Epoch [1/10], Step [234/303], Loss: 8.9097, Training-time: 715.22
Epoch [1/10], Step [235/303], Loss: 8.8801, Training-time: 718.27
Epoch [1/10], Step [236/303], Loss: 8.8808, Training-time: 721.33
Epoch [1/10], Step [237/303], Loss: 8.8594, Training-time: 724.39
Epoch [1/10], Step [238/303], Loss: 8.8310, Training-time: 727.46
Epoch [1/10], Step [239/303], Loss: 8.8046, Training-time: 730.52
Epoch [1/10], Step [240/303], Loss: 8.7784, Training-time: 733.58
Epoch [1/10], Step [241/303], Loss: 8.7473, Training-time: 736.64
Epoch [1/10], Step [242/303], Loss: 8.7169, Training-time: 739.71
Epoch [1/10], Step [243/303], Loss: 8.6859, Training-time: 742.77
Epoch [1/10], Step [244/303], Loss: 8.6625, Training-time: 745.81
Epoch [1/10], Step [245/303], Loss: 8.6454, Training-time: 748.87
Epoch [1/10], Step [246/303], Loss: 8.6181, Training-time: 751.94
Epoch [1/10], Step [247/303], Loss: 8.5953, Training-time: 754.99
Epoch [1/10], Step [248/303], Loss: 8.5681, Training-time: 758.03
Epoch [1/10], Step [249/303], Loss: 8.5416, Training-time: 761.09
Epoch [1/10], Step [250/303], Loss: 8.5096, Training-time: 764.14
Epoch [1/10], Step [251/303], Loss: 8.8217, Training-time: 767.20
Epoch [1/10], Step [252/303], Loss: 8.7983, Training-time: 770.26
Epoch [1/10], Step [253/303], Loss: 8.7655, Training-time: 773.32
Epoch [1/10], Step [254/303], Loss: 8.7387, Training-time: 776.38
Epoch [1/10], Step [255/303], Loss: 8.7086, Training-time: 779.45
Epoch [1/10], Step [256/303], Loss: 8.6806, Training-time: 782.50
Epoch [1/10], Step [257/303], Loss: 8.6510, Training-time: 785.56
Epoch [1/10], Step [258/303], Loss: 8.6575, Training-time: 788.63
Epoch [1/10], Step [259/303], Loss: 8.6290, Training-time: 791.68
Epoch [1/10], Step [260/303], Loss: 8.6012, Training-time: 794.73
Epoch [1/10], Step [261/303], Loss: 8.5718, Training-time: 797.77
Epoch [1/10], Step [262/303], Loss: 8.5442, Training-time: 800.83
Epoch [1/10], Step [263/303], Loss: 8.5161, Training-time: 803.89
Epoch [1/10], Step [264/303], Loss: 8.4965, Training-time: 806.95
Epoch [1/10], Step [265/303], Loss: 8.4723, Training-time: 810.00
Epoch [1/10], Step [266/303], Loss: 8.4652, Training-time: 813.06
Epoch [1/10], Step [267/303], Loss: 8.4404, Training-time: 816.11
Epoch [1/10], Step [268/303], Loss: 8.4115, Training-time: 819.16
Epoch [1/10], Step [269/303], Loss: 8.3864, Training-time: 822.22
Epoch [1/10], Step [270/303], Loss: 8.3577, Training-time: 825.29
Epoch [1/10], Step [271/303], Loss: 8.3406, Training-time: 828.34
Epoch [1/10], Step [272/303], Loss: 8.3241, Training-time: 831.40
Epoch [1/10], Step [273/303], Loss: 8.2963, Training-time: 834.45
Epoch [1/10], Step [274/303], Loss: 8.2704, Training-time: 837.51
Epoch [1/10], Step [275/303], Loss: 8.2426, Training-time: 840.57
Epoch [1/10], Step [276/303], Loss: 8.2223, Training-time: 843.63
Epoch [1/10], Step [277/303], Loss: 8.2177, Training-time: 846.68
Epoch [1/10], Step [278/303], Loss: 8.1939, Training-time: 849.75
Epoch [1/10], Step [279/303], Loss: 8.1667, Training-time: 852.81
Epoch [1/10], Step [280/303], Loss: 8.1418, Training-time: 855.87
Epoch [1/10], Step [281/303], Loss: 8.1168, Training-time: 858.92
Epoch [1/10], Step [282/303], Loss: 8.1229, Training-time: 861.99
Epoch [1/10], Step [283/303], Loss: 8.4545, Training-time: 865.05
Epoch [1/10], Step [284/303], Loss: 8.4271, Training-time: 868.10
Epoch [1/10], Step [285/303], Loss: 8.4601, Training-time: 871.16
Epoch [1/10], Step [286/303], Loss: 8.4635, Training-time: 874.23
Epoch [1/10], Step [287/303], Loss: 8.5055, Training-time: 877.28
Epoch [1/10], Step [288/303], Loss: 8.4835, Training-time: 880.32
Epoch [1/10], Step [289/303], Loss: 8.4601, Training-time: 883.38
Epoch [1/10], Step [290/303], Loss: 8.4443, Training-time: 886.43
Epoch [1/10], Step [291/303], Loss: 8.4263, Training-time: 889.49
Epoch [1/10], Step [292/303], Loss: 8.4178, Training-time: 892.55
Epoch [1/10], Step [293/303], Loss: 8.3955, Training-time: 895.62
Epoch [1/10], Step [294/303], Loss: 8.3730, Training-time: 898.67
Epoch [1/10], Step [295/303], Loss: 8.3500, Training-time: 901.74
Epoch [1/10], Step [296/303], Loss: 8.4455, Training-time: 904.80
Epoch [1/10], Step [297/303], Loss: 8.4250, Training-time: 907.85
Epoch [1/10], Step [298/303], Loss: 8.4040, Training-time: 910.88
Epoch [1/10], Step [299/303], Loss: 8.4193, Training-time: 913.90
Epoch [1/10], Step [300/303], Loss: 8.4147, Training-time: 916.93
Epoch [1/10], Step [301/303], Loss: 8.3943, Training-time: 919.94
Epoch [1/10], Step [302/303], Loss: 8.3851, Training-time: 922.98
Epoch [1/10], Step [303/303], Loss: 8.3596, Training-time: 923.58
Epoch [2/10], Step [1/303], Loss: 8.3403, Training-time: 926.95
Epoch [2/10], Step [2/303], Loss: 8.3263, Training-time: 930.01
Epoch [2/10], Step [3/303], Loss: 8.3208, Training-time: 933.07
Epoch [2/10], Step [4/303], Loss: 8.3140, Training-time: 936.12
Epoch [2/10], Step [5/303], Loss: 8.2890, Training-time: 939.17
Epoch [2/10], Step [6/303], Loss: 8.2638, Training-time: 942.22
Epoch [2/10], Step [7/303], Loss: 8.2578, Training-time: 945.27
Epoch [2/10], Step [8/303], Loss: 8.2339, Training-time: 948.33
Epoch [2/10], Step [9/303], Loss: 8.2111, Training-time: 951.37
Epoch [2/10], Step [10/303], Loss: 8.1943, Training-time: 954.43
Epoch [2/10], Step [11/303], Loss: 8.1728, Training-time: 957.48
Epoch [2/10], Step [12/303], Loss: 8.1619, Training-time: 960.54
Epoch [2/10], Step [13/303], Loss: 8.1965, Training-time: 963.59
Epoch [2/10], Step [14/303], Loss: 8.1747, Training-time: 966.64
Epoch [2/10], Step [15/303], Loss: 8.1972, Training-time: 969.68
Epoch [2/10], Step [16/303], Loss: 8.1769, Training-time: 972.73
Epoch [2/10], Step [17/303], Loss: 8.1624, Training-time: 975.77
Epoch [2/10], Step [18/303], Loss: 8.1546, Training-time: 978.80
Epoch [2/10], Step [19/303], Loss: 8.1493, Training-time: 981.85
Epoch [2/10], Step [20/303], Loss: 8.1290, Training-time: 984.89
Epoch [2/10], Step [21/303], Loss: 8.1071, Training-time: 987.93
Epoch [2/10], Step [22/303], Loss: 8.0902, Training-time: 990.99
Epoch [2/10], Step [23/303], Loss: 8.0677, Training-time: 994.04
Epoch [2/10], Step [24/303], Loss: 8.0478, Training-time: 997.09
Epoch [2/10], Step [25/303], Loss: 8.0279, Training-time: 1000.13
Epoch [2/10], Step [26/303], Loss: 8.0162, Training-time: 1003.17
Epoch [2/10], Step [27/303], Loss: 8.0028, Training-time: 1006.22
Epoch [2/10], Step [28/303], Loss: 7.9812, Training-time: 1009.28
Epoch [2/10], Step [29/303], Loss: 7.9595, Training-time: 1012.34
Epoch [2/10], Step [30/303], Loss: 8.1548, Training-time: 1015.39
Epoch [2/10], Step [31/303], Loss: 8.1393, Training-time: 1018.45
Epoch [2/10], Step [32/303], Loss: 8.1831, Training-time: 1021.50
Epoch [2/10], Step [33/303], Loss: 8.1910, Training-time: 1024.54
Epoch [2/10], Step [34/303], Loss: 8.1912, Training-time: 1027.60
Epoch [2/10], Step [35/303], Loss: 8.1741, Training-time: 1030.65
Epoch [2/10], Step [36/303], Loss: 8.1577, Training-time: 1033.70
Epoch [2/10], Step [37/303], Loss: 8.1402, Training-time: 1036.76
Epoch [2/10], Step [38/303], Loss: 8.3676, Training-time: 1039.80
Epoch [2/10], Step [39/303], Loss: 8.3703, Training-time: 1042.85
Epoch [2/10], Step [40/303], Loss: 8.3510, Training-time: 1045.91
Epoch [2/10], Step [41/303], Loss: 8.3313, Training-time: 1048.95
Epoch [2/10], Step [42/303], Loss: 8.5934, Training-time: 1052.00
Epoch [2/10], Step [43/303], Loss: 8.5725, Training-time: 1055.06
Epoch [2/10], Step [44/303], Loss: 8.6022, Training-time: 1058.10
Epoch [2/10], Step [45/303], Loss: 8.5825, Training-time: 1061.16
Epoch [2/10], Step [46/303], Loss: 8.5609, Training-time: 1064.20
Epoch [2/10], Step [47/303], Loss: 8.5407, Training-time: 1067.24
Epoch [2/10], Step [48/303], Loss: 8.5202, Training-time: 1070.29
Epoch [2/10], Step [49/303], Loss: 8.4995, Training-time: 1073.34
Epoch [2/10], Step [50/303], Loss: 8.4781, Training-time: 1076.39
Epoch [2/10], Step [51/303], Loss: 8.4569, Training-time: 1079.45
Epoch [2/10], Step [52/303], Loss: 8.4514, Training-time: 1082.50
Epoch [2/10], Step [53/303], Loss: 8.4328, Training-time: 1085.55
Epoch [2/10], Step [54/303], Loss: 8.4123, Training-time: 1088.60
Epoch [2/10], Step [55/303], Loss: 8.3907, Training-time: 1091.65
Epoch [2/10], Step [56/303], Loss: 8.3745, Training-time: 1094.69
Epoch [2/10], Step [57/303], Loss: 8.3563, Training-time: 1097.75
Epoch [2/10], Step [58/303], Loss: 8.3385, Training-time: 1100.80
Epoch [2/10], Step [59/303], Loss: 8.3278, Training-time: 1103.85
Epoch [2/10], Step [60/303], Loss: 8.3088, Training-time: 1106.89
Epoch [2/10], Step [61/303], Loss: 8.2986, Training-time: 1109.94
Epoch [2/10], Step [62/303], Loss: 8.2790, Training-time: 1112.99
Epoch [2/10], Step [63/303], Loss: 8.2592, Training-time: 1116.04
Epoch [2/10], Step [64/303], Loss: 8.2397, Training-time: 1119.09
Epoch [2/10], Step [65/303], Loss: 8.2213, Training-time: 1122.13
Epoch [2/10], Step [66/303], Loss: 8.2035, Training-time: 1125.18
Epoch [2/10], Step [67/303], Loss: 8.1895, Training-time: 1128.23
Epoch [2/10], Step [68/303], Loss: 8.1744, Training-time: 1131.28
Epoch [2/10], Step [69/303], Loss: 8.1559, Training-time: 1134.32
Epoch [2/10], Step [70/303], Loss: 8.1360, Training-time: 1137.38
Epoch [2/10], Step [71/303], Loss: 8.1221, Training-time: 1140.43
Epoch [2/10], Step [72/303], Loss: 8.1046, Training-time: 1143.48
Epoch [2/10], Step [73/303], Loss: 8.0863, Training-time: 1146.53
Epoch [2/10], Step [74/303], Loss: 8.0707, Training-time: 1149.58
Epoch [2/10], Step [75/303], Loss: 8.0523, Training-time: 1152.63
Epoch [2/10], Step [76/303], Loss: 8.0334, Training-time: 1155.68
Epoch [2/10], Step [77/303], Loss: 8.0319, Training-time: 1158.73
Epoch [2/10], Step [78/303], Loss: 8.0146, Training-time: 1161.77
Epoch [2/10], Step [79/303], Loss: 8.0252, Training-time: 1164.81
Epoch [2/10], Step [80/303], Loss: 8.0113, Training-time: 1167.86
Epoch [2/10], Step [81/303], Loss: 7.9956, Training-time: 1170.91
Epoch [2/10], Step [82/303], Loss: 7.9782, Training-time: 1173.95
Epoch [2/10], Step [83/303], Loss: 7.9587, Training-time: 1177.01
Epoch [2/10], Step [84/303], Loss: 7.9443, Training-time: 1180.06
Epoch [2/10], Step [85/303], Loss: 7.9291, Training-time: 1183.09
Epoch [2/10], Step [86/303], Loss: 7.9161, Training-time: 1186.14
Epoch [2/10], Step [87/303], Loss: 7.9084, Training-time: 1189.19
Epoch [2/10], Step [88/303], Loss: 7.8931, Training-time: 1192.23
Epoch [2/10], Step [89/303], Loss: 7.9782, Training-time: 1195.28
Epoch [2/10], Step [90/303], Loss: 7.9654, Training-time: 1198.32
Epoch [2/10], Step [91/303], Loss: 7.9467, Training-time: 1201.37
Epoch [2/10], Step [92/303], Loss: 7.9368, Training-time: 1204.43
Epoch [2/10], Step [93/303], Loss: 7.9644, Training-time: 1207.49
Epoch [2/10], Step [94/303], Loss: 7.9492, Training-time: 1210.54
Epoch [2/10], Step [95/303], Loss: 7.9557, Training-time: 1213.59
Epoch [2/10], Step [96/303], Loss: 7.9399, Training-time: 1216.63
Epoch [2/10], Step [97/303], Loss: 7.9316, Training-time: 1219.68
Epoch [2/10], Step [98/303], Loss: 7.9163, Training-time: 1222.73
Epoch [2/10], Step [99/303], Loss: 7.8996, Training-time: 1225.78
Epoch [2/10], Step [100/303], Loss: 7.8880, Training-time: 1228.82
Epoch [2/10], Step [101/303], Loss: 7.8708, Training-time: 1231.86
Epoch [2/10], Step [102/303], Loss: 7.8565, Training-time: 1234.91
Epoch [2/10], Step [103/303], Loss: 7.8427, Training-time: 1237.96
Epoch [2/10], Step [104/303], Loss: 7.9016, Training-time: 1241.02
Epoch [2/10], Step [105/303], Loss: 7.8842, Training-time: 1244.07
Epoch [2/10], Step [106/303], Loss: 7.8725, Training-time: 1247.13
Epoch [2/10], Step [107/303], Loss: 7.8598, Training-time: 1250.18
Epoch [2/10], Step [108/303], Loss: 7.8448, Training-time: 1253.23
Epoch [2/10], Step [109/303], Loss: 7.8320, Training-time: 1256.29
Epoch [2/10], Step [110/303], Loss: 7.8195, Training-time: 1259.35
Epoch [2/10], Step [111/303], Loss: 7.8350, Training-time: 1262.39
Epoch [2/10], Step [112/303], Loss: 7.8182, Training-time: 1265.45
Epoch [2/10], Step [113/303], Loss: 7.8049, Training-time: 1268.50
Epoch [2/10], Step [114/303], Loss: 7.7901, Training-time: 1271.55
Epoch [2/10], Step [115/303], Loss: 7.7779, Training-time: 1274.60
Epoch [2/10], Step [116/303], Loss: 7.7653, Training-time: 1277.64
Epoch [2/10], Step [117/303], Loss: 7.7500, Training-time: 1280.69
Epoch [2/10], Step [118/303], Loss: 7.7334, Training-time: 1283.73
Epoch [2/10], Step [119/303], Loss: 7.7195, Training-time: 1286.79
Epoch [2/10], Step [120/303], Loss: 7.7031, Training-time: 1289.84
Epoch [2/10], Step [121/303], Loss: 7.6915, Training-time: 1292.88
Epoch [2/10], Step [122/303], Loss: 7.6775, Training-time: 1295.93
Epoch [2/10], Step [123/303], Loss: 7.6652, Training-time: 1298.98
Epoch [2/10], Step [124/303], Loss: 7.6505, Training-time: 1302.03
Epoch [2/10], Step [125/303], Loss: 7.7161, Training-time: 1305.09
Epoch [2/10], Step [126/303], Loss: 7.7011, Training-time: 1308.14
Epoch [2/10], Step [127/303], Loss: 7.6851, Training-time: 1311.20
Epoch [2/10], Step [128/303], Loss: 7.6719, Training-time: 1314.25
Epoch [2/10], Step [129/303], Loss: 7.6586, Training-time: 1317.31
Epoch [2/10], Step [130/303], Loss: 7.6477, Training-time: 1320.35
Epoch [2/10], Step [131/303], Loss: 7.6329, Training-time: 1323.40
Epoch [2/10], Step [132/303], Loss: 7.7105, Training-time: 1326.46
Epoch [2/10], Step [133/303], Loss: 7.6984, Training-time: 1329.50
Epoch [2/10], Step [134/303], Loss: 7.6828, Training-time: 1332.56
Epoch [2/10], Step [135/303], Loss: 7.6677, Training-time: 1335.61
Epoch [2/10], Step [136/303], Loss: 7.6536, Training-time: 1338.66
Epoch [2/10], Step [137/303], Loss: 7.6383, Training-time: 1341.72
Epoch [2/10], Step [138/303], Loss: 7.6231, Training-time: 1344.77
Epoch [2/10], Step [139/303], Loss: 7.6145, Training-time: 1347.83
Epoch [2/10], Step [140/303], Loss: 7.6011, Training-time: 1350.88
Epoch [2/10], Step [141/303], Loss: 7.6195, Training-time: 1353.94
Epoch [2/10], Step [142/303], Loss: 7.6244, Training-time: 1357.00
Epoch [2/10], Step [143/303], Loss: 7.6240, Training-time: 1360.05
Epoch [2/10], Step [144/303], Loss: 7.6120, Training-time: 1363.11
Epoch [2/10], Step [145/303], Loss: 7.6319, Training-time: 1366.15
Epoch [2/10], Step [146/303], Loss: 7.6215, Training-time: 1369.19
Epoch [2/10], Step [147/303], Loss: 7.6069, Training-time: 1372.25
Epoch [2/10], Step [148/303], Loss: 7.6338, Training-time: 1375.30
Epoch [2/10], Step [149/303], Loss: 7.6212, Training-time: 1378.35
Epoch [2/10], Step [150/303], Loss: 7.6113, Training-time: 1381.40
Epoch [2/10], Step [151/303], Loss: 7.5990, Training-time: 1384.45
Epoch [2/10], Step [152/303], Loss: 7.5874, Training-time: 1387.50
Epoch [2/10], Step [153/303], Loss: 7.5731, Training-time: 1390.55
Epoch [2/10], Step [154/303], Loss: 7.5615, Training-time: 1393.60
Epoch [2/10], Step [155/303], Loss: 7.5471, Training-time: 1396.64
Epoch [2/10], Step [156/303], Loss: 7.5343, Training-time: 1399.69
Epoch [2/10], Step [157/303], Loss: 7.5244, Training-time: 1402.76
Epoch [2/10], Step [158/303], Loss: 7.5137, Training-time: 1405.82
Epoch [2/10], Step [159/303], Loss: 7.4995, Training-time: 1408.88
Epoch [2/10], Step [160/303], Loss: 7.4886, Training-time: 1411.93
Epoch [2/10], Step [161/303], Loss: 7.4745, Training-time: 1414.99
Epoch [2/10], Step [162/303], Loss: 7.4708, Training-time: 1418.03
Epoch [2/10], Step [163/303], Loss: 7.4734, Training-time: 1421.08
Epoch [2/10], Step [164/303], Loss: 7.4604, Training-time: 1424.13
Epoch [2/10], Step [165/303], Loss: 7.4465, Training-time: 1427.17
Epoch [2/10], Step [166/303], Loss: 7.4325, Training-time: 1430.21
Epoch [2/10], Step [167/303], Loss: 7.4213, Training-time: 1433.26
Epoch [2/10], Step [168/303], Loss: 7.4068, Training-time: 1436.32
Epoch [2/10], Step [169/303], Loss: 7.4369, Training-time: 1439.38
Epoch [2/10], Step [170/303], Loss: 7.4224, Training-time: 1442.43
Epoch [2/10], Step [171/303], Loss: 7.4084, Training-time: 1445.49
Epoch [2/10], Step [172/303], Loss: 7.3968, Training-time: 1448.54
Epoch [2/10], Step [173/303], Loss: 7.3845, Training-time: 1451.61
Epoch [2/10], Step [174/303], Loss: 7.3811, Training-time: 1454.65
Epoch [2/10], Step [175/303], Loss: 7.3670, Training-time: 1457.70
Epoch [2/10], Step [176/303], Loss: 7.3566, Training-time: 1460.77
Epoch [2/10], Step [177/303], Loss: 7.3445, Training-time: 1463.81
Epoch [2/10], Step [178/303], Loss: 7.3420, Training-time: 1466.86
Epoch [2/10], Step [179/303], Loss: 7.3318, Training-time: 1469.92
Epoch [2/10], Step [180/303], Loss: 7.3637, Training-time: 1472.98
Epoch [2/10], Step [181/303], Loss: 7.3502, Training-time: 1476.02
Epoch [2/10], Step [182/303], Loss: 7.3374, Training-time: 1479.07
Epoch [2/10], Step [183/303], Loss: 7.3266, Training-time: 1482.12
Epoch [2/10], Step [184/303], Loss: 7.3151, Training-time: 1485.16
Epoch [2/10], Step [185/303], Loss: 7.3021, Training-time: 1488.21
Epoch [2/10], Step [186/303], Loss: 7.2897, Training-time: 1491.25
Epoch [2/10], Step [187/303], Loss: 7.2852, Training-time: 1494.30
Epoch [2/10], Step [188/303], Loss: 7.2739, Training-time: 1497.36
Epoch [2/10], Step [189/303], Loss: 7.2610, Training-time: 1500.42
Epoch [2/10], Step [190/303], Loss: 7.2589, Training-time: 1503.46
Epoch [2/10], Step [191/303], Loss: 7.2454, Training-time: 1506.52
Epoch [2/10], Step [192/303], Loss: 7.2338, Training-time: 1509.57
Epoch [2/10], Step [193/303], Loss: 7.2201, Training-time: 1512.62
Epoch [2/10], Step [194/303], Loss: 7.2147, Training-time: 1515.66
Epoch [2/10], Step [195/303], Loss: 7.2133, Training-time: 1518.70
Epoch [2/10], Step [196/303], Loss: 7.1997, Training-time: 1521.75
Epoch [2/10], Step [197/303], Loss: 7.1870, Training-time: 1524.81
Epoch [2/10], Step [198/303], Loss: 7.1858, Training-time: 1527.88
Epoch [2/10], Step [199/303], Loss: 7.1848, Training-time: 1530.93
Epoch [2/10], Step [200/303], Loss: 7.2307, Training-time: 1533.98
Epoch [2/10], Step [201/303], Loss: 7.2293, Training-time: 1537.05
Epoch [2/10], Step [202/303], Loss: 7.2180, Training-time: 1540.10
Epoch [2/10], Step [203/303], Loss: 7.2099, Training-time: 1543.16
Epoch [2/10], Step [204/303], Loss: 7.1996, Training-time: 1546.21
Epoch [2/10], Step [205/303], Loss: 7.1874, Training-time: 1549.26
Epoch [2/10], Step [206/303], Loss: 7.1770, Training-time: 1552.30
Epoch [2/10], Step [207/303], Loss: 8.8425, Training-time: 1555.35
Epoch [2/10], Step [208/303], Loss: 8.8286, Training-time: 1558.39
Epoch [2/10], Step [209/303], Loss: 8.8154, Training-time: 1561.45
Epoch [2/10], Step [210/303], Loss: 8.8008, Training-time: 1564.49
Epoch [2/10], Step [211/303], Loss: 8.7992, Training-time: 1567.54
Epoch [2/10], Step [212/303], Loss: 8.7920, Training-time: 1570.60
Epoch [2/10], Step [213/303], Loss: 8.7810, Training-time: 1573.63
Epoch [2/10], Step [214/303], Loss: 8.7826, Training-time: 1576.69
Epoch [2/10], Step [215/303], Loss: 8.7729, Training-time: 1579.74
Epoch [2/10], Step [216/303], Loss: 8.7629, Training-time: 1582.78
Epoch [2/10], Step [217/303], Loss: 8.7549, Training-time: 1585.84
Epoch [2/10], Step [218/303], Loss: 8.7438, Training-time: 1588.89
Epoch [2/10], Step [219/303], Loss: 8.7341, Training-time: 1591.93
Epoch [2/10], Step [220/303], Loss: 8.7275, Training-time: 1594.97
Epoch [2/10], Step [221/303], Loss: 8.7238, Training-time: 1598.03
Epoch [2/10], Step [222/303], Loss: 8.7132, Training-time: 1601.07
Epoch [2/10], Step [223/303], Loss: 8.7016, Training-time: 1604.11
Epoch [2/10], Step [224/303], Loss: 8.7001, Training-time: 1607.16
Epoch [2/10], Step [225/303], Loss: 8.6898, Training-time: 1610.20
Epoch [2/10], Step [226/303], Loss: 8.6762, Training-time: 1613.25
Epoch [2/10], Step [227/303], Loss: 8.6617, Training-time: 1616.30
Epoch [2/10], Step [228/303], Loss: 8.6485, Training-time: 1619.35
Epoch [2/10], Step [229/303], Loss: 8.6390, Training-time: 1622.40
Epoch [2/10], Step [230/303], Loss: 8.7544, Training-time: 1625.45
Epoch [2/10], Step [231/303], Loss: 8.7498, Training-time: 1628.50
Epoch [2/10], Step [232/303], Loss: 8.7420, Training-time: 1631.56
Epoch [2/10], Step [233/303], Loss: 8.7271, Training-time: 1634.61
Epoch [2/10], Step [234/303], Loss: 8.7200, Training-time: 1637.68
Epoch [2/10], Step [235/303], Loss: 8.7072, Training-time: 1640.73
Epoch [2/10], Step [236/303], Loss: 8.6932, Training-time: 1643.77
Epoch [2/10], Step [237/303], Loss: 8.6805, Training-time: 1646.82
Epoch [2/10], Step [238/303], Loss: 8.6831, Training-time: 1649.86
Epoch [2/10], Step [239/303], Loss: 8.6711, Training-time: 1652.91
Epoch [2/10], Step [240/303], Loss: 8.6572, Training-time: 1655.97
Epoch [2/10], Step [241/303], Loss: 8.6428, Training-time: 1659.02
Epoch [2/10], Step [242/303], Loss: 8.6322, Training-time: 1662.07
Epoch [2/10], Step [243/303], Loss: 8.6196, Training-time: 1665.13
Epoch [2/10], Step [244/303], Loss: 8.6086, Training-time: 1668.17
Epoch [2/10], Step [245/303], Loss: 8.6009, Training-time: 1671.22
Epoch [2/10], Step [246/303], Loss: 8.5892, Training-time: 1674.27
Epoch [2/10], Step [247/303], Loss: 8.5762, Training-time: 1677.31
Epoch [2/10], Step [248/303], Loss: 8.5661, Training-time: 1680.36
Epoch [2/10], Step [249/303], Loss: 8.5518, Training-time: 1683.41
Epoch [2/10], Step [250/303], Loss: 8.5410, Training-time: 1686.46
Epoch [2/10], Step [251/303], Loss: 8.5276, Training-time: 1689.51
Epoch [2/10], Step [252/303], Loss: 8.5155, Training-time: 1692.56
Epoch [2/10], Step [253/303], Loss: 8.5105, Training-time: 1695.61
Epoch [2/10], Step [254/303], Loss: 8.4983, Training-time: 1698.66
Epoch [2/10], Step [255/303], Loss: 8.4865, Training-time: 1701.71
Epoch [2/10], Step [256/303], Loss: 8.4751, Training-time: 1704.76
Epoch [2/10], Step [257/303], Loss: 8.4631, Training-time: 1707.81
Epoch [2/10], Step [258/303], Loss: 8.4549, Training-time: 1710.86
Epoch [2/10], Step [259/303], Loss: 8.4421, Training-time: 1713.90
Epoch [2/10], Step [260/303], Loss: 8.4430, Training-time: 1716.94
Epoch [2/10], Step [261/303], Loss: 8.4300, Training-time: 1719.99
Epoch [2/10], Step [262/303], Loss: 8.4456, Training-time: 1723.05
Epoch [2/10], Step [263/303], Loss: 8.4326, Training-time: 1726.09
Epoch [2/10], Step [264/303], Loss: 8.4200, Training-time: 1729.14
Epoch [2/10], Step [265/303], Loss: 8.4098, Training-time: 1732.18
Epoch [2/10], Step [266/303], Loss: 8.3968, Training-time: 1735.23
Epoch [2/10], Step [267/303], Loss: 8.3910, Training-time: 1738.28
Epoch [2/10], Step [268/303], Loss: 8.3823, Training-time: 1741.34
Epoch [2/10], Step [269/303], Loss: 8.3695, Training-time: 1744.38
Epoch [2/10], Step [270/303], Loss: 8.3567, Training-time: 1747.44
Epoch [2/10], Step [271/303], Loss: 8.3437, Training-time: 1750.49
Epoch [2/10], Step [272/303], Loss: 8.3352, Training-time: 1753.55
Epoch [2/10], Step [273/303], Loss: 8.3232, Training-time: 1756.61
Epoch [2/10], Step [274/303], Loss: 8.3226, Training-time: 1759.66
Epoch [2/10], Step [275/303], Loss: 8.3099, Training-time: 1762.71
Epoch [2/10], Step [276/303], Loss: 8.2977, Training-time: 1765.76
Epoch [2/10], Step [277/303], Loss: 8.2847, Training-time: 1768.81
Epoch [2/10], Step [278/303], Loss: 8.2839, Training-time: 1771.86
Epoch [2/10], Step [279/303], Loss: 8.2737, Training-time: 1774.90
Epoch [2/10], Step [280/303], Loss: 8.2690, Training-time: 1777.95
Epoch [2/10], Step [281/303], Loss: 8.2563, Training-time: 1781.00
Epoch [2/10], Step [282/303], Loss: 8.2436, Training-time: 1784.06
Epoch [2/10], Step [283/303], Loss: 8.2322, Training-time: 1787.11
Epoch [2/10], Step [284/303], Loss: 8.2233, Training-time: 1790.16
Epoch [2/10], Step [285/303], Loss: 8.2124, Training-time: 1793.21
Epoch [2/10], Step [286/303], Loss: 8.1999, Training-time: 1796.25
Epoch [2/10], Step [287/303], Loss: 8.1970, Training-time: 1799.30
Epoch [2/10], Step [288/303], Loss: 8.1909, Training-time: 1802.35
Epoch [2/10], Step [289/303], Loss: 8.1786, Training-time: 1805.40
Epoch [2/10], Step [290/303], Loss: 8.1699, Training-time: 1808.45
Epoch [2/10], Step [291/303], Loss: 8.1572, Training-time: 1811.51
Epoch [2/10], Step [292/303], Loss: 8.1472, Training-time: 1814.55
Epoch [2/10], Step [293/303], Loss: 8.1364, Training-time: 1817.61
Epoch [2/10], Step [294/303], Loss: 8.1494, Training-time: 1820.66
Epoch [2/10], Step [295/303], Loss: 8.3855, Training-time: 1823.70
Epoch [2/10], Step [296/303], Loss: 8.3763, Training-time: 1826.75
Epoch [2/10], Step [297/303], Loss: 8.3642, Training-time: 1829.78
Epoch [2/10], Step [298/303], Loss: 8.3520, Training-time: 1832.81
Epoch [2/10], Step [299/303], Loss: 8.3411, Training-time: 1835.84
Epoch [2/10], Step [300/303], Loss: 8.3313, Training-time: 1838.87
Epoch [2/10], Step [301/303], Loss: 8.3197, Training-time: 1841.89
Epoch [2/10], Step [302/303], Loss: 8.3081, Training-time: 1844.91
Epoch [2/10], Step [303/303], Loss: 8.3010, Training-time: 1845.54
Epoch [3/10], Step [1/303], Loss: 8.2893, Training-time: 1848.91
Epoch [3/10], Step [2/303], Loss: 8.2792, Training-time: 1851.97
Epoch [3/10], Step [3/303], Loss: 8.2698, Training-time: 1855.02
Epoch [3/10], Step [4/303], Loss: 8.2572, Training-time: 1858.07
Epoch [3/10], Step [5/303], Loss: 8.2444, Training-time: 1861.11
Epoch [3/10], Step [6/303], Loss: 8.2318, Training-time: 1864.16
Epoch [3/10], Step [7/303], Loss: 8.2221, Training-time: 1867.21
Epoch [3/10], Step [8/303], Loss: 8.2115, Training-time: 1870.26
Epoch [3/10], Step [9/303], Loss: 8.1993, Training-time: 1873.30
Epoch [3/10], Step [10/303], Loss: 8.1883, Training-time: 1876.36
Epoch [3/10], Step [11/303], Loss: 8.1785, Training-time: 1879.40
Epoch [3/10], Step [12/303], Loss: 8.1657, Training-time: 1882.46
Epoch [3/10], Step [13/303], Loss: 8.1600, Training-time: 1885.52
Epoch [3/10], Step [14/303], Loss: 8.1473, Training-time: 1888.57
Epoch [3/10], Step [15/303], Loss: 8.1382, Training-time: 1891.63
Epoch [3/10], Step [16/303], Loss: 8.1303, Training-time: 1894.68
Epoch [3/10], Step [17/303], Loss: 8.1200, Training-time: 1897.73
Epoch [3/10], Step [18/303], Loss: 8.1083, Training-time: 1900.78
Epoch [3/10], Step [19/303], Loss: 8.1211, Training-time: 1903.84
Epoch [3/10], Step [20/303], Loss: 8.1098, Training-time: 1906.88
Epoch [3/10], Step [21/303], Loss: 8.1015, Training-time: 1909.93
Epoch [3/10], Step [22/303], Loss: 8.0927, Training-time: 1912.97
Epoch [3/10], Step [23/303], Loss: 8.0823, Training-time: 1916.02
Epoch [3/10], Step [24/303], Loss: 8.0725, Training-time: 1919.06
Epoch [3/10], Step [25/303], Loss: 8.0634, Training-time: 1922.11
Epoch [3/10], Step [26/303], Loss: 8.0527, Training-time: 1925.16
Epoch [3/10], Step [27/303], Loss: 8.0510, Training-time: 1928.22
Epoch [3/10], Step [28/303], Loss: 8.1486, Training-time: 1931.28
Epoch [3/10], Step [29/303], Loss: 8.1391, Training-time: 1934.33
Epoch [3/10], Step [30/303], Loss: 8.1322, Training-time: 1937.39
Epoch [3/10], Step [31/303], Loss: 8.1212, Training-time: 1940.44
Epoch [3/10], Step [32/303], Loss: 8.1122, Training-time: 1943.50
Epoch [3/10], Step [33/303], Loss: 8.2831, Training-time: 1946.56
Epoch [3/10], Step [34/303], Loss: 8.2814, Training-time: 1949.62
Epoch [3/10], Step [35/303], Loss: 8.2718, Training-time: 1952.67
Epoch [3/10], Step [36/303], Loss: 8.2750, Training-time: 1955.73
Epoch [3/10], Step [37/303], Loss: 8.2722, Training-time: 1958.78
Epoch [3/10], Step [38/303], Loss: 8.2621, Training-time: 1961.83
Epoch [3/10], Step [39/303], Loss: 8.2518, Training-time: 1964.87
Epoch [3/10], Step [40/303], Loss: 8.2414, Training-time: 1967.91
Epoch [3/10], Step [41/303], Loss: 8.2308, Training-time: 1970.96
Epoch [3/10], Step [42/303], Loss: 8.2209, Training-time: 1974.01
Epoch [3/10], Step [43/303], Loss: 8.2108, Training-time: 1977.05
Epoch [3/10], Step [44/303], Loss: 8.1998, Training-time: 1980.10
Epoch [3/10], Step [45/303], Loss: 8.1910, Training-time: 1983.16
Epoch [3/10], Step [46/303], Loss: 8.1945, Training-time: 1986.22
Epoch [3/10], Step [47/303], Loss: 8.1836, Training-time: 1989.27
Epoch [3/10], Step [48/303], Loss: 8.1724, Training-time: 1992.32
Epoch [3/10], Step [49/303], Loss: 8.1721, Training-time: 1995.37
Epoch [3/10], Step [50/303], Loss: 8.1629, Training-time: 1998.42
Epoch [3/10], Step [51/303], Loss: 8.1570, Training-time: 2001.48
Epoch [3/10], Step [52/303], Loss: 8.1468, Training-time: 2004.54
Epoch [3/10], Step [53/303], Loss: 8.1361, Training-time: 2007.59
Epoch [3/10], Step [54/303], Loss: 8.1305, Training-time: 2010.63
Epoch [3/10], Step [55/303], Loss: 8.1263, Training-time: 2013.69
Epoch [3/10], Step [56/303], Loss: 8.1467, Training-time: 2016.74
Epoch [3/10], Step [57/303], Loss: 8.1362, Training-time: 2019.79
Epoch [3/10], Step [58/303], Loss: 8.1270, Training-time: 2022.85
Epoch [3/10], Step [59/303], Loss: 8.1165, Training-time: 2025.90
Epoch [3/10], Step [60/303], Loss: 8.1089, Training-time: 2028.95
Epoch [3/10], Step [61/303], Loss: 8.0985, Training-time: 2032.00
Epoch [3/10], Step [62/303], Loss: 8.0939, Training-time: 2035.05
Epoch [3/10], Step [63/303], Loss: 8.0831, Training-time: 2038.10
Epoch [3/10], Step [64/303], Loss: 8.0737, Training-time: 2041.15
Epoch [3/10], Step [65/303], Loss: 8.0645, Training-time: 2044.21
Epoch [3/10], Step [66/303], Loss: 8.0543, Training-time: 2047.27
Epoch [3/10], Step [67/303], Loss: 8.0562, Training-time: 2050.32
Epoch [3/10], Step [68/303], Loss: 8.0459, Training-time: 2053.38
Epoch [3/10], Step [69/303], Loss: 8.0535, Training-time: 2056.44
Epoch [3/10], Step [70/303], Loss: 8.0446, Training-time: 2059.48
Epoch [3/10], Step [71/303], Loss: 8.0656, Training-time: 2062.55
Epoch [3/10], Step [72/303], Loss: 8.0563, Training-time: 2065.61
Epoch [3/10], Step [73/303], Loss: 8.0458, Training-time: 2068.66
Epoch [3/10], Step [74/303], Loss: 8.0471, Training-time: 2071.70
Epoch [3/10], Step [75/303], Loss: 8.0372, Training-time: 2074.76
Epoch [3/10], Step [76/303], Loss: 8.0289, Training-time: 2077.81
Epoch [3/10], Step [77/303], Loss: 8.0210, Training-time: 2080.87
Epoch [3/10], Step [78/303], Loss: 8.0118, Training-time: 2083.93
Epoch [3/10], Step [79/303], Loss: 8.0020, Training-time: 2086.98
Epoch [3/10], Step [80/303], Loss: 7.9922, Training-time: 2090.03
Epoch [3/10], Step [81/303], Loss: 7.9826, Training-time: 2093.08
Epoch [3/10], Step [82/303], Loss: 7.9743, Training-time: 2096.14
Epoch [3/10], Step [83/303], Loss: 8.0174, Training-time: 2099.19
Epoch [3/10], Step [84/303], Loss: 8.0069, Training-time: 2102.24
Epoch [3/10], Step [85/303], Loss: 7.9996, Training-time: 2105.29
Epoch [3/10], Step [86/303], Loss: 7.9956, Training-time: 2108.35
Epoch [3/10], Step [87/303], Loss: 7.9958, Training-time: 2111.41
Epoch [3/10], Step [88/303], Loss: 8.0014, Training-time: 2114.46
Epoch [3/10], Step [89/303], Loss: 7.9918, Training-time: 2117.51
Epoch [3/10], Step [90/303], Loss: 7.9819, Training-time: 2120.56
Epoch [3/10], Step [91/303], Loss: 9.1923, Training-time: 2123.62
Epoch [3/10], Step [92/303], Loss: 9.1836, Training-time: 2126.67
Epoch [3/10], Step [93/303], Loss: 9.1734, Training-time: 2129.72
Epoch [3/10], Step [94/303], Loss: 9.1637, Training-time: 2132.78
Epoch [3/10], Step [95/303], Loss: 9.1583, Training-time: 2135.83
Epoch [3/10], Step [96/303], Loss: 9.1488, Training-time: 2138.88
Epoch [3/10], Step [97/303], Loss: 9.1401, Training-time: 2141.94
Epoch [3/10], Step [98/303], Loss: 9.1313, Training-time: 2145.00
Epoch [3/10], Step [99/303], Loss: 9.1237, Training-time: 2148.05
Epoch [3/10], Step [100/303], Loss: 9.1140, Training-time: 2151.11
Epoch [3/10], Step [101/303], Loss: 9.1061, Training-time: 2154.16
Epoch [3/10], Step [102/303], Loss: 9.0995, Training-time: 2157.22
Epoch [3/10], Step [103/303], Loss: 9.0880, Training-time: 2160.27
Epoch [3/10], Step [104/303], Loss: 9.0766, Training-time: 2163.32
Epoch [3/10], Step [105/303], Loss: 9.0670, Training-time: 2166.37
Epoch [3/10], Step [106/303], Loss: 9.0562, Training-time: 2169.42
Epoch [3/10], Step [107/303], Loss: 9.0458, Training-time: 2172.48
Epoch [3/10], Step [108/303], Loss: 9.0384, Training-time: 2175.53
Epoch [3/10], Step [109/303], Loss: 9.0437, Training-time: 2178.59
Epoch [3/10], Step [110/303], Loss: 9.0320, Training-time: 2181.64
Epoch [3/10], Step [111/303], Loss: 9.0247, Training-time: 2184.69
Epoch [3/10], Step [112/303], Loss: 9.0173, Training-time: 2187.73
Epoch [3/10], Step [113/303], Loss: 9.0062, Training-time: 2190.78
Epoch [3/10], Step [114/303], Loss: 8.9956, Training-time: 2193.83
Epoch [3/10], Step [115/303], Loss: 8.9868, Training-time: 2196.89
Epoch [3/10], Step [116/303], Loss: 8.9755, Training-time: 2199.93
Epoch [3/10], Step [117/303], Loss: 8.9662, Training-time: 2202.98
Epoch [3/10], Step [118/303], Loss: 8.9548, Training-time: 2206.03
Epoch [3/10], Step [119/303], Loss: 8.9441, Training-time: 2209.08
Epoch [3/10], Step [120/303], Loss: 8.9336, Training-time: 2212.13
Epoch [3/10], Step [121/303], Loss: 8.9259, Training-time: 2215.16
Epoch [3/10], Step [122/303], Loss: 8.9157, Training-time: 2218.21
Epoch [3/10], Step [123/303], Loss: 8.9041, Training-time: 2221.25
Epoch [3/10], Step [124/303], Loss: 8.8939, Training-time: 2224.30
Epoch [3/10], Step [125/303], Loss: 8.8918, Training-time: 2227.35
Epoch [3/10], Step [126/303], Loss: 8.8978, Training-time: 2230.40
Epoch [3/10], Step [127/303], Loss: 8.8890, Training-time: 2233.45
Epoch [3/10], Step [128/303], Loss: 8.8776, Training-time: 2236.50
Epoch [3/10], Step [129/303], Loss: 8.8752, Training-time: 2239.56
Epoch [3/10], Step [130/303], Loss: 8.8643, Training-time: 2242.61
Epoch [3/10], Step [131/303], Loss: 8.8538, Training-time: 2245.65
Epoch [3/10], Step [132/303], Loss: 8.8448, Training-time: 2248.71
Epoch [3/10], Step [133/303], Loss: 8.8351, Training-time: 2251.77
Epoch [3/10], Step [134/303], Loss: 8.8306, Training-time: 2254.81
Epoch [3/10], Step [135/303], Loss: 8.8195, Training-time: 2257.87
Epoch [3/10], Step [136/303], Loss: 8.8089, Training-time: 2260.92
Epoch [3/10], Step [137/303], Loss: 8.8009, Training-time: 2263.98
Epoch [3/10], Step [138/303], Loss: 8.7941, Training-time: 2267.03
Epoch [3/10], Step [139/303], Loss: 8.7838, Training-time: 2270.08
Epoch [3/10], Step [140/303], Loss: 8.8166, Training-time: 2273.13
Epoch [3/10], Step [141/303], Loss: 8.8103, Training-time: 2276.18
Epoch [3/10], Step [142/303], Loss: 8.8010, Training-time: 2279.24
Epoch [3/10], Step [143/303], Loss: 8.7910, Training-time: 2282.29
Epoch [3/10], Step [144/303], Loss: 8.7867, Training-time: 2285.35
Epoch [3/10], Step [145/303], Loss: 8.7763, Training-time: 2288.41
Epoch [3/10], Step [146/303], Loss: 8.7668, Training-time: 2291.46
Epoch [3/10], Step [147/303], Loss: 8.7577, Training-time: 2294.50
Epoch [3/10], Step [148/303], Loss: 8.7471, Training-time: 2297.56
Epoch [3/10], Step [149/303], Loss: 8.7374, Training-time: 2300.61
Epoch [3/10], Step [150/303], Loss: 8.7308, Training-time: 2303.68
Epoch [3/10], Step [151/303], Loss: 8.7210, Training-time: 2306.73
Epoch [3/10], Step [152/303], Loss: 8.7109, Training-time: 2309.78
Epoch [3/10], Step [153/303], Loss: 8.7074, Training-time: 2312.84
Epoch [3/10], Step [154/303], Loss: 8.6965, Training-time: 2315.90
Epoch [3/10], Step [155/303], Loss: 8.6858, Training-time: 2318.96
Epoch [3/10], Step [156/303], Loss: 8.6825, Training-time: 2322.01
Epoch [3/10], Step [157/303], Loss: 8.6735, Training-time: 2325.06
Epoch [3/10], Step [158/303], Loss: 8.6691, Training-time: 2328.11
Epoch [3/10], Step [159/303], Loss: 8.6592, Training-time: 2331.15
Epoch [3/10], Step [160/303], Loss: 8.6488, Training-time: 2334.20
Epoch [3/10], Step [161/303], Loss: 8.6518, Training-time: 2337.25
Epoch [3/10], Step [162/303], Loss: 8.6579, Training-time: 2340.30
Epoch [3/10], Step [163/303], Loss: 8.6477, Training-time: 2343.35
Epoch [3/10], Step [164/303], Loss: 8.7521, Training-time: 2346.40
Epoch [3/10], Step [165/303], Loss: 8.7418, Training-time: 2349.45
Epoch [3/10], Step [166/303], Loss: 8.7333, Training-time: 2352.50
Epoch [3/10], Step [167/303], Loss: 8.7277, Training-time: 2355.55
Epoch [3/10], Step [168/303], Loss: 8.7190, Training-time: 2358.60
Epoch [3/10], Step [169/303], Loss: 8.7282, Training-time: 2361.65
Epoch [3/10], Step [170/303], Loss: 8.7188, Training-time: 2364.69
Epoch [3/10], Step [171/303], Loss: 8.7107, Training-time: 2367.74
Epoch [3/10], Step [172/303], Loss: 8.7008, Training-time: 2370.80
Epoch [3/10], Step [173/303], Loss: 8.7007, Training-time: 2373.86
Epoch [3/10], Step [174/303], Loss: 8.6930, Training-time: 2376.90
Epoch [3/10], Step [175/303], Loss: 8.6850, Training-time: 2379.96
Epoch [3/10], Step [176/303], Loss: 8.6751, Training-time: 2383.00
Epoch [3/10], Step [177/303], Loss: 8.6671, Training-time: 2386.07
Epoch [3/10], Step [178/303], Loss: 8.6570, Training-time: 2389.12
Epoch [3/10], Step [179/303], Loss: 8.6479, Training-time: 2392.17
Epoch [3/10], Step [180/303], Loss: 8.6379, Training-time: 2395.20
Epoch [3/10], Step [181/303], Loss: 8.6295, Training-time: 2398.26
Epoch [3/10], Step [182/303], Loss: 8.6411, Training-time: 2401.31
Epoch [3/10], Step [183/303], Loss: 8.6316, Training-time: 2404.35
Epoch [3/10], Step [184/303], Loss: 8.6241, Training-time: 2407.40
Epoch [3/10], Step [185/303], Loss: 8.6138, Training-time: 2410.45
Epoch [3/10], Step [186/303], Loss: 8.6068, Training-time: 2413.52
Epoch [3/10], Step [187/303], Loss: 8.5981, Training-time: 2416.56
Epoch [3/10], Step [188/303], Loss: 8.5881, Training-time: 2419.60
Epoch [3/10], Step [189/303], Loss: 8.5825, Training-time: 2422.64
Epoch [3/10], Step [190/303], Loss: 8.5734, Training-time: 2425.70
Epoch [3/10], Step [191/303], Loss: 8.5632, Training-time: 2428.74
Epoch [3/10], Step [192/303], Loss: 8.5544, Training-time: 2431.79
Epoch [3/10], Step [193/303], Loss: 8.5581, Training-time: 2434.84
Epoch [3/10], Step [194/303], Loss: 8.5501, Training-time: 2437.88
Epoch [3/10], Step [195/303], Loss: 8.5412, Training-time: 2440.94
Epoch [3/10], Step [196/303], Loss: 8.5331, Training-time: 2443.98
Epoch [3/10], Step [197/303], Loss: 8.5251, Training-time: 2447.02
Epoch [3/10], Step [198/303], Loss: 8.5248, Training-time: 2450.07
Epoch [3/10], Step [199/303], Loss: 8.5149, Training-time: 2453.13
Epoch [3/10], Step [200/303], Loss: 8.5116, Training-time: 2456.18
Epoch [3/10], Step [201/303], Loss: 8.5030, Training-time: 2459.24
Epoch [3/10], Step [202/303], Loss: 8.4986, Training-time: 2462.29
Epoch [3/10], Step [203/303], Loss: 8.4893, Training-time: 2465.35
Epoch [3/10], Step [204/303], Loss: 8.4865, Training-time: 2468.41
Epoch [3/10], Step [205/303], Loss: 8.4768, Training-time: 2471.46
Epoch [3/10], Step [206/303], Loss: 8.4769, Training-time: 2474.52
Epoch [3/10], Step [207/303], Loss: 8.4714, Training-time: 2477.59
Epoch [3/10], Step [208/303], Loss: 8.4618, Training-time: 2480.63
Epoch [3/10], Step [209/303], Loss: 8.4539, Training-time: 2483.69
Epoch [3/10], Step [210/303], Loss: 8.4455, Training-time: 2486.75
Epoch [3/10], Step [211/303], Loss: 8.4498, Training-time: 2489.80
Epoch [3/10], Step [212/303], Loss: 8.4412, Training-time: 2492.84
Epoch [3/10], Step [213/303], Loss: 8.4372, Training-time: 2495.88
Epoch [3/10], Step [214/303], Loss: 8.4282, Training-time: 2498.93
Epoch [3/10], Step [215/303], Loss: 8.4198, Training-time: 2501.97
Epoch [3/10], Step [216/303], Loss: 8.4223, Training-time: 2505.02
Epoch [3/10], Step [217/303], Loss: 8.4167, Training-time: 2508.07
Epoch [3/10], Step [218/303], Loss: 8.4134, Training-time: 2511.12
Epoch [3/10], Step [219/303], Loss: 8.4048, Training-time: 2514.18
Epoch [3/10], Step [220/303], Loss: 8.3969, Training-time: 2517.23
Epoch [3/10], Step [221/303], Loss: 8.3887, Training-time: 2520.29
Epoch [3/10], Step [222/303], Loss: 8.3801, Training-time: 2523.34
Epoch [3/10], Step [223/303], Loss: 8.3709, Training-time: 2526.40
Epoch [3/10], Step [224/303], Loss: 8.3704, Training-time: 2529.46
Epoch [3/10], Step [225/303], Loss: 8.3656, Training-time: 2532.52
Epoch [3/10], Step [226/303], Loss: 8.3588, Training-time: 2535.56
Epoch [3/10], Step [227/303], Loss: 8.3524, Training-time: 2538.61
Epoch [3/10], Step [228/303], Loss: 8.3489, Training-time: 2541.66
Epoch [3/10], Step [229/303], Loss: 8.3427, Training-time: 2544.71
Epoch [3/10], Step [230/303], Loss: 8.3339, Training-time: 2547.76
Epoch [3/10], Step [231/303], Loss: 8.3274, Training-time: 2550.80
Epoch [3/10], Step [232/303], Loss: 8.3187, Training-time: 2553.85
Epoch [3/10], Step [233/303], Loss: 8.3173, Training-time: 2556.90
Epoch [3/10], Step [234/303], Loss: 8.3161, Training-time: 2559.96
Epoch [3/10], Step [235/303], Loss: 8.3089, Training-time: 2563.01
Epoch [3/10], Step [236/303], Loss: 8.2999, Training-time: 2566.07
Epoch [3/10], Step [237/303], Loss: 8.2934, Training-time: 2569.11
Epoch [3/10], Step [238/303], Loss: 8.2878, Training-time: 2572.16
Epoch [3/10], Step [239/303], Loss: 8.2808, Training-time: 2575.21
Epoch [3/10], Step [240/303], Loss: 8.2746, Training-time: 2578.26
Epoch [3/10], Step [241/303], Loss: 8.2661, Training-time: 2581.32
Epoch [3/10], Step [242/303], Loss: 8.2583, Training-time: 2584.36
Epoch [3/10], Step [243/303], Loss: 8.2496, Training-time: 2587.41
Epoch [3/10], Step [244/303], Loss: 8.2432, Training-time: 2590.45
Epoch [3/10], Step [245/303], Loss: 8.4036, Training-time: 2593.49
Epoch [3/10], Step [246/303], Loss: 8.3954, Training-time: 2596.54
Epoch [3/10], Step [247/303], Loss: 8.3866, Training-time: 2599.60
Epoch [3/10], Step [248/303], Loss: 8.3950, Training-time: 2602.65
Epoch [3/10], Step [249/303], Loss: 8.3892, Training-time: 2605.70
Epoch [3/10], Step [250/303], Loss: 8.3814, Training-time: 2608.75
Epoch [3/10], Step [251/303], Loss: 8.3810, Training-time: 2611.81
Epoch [3/10], Step [252/303], Loss: 8.3752, Training-time: 2614.87
Epoch [3/10], Step [253/303], Loss: 8.3666, Training-time: 2617.93
Epoch [3/10], Step [254/303], Loss: 8.3596, Training-time: 2620.98
Epoch [3/10], Step [255/303], Loss: 8.3862, Training-time: 2624.03
Epoch [3/10], Step [256/303], Loss: 8.3820, Training-time: 2627.08
Epoch [3/10], Step [257/303], Loss: 8.3738, Training-time: 2630.13
Epoch [3/10], Step [258/303], Loss: 8.3661, Training-time: 2633.18
Epoch [3/10], Step [259/303], Loss: 8.3601, Training-time: 2636.23
Epoch [3/10], Step [260/303], Loss: 8.3667, Training-time: 2639.29
Epoch [3/10], Step [261/303], Loss: 8.3600, Training-time: 2642.34
Epoch [3/10], Step [262/303], Loss: 8.3525, Training-time: 2645.38
Epoch [3/10], Step [263/303], Loss: 8.3788, Training-time: 2648.43
Epoch [3/10], Step [264/303], Loss: 8.3703, Training-time: 2651.48
Epoch [3/10], Step [265/303], Loss: 8.3651, Training-time: 2654.53
Epoch [3/10], Step [266/303], Loss: 8.4244, Training-time: 2657.59
Epoch [3/10], Step [267/303], Loss: 8.4321, Training-time: 2660.64
Epoch [3/10], Step [268/303], Loss: 8.4268, Training-time: 2663.69
Epoch [3/10], Step [269/303], Loss: 8.4229, Training-time: 2666.73
Epoch [3/10], Step [270/303], Loss: 8.4660, Training-time: 2669.78
Epoch [3/10], Step [271/303], Loss: 8.4584, Training-time: 2672.83
Epoch [3/10], Step [272/303], Loss: 8.4509, Training-time: 2675.88
Epoch [3/10], Step [273/303], Loss: 8.4822, Training-time: 2678.93
Epoch [3/10], Step [274/303], Loss: 8.4793, Training-time: 2681.98
Epoch [3/10], Step [275/303], Loss: 8.4731, Training-time: 2685.04
Epoch [3/10], Step [276/303], Loss: 8.4660, Training-time: 2688.10
Epoch [3/10], Step [277/303], Loss: 8.4583, Training-time: 2691.16
Epoch [3/10], Step [278/303], Loss: 8.4508, Training-time: 2694.21
Epoch [3/10], Step [279/303], Loss: 8.4426, Training-time: 2697.26
Epoch [3/10], Step [280/303], Loss: 8.4349, Training-time: 2700.32
Epoch [3/10], Step [281/303], Loss: 8.4269, Training-time: 2703.37
Epoch [3/10], Step [282/303], Loss: 8.4202, Training-time: 2706.43
Epoch [3/10], Step [283/303], Loss: 8.4132, Training-time: 2709.48
Epoch [3/10], Step [284/303], Loss: 8.4057, Training-time: 2712.52
Epoch [3/10], Step [285/303], Loss: 8.3989, Training-time: 2715.57
Epoch [3/10], Step [286/303], Loss: 8.3935, Training-time: 2718.62
Epoch [3/10], Step [287/303], Loss: 8.3848, Training-time: 2721.65
Epoch [3/10], Step [288/303], Loss: 8.3761, Training-time: 2724.71
Epoch [3/10], Step [289/303], Loss: 8.3695, Training-time: 2727.76
Epoch [3/10], Step [290/303], Loss: 8.3621, Training-time: 2730.81
Epoch [3/10], Step [291/303], Loss: 8.3557, Training-time: 2733.87
Epoch [3/10], Step [292/303], Loss: 8.3476, Training-time: 2736.92
Epoch [3/10], Step [293/303], Loss: 8.3461, Training-time: 2739.98
Epoch [3/10], Step [294/303], Loss: 8.3376, Training-time: 2743.05
Epoch [3/10], Step [295/303], Loss: 8.3296, Training-time: 2746.10
Epoch [3/10], Step [296/303], Loss: 8.3251, Training-time: 2749.15
Epoch [3/10], Step [297/303], Loss: 8.3180, Training-time: 2752.19
Epoch [3/10], Step [298/303], Loss: 8.3126, Training-time: 2755.21
Epoch [3/10], Step [299/303], Loss: 8.3050, Training-time: 2758.23
Epoch [3/10], Step [300/303], Loss: 8.2976, Training-time: 2761.26
Epoch [3/10], Step [301/303], Loss: 8.2933, Training-time: 2764.28
Epoch [3/10], Step [302/303], Loss: 8.2859, Training-time: 2767.30
Epoch [3/10], Step [303/303], Loss: 8.2778, Training-time: 2767.93
Epoch [4/10], Step [1/303], Loss: 8.2727, Training-time: 2771.28
Epoch [4/10], Step [2/303], Loss: 8.2657, Training-time: 2774.33
Epoch [4/10], Step [3/303], Loss: 8.2603, Training-time: 2777.38
Epoch [4/10], Step [4/303], Loss: 8.2543, Training-time: 2780.43
Epoch [4/10], Step [5/303], Loss: 8.2462, Training-time: 2783.48
Epoch [4/10], Step [6/303], Loss: 8.2412, Training-time: 2786.52
Epoch [4/10], Step [7/303], Loss: 8.2343, Training-time: 2789.57
Epoch [4/10], Step [8/303], Loss: 8.2306, Training-time: 2792.61
Epoch [4/10], Step [9/303], Loss: 8.2255, Training-time: 2795.66
Epoch [4/10], Step [10/303], Loss: 8.2176, Training-time: 2798.71
Epoch [4/10], Step [11/303], Loss: 8.2109, Training-time: 2801.76
Epoch [4/10], Step [12/303], Loss: 8.2045, Training-time: 2804.81
Epoch [4/10], Step [13/303], Loss: 8.1982, Training-time: 2807.86
Epoch [4/10], Step [14/303], Loss: 8.1928, Training-time: 2810.91
Epoch [4/10], Step [15/303], Loss: 8.1858, Training-time: 2813.96
Epoch [4/10], Step [16/303], Loss: 8.2149, Training-time: 2817.02
Epoch [4/10], Step [17/303], Loss: 8.2185, Training-time: 2820.07
Epoch [4/10], Step [18/303], Loss: 8.2112, Training-time: 2823.12
Epoch [4/10], Step [19/303], Loss: 8.2046, Training-time: 2826.17
Epoch [4/10], Step [20/303], Loss: 8.1973, Training-time: 2829.22
Epoch [4/10], Step [21/303], Loss: 8.1932, Training-time: 2832.27
Epoch [4/10], Step [22/303], Loss: 8.1858, Training-time: 2835.33
Epoch [4/10], Step [23/303], Loss: 8.1781, Training-time: 2838.38
Epoch [4/10], Step [24/303], Loss: 8.1767, Training-time: 2841.43
Epoch [4/10], Step [25/303], Loss: 8.1692, Training-time: 2844.48
Epoch [4/10], Step [26/303], Loss: 8.1854, Training-time: 2847.52
Epoch [4/10], Step [27/303], Loss: 8.1778, Training-time: 2850.57
Epoch [4/10], Step [28/303], Loss: 8.1708, Training-time: 2853.62
Epoch [4/10], Step [29/303], Loss: 8.1770, Training-time: 2856.67
Epoch [4/10], Step [30/303], Loss: 8.1690, Training-time: 2859.72
Epoch [4/10], Step [31/303], Loss: 8.1687, Training-time: 2862.76
Epoch [4/10], Step [32/303], Loss: 8.1677, Training-time: 2865.81
Epoch [4/10], Step [33/303], Loss: 8.1599, Training-time: 2868.85
Epoch [4/10], Step [34/303], Loss: 8.1520, Training-time: 2871.89
Epoch [4/10], Step [35/303], Loss: 8.1442, Training-time: 2874.93
Epoch [4/10], Step [36/303], Loss: 8.1371, Training-time: 2877.97
Epoch [4/10], Step [37/303], Loss: 8.1403, Training-time: 2881.03
Epoch [4/10], Step [38/303], Loss: 8.1369, Training-time: 2884.08
Epoch [4/10], Step [39/303], Loss: 8.1609, Training-time: 2887.13
Epoch [4/10], Step [40/303], Loss: 8.1548, Training-time: 2890.19
Epoch [4/10], Step [41/303], Loss: 8.1516, Training-time: 2893.24
Epoch [4/10], Step [42/303], Loss: 8.2070, Training-time: 2896.28
Epoch [4/10], Step [43/303], Loss: 8.2052, Training-time: 2899.32
Epoch [4/10], Step [44/303], Loss: 8.1981, Training-time: 2902.36
Epoch [4/10], Step [45/303], Loss: 8.1911, Training-time: 2905.39
Epoch [4/10], Step [46/303], Loss: 8.1844, Training-time: 2908.45
Epoch [4/10], Step [47/303], Loss: 8.1812, Training-time: 2911.50
Epoch [4/10], Step [48/303], Loss: 8.1945, Training-time: 2914.55
Epoch [4/10], Step [49/303], Loss: 8.1941, Training-time: 2917.62
Epoch [4/10], Step [50/303], Loss: 8.1877, Training-time: 2920.67
Epoch [4/10], Step [51/303], Loss: 8.1806, Training-time: 2923.72
Epoch [4/10], Step [52/303], Loss: 8.1729, Training-time: 2926.76
Epoch [4/10], Step [53/303], Loss: 8.1707, Training-time: 2929.81
Epoch [4/10], Step [54/303], Loss: 8.1638, Training-time: 2932.86
Epoch [4/10], Step [55/303], Loss: 8.1563, Training-time: 2935.91
Epoch [4/10], Step [56/303], Loss: 8.1515, Training-time: 2938.95
Epoch [4/10], Step [57/303], Loss: 8.1441, Training-time: 2942.00
Epoch [4/10], Step [58/303], Loss: 8.1373, Training-time: 2945.05
Epoch [4/10], Step [59/303], Loss: 8.1338, Training-time: 2948.10
Epoch [4/10], Step [60/303], Loss: 8.2152, Training-time: 2951.16
Epoch [4/10], Step [61/303], Loss: 8.2104, Training-time: 2954.21
Epoch [4/10], Step [62/303], Loss: 8.2029, Training-time: 2957.26
Epoch [4/10], Step [63/303], Loss: 8.2331, Training-time: 2960.31
Epoch [4/10], Step [64/303], Loss: 8.2260, Training-time: 2963.35
Epoch [4/10], Step [65/303], Loss: 8.2199, Training-time: 2966.39
Epoch [4/10], Step [66/303], Loss: 8.2138, Training-time: 2969.44
Epoch [4/10], Step [67/303], Loss: 8.2186, Training-time: 2972.49
Epoch [4/10], Step [68/303], Loss: 8.2231, Training-time: 2975.53
Epoch [4/10], Step [69/303], Loss: 8.2166, Training-time: 2978.57
Epoch [4/10], Step [70/303], Loss: 8.3084, Training-time: 2981.62
Epoch [4/10], Step [71/303], Loss: 8.3012, Training-time: 2984.66
Epoch [4/10], Step [72/303], Loss: 8.2941, Training-time: 2987.70
Epoch [4/10], Step [73/303], Loss: 8.2872, Training-time: 2990.74
Epoch [4/10], Step [74/303], Loss: 8.2813, Training-time: 2993.79
Epoch [4/10], Step [75/303], Loss: 8.2781, Training-time: 2996.83
Epoch [4/10], Step [76/303], Loss: 8.2760, Training-time: 2999.87
Epoch [4/10], Step [77/303], Loss: 8.2707, Training-time: 3002.93
Epoch [4/10], Step [78/303], Loss: 8.2635, Training-time: 3005.98
Epoch [4/10], Step [79/303], Loss: 8.2584, Training-time: 3009.04
Epoch [4/10], Step [80/303], Loss: 8.2522, Training-time: 3012.09
Epoch [4/10], Step [81/303], Loss: 8.2468, Training-time: 3015.14
Epoch [4/10], Step [82/303], Loss: 8.2525, Training-time: 3018.19
Epoch [4/10], Step [83/303], Loss: 8.2470, Training-time: 3021.24
Epoch [4/10], Step [84/303], Loss: 8.2416, Training-time: 3024.28
Epoch [4/10], Step [85/303], Loss: 8.2653, Training-time: 3027.32
Epoch [4/10], Step [86/303], Loss: 8.2615, Training-time: 3030.35
Epoch [4/10], Step [87/303], Loss: 8.2608, Training-time: 3033.41
Epoch [4/10], Step [88/303], Loss: 8.2552, Training-time: 3036.46
Epoch [4/10], Step [89/303], Loss: 8.2488, Training-time: 3039.53
Epoch [4/10], Step [90/303], Loss: 8.2416, Training-time: 3042.58
Epoch [4/10], Step [91/303], Loss: 8.2393, Training-time: 3045.63
Epoch [4/10], Step [92/303], Loss: 8.2375, Training-time: 3048.68
Epoch [4/10], Step [93/303], Loss: 8.2305, Training-time: 3051.72
Epoch [4/10], Step [94/303], Loss: 8.2253, Training-time: 3054.78
Epoch [4/10], Step [95/303], Loss: 8.2196, Training-time: 3057.83
Epoch [4/10], Step [96/303], Loss: 8.2122, Training-time: 3060.88
Epoch [4/10], Step [97/303], Loss: 8.2062, Training-time: 3063.92
Epoch [4/10], Step [98/303], Loss: 8.1994, Training-time: 3066.97
Epoch [4/10], Step [99/303], Loss: 8.1922, Training-time: 3070.02
Epoch [4/10], Step [100/303], Loss: 8.1886, Training-time: 3073.07
Epoch [4/10], Step [101/303], Loss: 8.1819, Training-time: 3076.12
Epoch [4/10], Step [102/303], Loss: 9.0205, Training-time: 3079.17
Epoch [4/10], Step [103/303], Loss: 9.0125, Training-time: 3082.23
Epoch [4/10], Step [104/303], Loss: 9.0053, Training-time: 3085.29
Epoch [4/10], Step [105/303], Loss: 9.0151, Training-time: 3088.35
Epoch [4/10], Step [106/303], Loss: 9.0092, Training-time: 3091.39
Epoch [4/10], Step [107/303], Loss: 9.0022, Training-time: 3094.44
Epoch [4/10], Step [108/303], Loss: 8.9962, Training-time: 3097.49
Epoch [4/10], Step [109/303], Loss: 8.9942, Training-time: 3100.55
Epoch [4/10], Step [110/303], Loss: 8.9968, Training-time: 3103.60
Epoch [4/10], Step [111/303], Loss: 8.9907, Training-time: 3106.65
Epoch [4/10], Step [112/303], Loss: 8.9841, Training-time: 3109.71
Epoch [4/10], Step [113/303], Loss: 8.9770, Training-time: 3112.76
Epoch [4/10], Step [114/303], Loss: 8.9717, Training-time: 3115.80
Epoch [4/10], Step [115/303], Loss: 8.9651, Training-time: 3118.85
Epoch [4/10], Step [116/303], Loss: 8.9628, Training-time: 3121.89
Epoch [4/10], Step [117/303], Loss: 8.9552, Training-time: 3124.95
Epoch [4/10], Step [118/303], Loss: 8.9481, Training-time: 3128.00
Epoch [4/10], Step [119/303], Loss: 8.9407, Training-time: 3131.06
Epoch [4/10], Step [120/303], Loss: 8.9468, Training-time: 3134.11
Epoch [4/10], Step [121/303], Loss: 8.9402, Training-time: 3137.17
Epoch [4/10], Step [122/303], Loss: 8.9330, Training-time: 3140.23
Epoch [4/10], Step [123/303], Loss: 8.9255, Training-time: 3143.27
Epoch [4/10], Step [124/303], Loss: 8.9304, Training-time: 3146.33
Epoch [4/10], Step [125/303], Loss: 8.9232, Training-time: 3149.38
Epoch [4/10], Step [126/303], Loss: 8.9156, Training-time: 3152.43
Epoch [4/10], Step [127/303], Loss: 8.9087, Training-time: 3155.48
Epoch [4/10], Step [128/303], Loss: 8.9009, Training-time: 3158.53
Epoch [4/10], Step [129/303], Loss: 8.8967, Training-time: 3161.57
Epoch [4/10], Step [130/303], Loss: 8.8939, Training-time: 3164.63
Epoch [4/10], Step [131/303], Loss: 8.8904, Training-time: 3167.68
Epoch [4/10], Step [132/303], Loss: 8.8875, Training-time: 3170.73
Epoch [4/10], Step [133/303], Loss: 8.8799, Training-time: 3173.78
Epoch [4/10], Step [134/303], Loss: 8.8727, Training-time: 3176.81
Epoch [4/10], Step [135/303], Loss: 8.8648, Training-time: 3179.85
Epoch [4/10], Step [136/303], Loss: 8.8581, Training-time: 3182.90
Epoch [4/10], Step [137/303], Loss: 8.8531, Training-time: 3185.96
Epoch [4/10], Step [138/303], Loss: 8.8453, Training-time: 3189.01
Epoch [4/10], Step [139/303], Loss: 8.8399, Training-time: 3192.06
Epoch [4/10], Step [140/303], Loss: 8.8358, Training-time: 3195.09
Epoch [4/10], Step [141/303], Loss: 8.8291, Training-time: 3198.14
Epoch [4/10], Step [142/303], Loss: 8.8231, Training-time: 3201.18
Epoch [4/10], Step [143/303], Loss: 8.8162, Training-time: 3204.24
Epoch [4/10], Step [144/303], Loss: 8.8106, Training-time: 3207.28
Epoch [4/10], Step [145/303], Loss: 8.8034, Training-time: 3210.33
Epoch [4/10], Step [146/303], Loss: 8.7993, Training-time: 3213.38
Epoch [4/10], Step [147/303], Loss: 8.7953, Training-time: 3216.43
Epoch [4/10], Step [148/303], Loss: 8.7878, Training-time: 3219.47
Epoch [4/10], Step [149/303], Loss: 8.7886, Training-time: 3222.51
Epoch [4/10], Step [150/303], Loss: 8.7819, Training-time: 3225.56
Epoch [4/10], Step [151/303], Loss: 8.7744, Training-time: 3228.61
Epoch [4/10], Step [152/303], Loss: 8.7682, Training-time: 3231.67
Epoch [4/10], Step [153/303], Loss: 8.7614, Training-time: 3234.73
Epoch [4/10], Step [154/303], Loss: 8.7538, Training-time: 3237.78
Epoch [4/10], Step [155/303], Loss: 8.7488, Training-time: 3240.83
Epoch [4/10], Step [156/303], Loss: 8.7417, Training-time: 3243.88
Epoch [4/10], Step [157/303], Loss: 8.7555, Training-time: 3246.93
Epoch [4/10], Step [158/303], Loss: 8.7482, Training-time: 3249.98
Epoch [4/10], Step [159/303], Loss: 8.7440, Training-time: 3253.02
Epoch [4/10], Step [160/303], Loss: 8.7367, Training-time: 3256.07
Epoch [4/10], Step [161/303], Loss: 8.7362, Training-time: 3259.10
Epoch [4/10], Step [162/303], Loss: 8.7305, Training-time: 3262.15
Epoch [4/10], Step [163/303], Loss: 8.7234, Training-time: 3265.21
Epoch [4/10], Step [164/303], Loss: 8.7178, Training-time: 3268.26
Epoch [4/10], Step [165/303], Loss: 8.7111, Training-time: 3271.31
Epoch [4/10], Step [166/303], Loss: 8.7051, Training-time: 3274.36
Epoch [4/10], Step [167/303], Loss: 8.6982, Training-time: 3277.42
Epoch [4/10], Step [168/303], Loss: 8.6918, Training-time: 3280.47
Epoch [4/10], Step [169/303], Loss: 8.6843, Training-time: 3283.53
Epoch [4/10], Step [170/303], Loss: 8.6779, Training-time: 3286.58
Epoch [4/10], Step [171/303], Loss: 8.6733, Training-time: 3289.64
Epoch [4/10], Step [172/303], Loss: 8.6674, Training-time: 3292.69
Epoch [4/10], Step [173/303], Loss: 8.6602, Training-time: 3295.73
Epoch [4/10], Step [174/303], Loss: 8.6617, Training-time: 3298.77
Epoch [4/10], Step [175/303], Loss: 8.6553, Training-time: 3301.82
Epoch [4/10], Step [176/303], Loss: 8.6486, Training-time: 3304.87
Epoch [4/10], Step [177/303], Loss: 8.6447, Training-time: 3307.91
Epoch [4/10], Step [178/303], Loss: 8.6440, Training-time: 3310.96
Epoch [4/10], Step [179/303], Loss: 8.6368, Training-time: 3314.01
Epoch [4/10], Step [180/303], Loss: 8.6303, Training-time: 3317.07
Epoch [4/10], Step [181/303], Loss: 8.6273, Training-time: 3320.11
Epoch [4/10], Step [182/303], Loss: 8.6200, Training-time: 3323.17
Epoch [4/10], Step [183/303], Loss: 8.6128, Training-time: 3326.21
Epoch [4/10], Step [184/303], Loss: 8.6127, Training-time: 3329.26
Epoch [4/10], Step [185/303], Loss: 8.6056, Training-time: 3332.30
Epoch [4/10], Step [186/303], Loss: 8.5993, Training-time: 3335.35
Epoch [4/10], Step [187/303], Loss: 8.5937, Training-time: 3338.40
Epoch [4/10], Step [188/303], Loss: 8.5883, Training-time: 3341.45
Epoch [4/10], Step [189/303], Loss: 8.5837, Training-time: 3344.49
Epoch [4/10], Step [190/303], Loss: 8.5777, Training-time: 3347.54
Epoch [4/10], Step [191/303], Loss: 8.5711, Training-time: 3350.59
Epoch [4/10], Step [192/303], Loss: 8.5652, Training-time: 3353.64
Epoch [4/10], Step [193/303], Loss: 8.5609, Training-time: 3356.70
Epoch [4/10], Step [194/303], Loss: 8.5547, Training-time: 3359.75
Epoch [4/10], Step [195/303], Loss: 8.5493, Training-time: 3362.80
Epoch [4/10], Step [196/303], Loss: 8.5424, Training-time: 3365.86
Epoch [4/10], Step [197/303], Loss: 8.5362, Training-time: 3368.93
Epoch [4/10], Step [198/303], Loss: 8.5330, Training-time: 3371.98
Epoch [4/10], Step [199/303], Loss: 8.5270, Training-time: 3375.04
Epoch [4/10], Step [200/303], Loss: 8.5229, Training-time: 3378.09
Epoch [4/10], Step [201/303], Loss: 8.5164, Training-time: 3381.14
Epoch [4/10], Step [202/303], Loss: 8.5098, Training-time: 3384.19
Epoch [4/10], Step [203/303], Loss: 8.5045, Training-time: 3387.23
Epoch [4/10], Step [204/303], Loss: 8.5124, Training-time: 3390.27
Epoch [4/10], Step [205/303], Loss: 8.5082, Training-time: 3393.33
Epoch [4/10], Step [206/303], Loss: 8.5023, Training-time: 3396.37
Epoch [4/10], Step [207/303], Loss: 8.4958, Training-time: 3399.43
Epoch [4/10], Step [208/303], Loss: 8.4910, Training-time: 3402.49
Epoch [4/10], Step [209/303], Loss: 8.4845, Training-time: 3405.54
Epoch [4/10], Step [210/303], Loss: 8.4779, Training-time: 3408.60
Epoch [4/10], Step [211/303], Loss: 8.4710, Training-time: 3411.65
Epoch [4/10], Step [212/303], Loss: 8.4644, Training-time: 3414.69
Epoch [4/10], Step [213/303], Loss: 8.4574, Training-time: 3417.73
Epoch [4/10], Step [214/303], Loss: 8.4504, Training-time: 3420.78
Epoch [4/10], Step [215/303], Loss: 8.4568, Training-time: 3423.82
Epoch [4/10], Step [216/303], Loss: 8.4503, Training-time: 3426.87
Epoch [4/10], Step [217/303], Loss: 8.4448, Training-time: 3429.92
Epoch [4/10], Step [218/303], Loss: 8.4393, Training-time: 3432.97
Epoch [4/10], Step [219/303], Loss: 8.4327, Training-time: 3436.03
Epoch [4/10], Step [220/303], Loss: 8.4290, Training-time: 3439.08
Epoch [4/10], Step [221/303], Loss: 8.4225, Training-time: 3442.13
Epoch [4/10], Step [222/303], Loss: 8.4193, Training-time: 3445.18
Epoch [4/10], Step [223/303], Loss: 8.4132, Training-time: 3448.23
Epoch [4/10], Step [224/303], Loss: 8.4132, Training-time: 3451.29
Epoch [4/10], Step [225/303], Loss: 8.4088, Training-time: 3454.34
Epoch [4/10], Step [226/303], Loss: 8.4031, Training-time: 3457.39
Epoch [4/10], Step [227/303], Loss: 8.3971, Training-time: 3460.44
Epoch [4/10], Step [228/303], Loss: 8.3912, Training-time: 3463.50
Epoch [4/10], Step [229/303], Loss: 8.3844, Training-time: 3466.55
Epoch [4/10], Step [230/303], Loss: 8.3840, Training-time: 3469.59
Epoch [4/10], Step [231/303], Loss: 8.3904, Training-time: 3472.63
Epoch [4/10], Step [232/303], Loss: 8.3840, Training-time: 3475.67
Epoch [4/10], Step [233/303], Loss: 8.3782, Training-time: 3478.71
Epoch [4/10], Step [234/303], Loss: 8.3761, Training-time: 3481.76
Epoch [4/10], Step [235/303], Loss: 8.3703, Training-time: 3484.81
Epoch [4/10], Step [236/303], Loss: 8.3661, Training-time: 3487.86
Epoch [4/10], Step [237/303], Loss: 8.3595, Training-time: 3490.92
Epoch [4/10], Step [238/303], Loss: 8.3561, Training-time: 3493.98
Epoch [4/10], Step [239/303], Loss: 8.3518, Training-time: 3497.02
Epoch [4/10], Step [240/303], Loss: 8.3453, Training-time: 3500.08
Epoch [4/10], Step [241/303], Loss: 8.3396, Training-time: 3503.13
Epoch [4/10], Step [242/303], Loss: 8.3367, Training-time: 3506.17
Epoch [4/10], Step [243/303], Loss: 8.3321, Training-time: 3509.21
Epoch [4/10], Step [244/303], Loss: 8.3257, Training-time: 3512.26
Epoch [4/10], Step [245/303], Loss: 8.3204, Training-time: 3515.31
Epoch [4/10], Step [246/303], Loss: 8.3701, Training-time: 3518.36
Epoch [4/10], Step [247/303], Loss: 8.3686, Training-time: 3521.40
Epoch [4/10], Step [248/303], Loss: 8.3624, Training-time: 3524.44
Epoch [4/10], Step [249/303], Loss: 8.3563, Training-time: 3527.50
Epoch [4/10], Step [250/303], Loss: 8.3501, Training-time: 3530.54
Epoch [4/10], Step [251/303], Loss: 8.3483, Training-time: 3533.59
Epoch [4/10], Step [252/303], Loss: 8.3432, Training-time: 3536.64
Epoch [4/10], Step [253/303], Loss: 8.3367, Training-time: 3539.69
Epoch [4/10], Step [254/303], Loss: 8.3305, Training-time: 3542.74
Epoch [4/10], Step [255/303], Loss: 8.3261, Training-time: 3545.79
Epoch [4/10], Step [256/303], Loss: 8.3294, Training-time: 3548.85
Epoch [4/10], Step [257/303], Loss: 8.3234, Training-time: 3551.89
Epoch [4/10], Step [258/303], Loss: 8.3173, Training-time: 3554.94
Epoch [4/10], Step [259/303], Loss: 8.3112, Training-time: 3557.99
Epoch [4/10], Step [260/303], Loss: 8.3046, Training-time: 3561.04
Epoch [4/10], Step [261/303], Loss: 8.2991, Training-time: 3564.09
Epoch [4/10], Step [262/303], Loss: 8.2936, Training-time: 3567.14
Epoch [4/10], Step [263/303], Loss: 8.2868, Training-time: 3570.19
Epoch [4/10], Step [264/303], Loss: 8.2811, Training-time: 3573.24
Epoch [4/10], Step [265/303], Loss: 8.2840, Training-time: 3576.30
Epoch [4/10], Step [266/303], Loss: 8.2784, Training-time: 3579.36
Epoch [4/10], Step [267/303], Loss: 8.2745, Training-time: 3582.41
Epoch [4/10], Step [268/303], Loss: 8.2721, Training-time: 3585.47
Epoch [4/10], Step [269/303], Loss: 8.2656, Training-time: 3588.51
Epoch [4/10], Step [270/303], Loss: 8.2598, Training-time: 3591.56
Epoch [4/10], Step [271/303], Loss: 8.2594, Training-time: 3594.61
Epoch [4/10], Step [272/303], Loss: 8.2553, Training-time: 3597.66
Epoch [4/10], Step [273/303], Loss: 8.2612, Training-time: 3600.71
Epoch [4/10], Step [274/303], Loss: 8.2589, Training-time: 3603.76
Epoch [4/10], Step [275/303], Loss: 8.2526, Training-time: 3606.81
Epoch [4/10], Step [276/303], Loss: 8.2464, Training-time: 3609.86
Epoch [4/10], Step [277/303], Loss: 8.2409, Training-time: 3612.91
Epoch [4/10], Step [278/303], Loss: 8.2350, Training-time: 3615.95
Epoch [4/10], Step [279/303], Loss: 8.2292, Training-time: 3619.01
Epoch [4/10], Step [280/303], Loss: 8.2237, Training-time: 3622.05
Epoch [4/10], Step [281/303], Loss: 8.2178, Training-time: 3625.11
Epoch [4/10], Step [282/303], Loss: 8.2127, Training-time: 3628.17
Epoch [4/10], Step [283/303], Loss: 8.2071, Training-time: 3631.22
Epoch [4/10], Step [284/303], Loss: 8.2029, Training-time: 3634.27
Epoch [4/10], Step [285/303], Loss: 8.2296, Training-time: 3637.33
Epoch [4/10], Step [286/303], Loss: 8.2269, Training-time: 3640.37
Epoch [4/10], Step [287/303], Loss: 8.2219, Training-time: 3643.42
Epoch [4/10], Step [288/303], Loss: 8.2162, Training-time: 3646.47
Epoch [4/10], Step [289/303], Loss: 8.2117, Training-time: 3649.52
Epoch [4/10], Step [290/303], Loss: 8.2059, Training-time: 3652.57
Epoch [4/10], Step [291/303], Loss: 8.2004, Training-time: 3655.63
Epoch [4/10], Step [292/303], Loss: 8.1947, Training-time: 3658.69
Epoch [4/10], Step [293/303], Loss: 8.3043, Training-time: 3661.75
Epoch [4/10], Step [294/303], Loss: 8.2991, Training-time: 3664.80
Epoch [4/10], Step [295/303], Loss: 8.2933, Training-time: 3667.85
Epoch [4/10], Step [296/303], Loss: 8.2891, Training-time: 3670.90
Epoch [4/10], Step [297/303], Loss: 8.2837, Training-time: 3673.94
Epoch [4/10], Step [298/303], Loss: 8.2779, Training-time: 3676.97
Epoch [4/10], Step [299/303], Loss: 8.2745, Training-time: 3680.00
Epoch [4/10], Step [300/303], Loss: 8.2689, Training-time: 3683.02
Epoch [4/10], Step [301/303], Loss: 8.2634, Training-time: 3686.04
Epoch [4/10], Step [302/303], Loss: 8.2578, Training-time: 3689.06
Epoch [4/10], Step [303/303], Loss: 8.2526, Training-time: 3689.68
Epoch [5/10], Step [1/303], Loss: 8.2465, Training-time: 3693.07
Epoch [5/10], Step [2/303], Loss: 8.2406, Training-time: 3696.14
Epoch [5/10], Step [3/303], Loss: 8.2360, Training-time: 3699.19
Epoch [5/10], Step [4/303], Loss: 8.2301, Training-time: 3702.24
Epoch [5/10], Step [5/303], Loss: 8.2246, Training-time: 3705.30
Epoch [5/10], Step [6/303], Loss: 8.2272, Training-time: 3708.34
Epoch [5/10], Step [7/303], Loss: 8.2231, Training-time: 3711.39
Epoch [5/10], Step [8/303], Loss: 8.2182, Training-time: 3714.43
Epoch [5/10], Step [9/303], Loss: 8.2126, Training-time: 3717.49
Epoch [5/10], Step [10/303], Loss: 8.2064, Training-time: 3720.55
Epoch [5/10], Step [11/303], Loss: 8.2001, Training-time: 3723.58
Epoch [5/10], Step [12/303], Loss: 8.2111, Training-time: 3726.63
Epoch [5/10], Step [13/303], Loss: 8.2058, Training-time: 3729.68
Epoch [5/10], Step [14/303], Loss: 8.2032, Training-time: 3732.73
Epoch [5/10], Step [15/303], Loss: 8.1970, Training-time: 3735.78
Epoch [5/10], Step [16/303], Loss: 8.1911, Training-time: 3738.83
Epoch [5/10], Step [17/303], Loss: 8.1877, Training-time: 3741.86
Epoch [5/10], Step [18/303], Loss: 8.1827, Training-time: 3744.91
Epoch [5/10], Step [19/303], Loss: 8.1774, Training-time: 3747.96
Epoch [5/10], Step [20/303], Loss: 8.1718, Training-time: 3751.01
Epoch [5/10], Step [21/303], Loss: 8.1682, Training-time: 3754.06
Epoch [5/10], Step [22/303], Loss: 8.1625, Training-time: 3757.11
Epoch [5/10], Step [23/303], Loss: 8.1581, Training-time: 3760.15
Epoch [5/10], Step [24/303], Loss: 8.1521, Training-time: 3763.21
Epoch [5/10], Step [25/303], Loss: 8.1495, Training-time: 3766.26
Epoch [5/10], Step [26/303], Loss: 8.1441, Training-time: 3769.31
Epoch [5/10], Step [27/303], Loss: 8.1511, Training-time: 3772.35
Epoch [5/10], Step [28/303], Loss: 8.1458, Training-time: 3775.39
Epoch [5/10], Step [29/303], Loss: 8.1428, Training-time: 3778.45
Epoch [5/10], Step [30/303], Loss: 8.1468, Training-time: 3781.50
Epoch [5/10], Step [31/303], Loss: 8.1445, Training-time: 3784.54
Epoch [5/10], Step [32/303], Loss: 8.1429, Training-time: 3787.60
Epoch [5/10], Step [33/303], Loss: 8.1368, Training-time: 3790.64
Epoch [5/10], Step [34/303], Loss: 8.1312, Training-time: 3793.69
Epoch [5/10], Step [35/303], Loss: 8.1265, Training-time: 3796.74
Epoch [5/10], Step [36/303], Loss: 8.1208, Training-time: 3799.79
Epoch [5/10], Step [37/303], Loss: 8.1154, Training-time: 3802.85
Epoch [5/10], Step [38/303], Loss: 8.1101, Training-time: 3805.90
Epoch [5/10], Step [39/303], Loss: 8.1042, Training-time: 3808.95
Epoch [5/10], Step [40/303], Loss: 8.1271, Training-time: 3812.01
Epoch [5/10], Step [41/303], Loss: 8.1219, Training-time: 3815.04
Epoch [5/10], Step [42/303], Loss: 8.1214, Training-time: 3818.09
Epoch [5/10], Step [43/303], Loss: 8.1158, Training-time: 3821.14
Epoch [5/10], Step [44/303], Loss: 8.1103, Training-time: 3824.19
Epoch [5/10], Step [45/303], Loss: 8.1142, Training-time: 3827.24
Epoch [5/10], Step [46/303], Loss: 8.1088, Training-time: 3830.28
Epoch [5/10], Step [47/303], Loss: 8.1052, Training-time: 3833.33
Epoch [5/10], Step [48/303], Loss: 8.1003, Training-time: 3836.38
Epoch [5/10], Step [49/303], Loss: 8.0952, Training-time: 3839.43
Epoch [5/10], Step [50/303], Loss: 8.0908, Training-time: 3842.46
Epoch [5/10], Step [51/303], Loss: 8.0849, Training-time: 3845.52
Epoch [5/10], Step [52/303], Loss: 8.0877, Training-time: 3848.56
Epoch [5/10], Step [53/303], Loss: 8.0837, Training-time: 3851.61
Epoch [5/10], Step [54/303], Loss: 8.0823, Training-time: 3854.66
Epoch [5/10], Step [55/303], Loss: 8.0769, Training-time: 3857.72
Epoch [5/10], Step [56/303], Loss: 8.7497, Training-time: 3860.77
Epoch [5/10], Step [57/303], Loss: 8.7453, Training-time: 3863.82
Epoch [5/10], Step [58/303], Loss: 8.7402, Training-time: 3866.88
Epoch [5/10], Step [59/303], Loss: 8.7372, Training-time: 3869.93
Epoch [5/10], Step [60/303], Loss: 8.7316, Training-time: 3872.98
Epoch [5/10], Step [61/303], Loss: 8.7279, Training-time: 3876.03
Epoch [5/10], Step [62/303], Loss: 8.7235, Training-time: 3879.07
Epoch [5/10], Step [63/303], Loss: 8.7183, Training-time: 3882.12
Epoch [5/10], Step [64/303], Loss: 8.7144, Training-time: 3885.17
Epoch [5/10], Step [65/303], Loss: 8.7098, Training-time: 3888.22
Epoch [5/10], Step [66/303], Loss: 8.7048, Training-time: 3891.28
Epoch [5/10], Step [67/303], Loss: 8.7008, Training-time: 3894.33
Epoch [5/10], Step [68/303], Loss: 8.6978, Training-time: 3897.37
Epoch [5/10], Step [69/303], Loss: 8.6975, Training-time: 3900.43
Epoch [5/10], Step [70/303], Loss: 8.7653, Training-time: 3903.48
Epoch [5/10], Step [71/303], Loss: 8.7591, Training-time: 3906.53
Epoch [5/10], Step [72/303], Loss: 8.7684, Training-time: 3909.59
Epoch [5/10], Step [73/303], Loss: 8.7652, Training-time: 3912.63
Epoch [5/10], Step [74/303], Loss: 8.7835, Training-time: 3915.67
Epoch [5/10], Step [75/303], Loss: 8.7779, Training-time: 3918.71
Epoch [5/10], Step [76/303], Loss: 8.8852, Training-time: 3921.76
Epoch [5/10], Step [77/303], Loss: 8.8797, Training-time: 3924.82
Epoch [5/10], Step [78/303], Loss: 8.8745, Training-time: 3927.87
Epoch [5/10], Step [79/303], Loss: 8.8687, Training-time: 3930.93
Epoch [5/10], Step [80/303], Loss: 8.8638, Training-time: 3933.98
Epoch [5/10], Step [81/303], Loss: 8.8627, Training-time: 3937.04
Epoch [5/10], Step [82/303], Loss: 8.8569, Training-time: 3940.09
Epoch [5/10], Step [83/303], Loss: 8.8533, Training-time: 3943.14
Epoch [5/10], Step [84/303], Loss: 8.8753, Training-time: 3946.18
Epoch [5/10], Step [85/303], Loss: 8.8694, Training-time: 3949.23
Epoch [5/10], Step [86/303], Loss: 8.8647, Training-time: 3952.27
Epoch [5/10], Step [87/303], Loss: 8.8587, Training-time: 3955.31
Epoch [5/10], Step [88/303], Loss: 8.8532, Training-time: 3958.36
Epoch [5/10], Step [89/303], Loss: 8.8474, Training-time: 3961.41
Epoch [5/10], Step [90/303], Loss: 8.8413, Training-time: 3964.45
Epoch [5/10], Step [91/303], Loss: 8.8412, Training-time: 3967.49
Epoch [5/10], Step [92/303], Loss: 8.8357, Training-time: 3970.53
Epoch [5/10], Step [93/303], Loss: 8.8300, Training-time: 3973.57
Epoch [5/10], Step [94/303], Loss: 8.8246, Training-time: 3976.62
Epoch [5/10], Step [95/303], Loss: 8.8188, Training-time: 3979.67
Epoch [5/10], Step [96/303], Loss: 8.8128, Training-time: 3982.73
Epoch [5/10], Step [97/303], Loss: 8.8102, Training-time: 3985.78
Epoch [5/10], Step [98/303], Loss: 8.8043, Training-time: 3988.81
Epoch [5/10], Step [99/303], Loss: 8.7986, Training-time: 3991.87
Epoch [5/10], Step [100/303], Loss: 8.8162, Training-time: 3994.92
Epoch [5/10], Step [101/303], Loss: 8.8140, Training-time: 3997.96
Epoch [5/10], Step [102/303], Loss: 8.8078, Training-time: 4001.01
Epoch [5/10], Step [103/303], Loss: 8.8020, Training-time: 4004.05
Epoch [5/10], Step [104/303], Loss: 8.7961, Training-time: 4007.10
Epoch [5/10], Step [105/303], Loss: 8.7901, Training-time: 4010.14
Epoch [5/10], Step [106/303], Loss: 8.7844, Training-time: 4013.19
Epoch [5/10], Step [107/303], Loss: 8.7785, Training-time: 4016.22
Epoch [5/10], Step [108/303], Loss: 8.7742, Training-time: 4019.27
Epoch [5/10], Step [109/303], Loss: 8.7683, Training-time: 4022.32
Epoch [5/10], Step [110/303], Loss: 8.7621, Training-time: 4025.36
Epoch [5/10], Step [111/303], Loss: 8.7563, Training-time: 4028.42
Epoch [5/10], Step [112/303], Loss: 8.7509, Training-time: 4031.47
Epoch [5/10], Step [113/303], Loss: 8.7448, Training-time: 4034.53
Epoch [5/10], Step [114/303], Loss: 8.7386, Training-time: 4037.58
Epoch [5/10], Step [115/303], Loss: 8.7341, Training-time: 4040.62
Epoch [5/10], Step [116/303], Loss: 8.7286, Training-time: 4043.67
Epoch [5/10], Step [117/303], Loss: 8.7227, Training-time: 4046.72
Epoch [5/10], Step [118/303], Loss: 8.7194, Training-time: 4049.77
Epoch [5/10], Step [119/303], Loss: 8.7161, Training-time: 4052.83
Epoch [5/10], Step [120/303], Loss: 8.7114, Training-time: 4055.89
Epoch [5/10], Step [121/303], Loss: 8.7080, Training-time: 4058.94
Epoch [5/10], Step [122/303], Loss: 8.7021, Training-time: 4061.98
Epoch [5/10], Step [123/303], Loss: 8.6963, Training-time: 4065.03
Epoch [5/10], Step [124/303], Loss: 8.6917, Training-time: 4068.09
Epoch [5/10], Step [125/303], Loss: 8.6866, Training-time: 4071.15
Epoch [5/10], Step [126/303], Loss: 8.6813, Training-time: 4074.20
Epoch [5/10], Step [127/303], Loss: 8.6758, Training-time: 4077.25
Epoch [5/10], Step [128/303], Loss: 8.6700, Training-time: 4080.29
Epoch [5/10], Step [129/303], Loss: 8.6645, Training-time: 4083.34
Epoch [5/10], Step [130/303], Loss: 8.6597, Training-time: 4086.39
Epoch [5/10], Step [131/303], Loss: 8.6538, Training-time: 4089.45
Epoch [5/10], Step [132/303], Loss: 8.6479, Training-time: 4092.51
Epoch [5/10], Step [133/303], Loss: 8.6429, Training-time: 4095.56
Epoch [5/10], Step [134/303], Loss: 8.6375, Training-time: 4098.61
Epoch [5/10], Step [135/303], Loss: 8.6321, Training-time: 4101.66
Epoch [5/10], Step [136/303], Loss: 8.6272, Training-time: 4104.72
Epoch [5/10], Step [137/303], Loss: 8.6215, Training-time: 4107.78
Epoch [5/10], Step [138/303], Loss: 8.6222, Training-time: 4110.85
Epoch [5/10], Step [139/303], Loss: 8.6201, Training-time: 4113.91
Epoch [5/10], Step [140/303], Loss: 8.6144, Training-time: 4116.96
Epoch [5/10], Step [141/303], Loss: 8.6104, Training-time: 4120.00
Epoch [5/10], Step [142/303], Loss: 8.6056, Training-time: 4123.05
Epoch [5/10], Step [143/303], Loss: 8.6029, Training-time: 4126.10
Epoch [5/10], Step [144/303], Loss: 8.6044, Training-time: 4129.14
Epoch [5/10], Step [145/303], Loss: 8.6029, Training-time: 4132.19
Epoch [5/10], Step [146/303], Loss: 8.5998, Training-time: 4135.23
Epoch [5/10], Step [147/303], Loss: 8.5960, Training-time: 4138.28
Epoch [5/10], Step [148/303], Loss: 8.5915, Training-time: 4141.34
Epoch [5/10], Step [149/303], Loss: 8.6310, Training-time: 4144.39
Epoch [5/10], Step [150/303], Loss: 8.6395, Training-time: 4147.45
Epoch [5/10], Step [151/303], Loss: 8.6342, Training-time: 4150.50
Epoch [5/10], Step [152/303], Loss: 8.6288, Training-time: 4153.55
Epoch [5/10], Step [153/303], Loss: 8.6286, Training-time: 4156.60
Epoch [5/10], Step [154/303], Loss: 8.6239, Training-time: 4159.65
Epoch [5/10], Step [155/303], Loss: 8.6185, Training-time: 4162.70
Epoch [5/10], Step [156/303], Loss: 8.6135, Training-time: 4165.75
Epoch [5/10], Step [157/303], Loss: 8.6090, Training-time: 4168.81
Epoch [5/10], Step [158/303], Loss: 8.6046, Training-time: 4171.85
Epoch [5/10], Step [159/303], Loss: 8.6010, Training-time: 4174.89
Epoch [5/10], Step [160/303], Loss: 8.5959, Training-time: 4177.94
Epoch [5/10], Step [161/303], Loss: 8.5915, Training-time: 4180.99
Epoch [5/10], Step [162/303], Loss: 8.5866, Training-time: 4184.04
Epoch [5/10], Step [163/303], Loss: 8.5812, Training-time: 4187.11
Epoch [5/10], Step [164/303], Loss: 8.5883, Training-time: 4190.14
Epoch [5/10], Step [165/303], Loss: 8.5847, Training-time: 4193.18
Epoch [5/10], Step [166/303], Loss: 8.5795, Training-time: 4196.23
Epoch [5/10], Step [167/303], Loss: 8.5764, Training-time: 4199.28
Epoch [5/10], Step [168/303], Loss: 8.5804, Training-time: 4202.31
Epoch [5/10], Step [169/303], Loss: 8.5782, Training-time: 4205.37
Epoch [5/10], Step [170/303], Loss: 8.5740, Training-time: 4208.41
Epoch [5/10], Step [171/303], Loss: 8.5685, Training-time: 4211.46
Epoch [5/10], Step [172/303], Loss: 8.5630, Training-time: 4214.51
Epoch [5/10], Step [173/303], Loss: 8.5586, Training-time: 4217.56
Epoch [5/10], Step [174/303], Loss: 8.5530, Training-time: 4220.60
Epoch [5/10], Step [175/303], Loss: 8.5482, Training-time: 4223.65
Epoch [5/10], Step [176/303], Loss: 8.5438, Training-time: 4226.70
Epoch [5/10], Step [177/303], Loss: 8.5414, Training-time: 4229.76
Epoch [5/10], Step [178/303], Loss: 8.5418, Training-time: 4232.81
Epoch [5/10], Step [179/303], Loss: 8.5368, Training-time: 4235.87
Epoch [5/10], Step [180/303], Loss: 8.5312, Training-time: 4238.91
Epoch [5/10], Step [181/303], Loss: 8.5260, Training-time: 4241.95
Epoch [5/10], Step [182/303], Loss: 8.5212, Training-time: 4245.00
Epoch [5/10], Step [183/303], Loss: 8.5195, Training-time: 4248.05
Epoch [5/10], Step [184/303], Loss: 8.5152, Training-time: 4251.10
Epoch [5/10], Step [185/303], Loss: 8.5099, Training-time: 4254.16
Epoch [5/10], Step [186/303], Loss: 8.5046, Training-time: 4257.20
Epoch [5/10], Step [187/303], Loss: 8.5034, Training-time: 4260.24
Epoch [5/10], Step [188/303], Loss: 8.5023, Training-time: 4263.28
Epoch [5/10], Step [189/303], Loss: 8.5034, Training-time: 4266.33
Epoch [5/10], Step [190/303], Loss: 8.4987, Training-time: 4269.38
Epoch [5/10], Step [191/303], Loss: 8.4936, Training-time: 4272.42
Epoch [5/10], Step [192/303], Loss: 8.4882, Training-time: 4275.48
Epoch [5/10], Step [193/303], Loss: 8.4840, Training-time: 4278.53
Epoch [5/10], Step [194/303], Loss: 8.4791, Training-time: 4281.59
Epoch [5/10], Step [195/303], Loss: 8.4771, Training-time: 4284.63
Epoch [5/10], Step [196/303], Loss: 8.4714, Training-time: 4287.68
Epoch [5/10], Step [197/303], Loss: 8.4684, Training-time: 4290.73
Epoch [5/10], Step [198/303], Loss: 8.4652, Training-time: 4293.78
Epoch [5/10], Step [199/303], Loss: 8.4599, Training-time: 4296.83
Epoch [5/10], Step [200/303], Loss: 8.4560, Training-time: 4299.87
Epoch [5/10], Step [201/303], Loss: 8.4584, Training-time: 4302.92
Epoch [5/10], Step [202/303], Loss: 8.4528, Training-time: 4305.97
Epoch [5/10], Step [203/303], Loss: 8.4499, Training-time: 4309.02
Epoch [5/10], Step [204/303], Loss: 8.4460, Training-time: 4312.07
Epoch [5/10], Step [205/303], Loss: 8.4559, Training-time: 4315.13
Epoch [5/10], Step [206/303], Loss: 8.4506, Training-time: 4318.18
Epoch [5/10], Step [207/303], Loss: 8.4454, Training-time: 4321.23
Epoch [5/10], Step [208/303], Loss: 8.4402, Training-time: 4324.28
Epoch [5/10], Step [209/303], Loss: 8.4945, Training-time: 4327.34
Epoch [5/10], Step [210/303], Loss: 8.4897, Training-time: 4330.39
Epoch [5/10], Step [211/303], Loss: 8.4879, Training-time: 4333.45
Epoch [5/10], Step [212/303], Loss: 8.4829, Training-time: 4336.49
Epoch [5/10], Step [213/303], Loss: 8.4777, Training-time: 4339.54
Epoch [5/10], Step [214/303], Loss: 8.4728, Training-time: 4342.59
Epoch [5/10], Step [215/303], Loss: 8.4713, Training-time: 4345.65
Epoch [5/10], Step [216/303], Loss: 8.4694, Training-time: 4348.70
Epoch [5/10], Step [217/303], Loss: 8.4644, Training-time: 4351.76
Epoch [5/10], Step [218/303], Loss: 8.4604, Training-time: 4354.81
Epoch [5/10], Step [219/303], Loss: 8.4557, Training-time: 4357.86
Epoch [5/10], Step [220/303], Loss: 8.4544, Training-time: 4360.90
Epoch [5/10], Step [221/303], Loss: 8.4492, Training-time: 4363.94
Epoch [5/10], Step [222/303], Loss: 8.4455, Training-time: 4366.99
Epoch [5/10], Step [223/303], Loss: 8.4400, Training-time: 4370.04
Epoch [5/10], Step [224/303], Loss: 8.4364, Training-time: 4373.10
Epoch [5/10], Step [225/303], Loss: 8.4312, Training-time: 4376.14
Epoch [5/10], Step [226/303], Loss: 8.4263, Training-time: 4379.19
Epoch [5/10], Step [227/303], Loss: 8.4217, Training-time: 4382.24
Epoch [5/10], Step [228/303], Loss: 8.4162, Training-time: 4385.29
Epoch [5/10], Step [229/303], Loss: 8.4110, Training-time: 4388.34
Epoch [5/10], Step [230/303], Loss: 8.4056, Training-time: 4391.40
Epoch [5/10], Step [231/303], Loss: 8.4006, Training-time: 4394.45
Epoch [5/10], Step [232/303], Loss: 8.3959, Training-time: 4397.51
Epoch [5/10], Step [233/303], Loss: 8.3906, Training-time: 4400.57
Epoch [5/10], Step [234/303], Loss: 8.3866, Training-time: 4403.62
Epoch [5/10], Step [235/303], Loss: 8.3812, Training-time: 4406.69
Epoch [5/10], Step [236/303], Loss: 8.3762, Training-time: 4409.75
Epoch [5/10], Step [237/303], Loss: 8.3707, Training-time: 4412.79
Epoch [5/10], Step [238/303], Loss: 8.3695, Training-time: 4415.86
Epoch [5/10], Step [239/303], Loss: 8.3644, Training-time: 4418.91
Epoch [5/10], Step [240/303], Loss: 8.3611, Training-time: 4421.95
Epoch [5/10], Step [241/303], Loss: 8.3558, Training-time: 4425.02
Epoch [5/10], Step [242/303], Loss: 8.3518, Training-time: 4428.07
Epoch [5/10], Step [243/303], Loss: 8.3464, Training-time: 4431.13
Epoch [5/10], Step [244/303], Loss: 8.3423, Training-time: 4434.18
Epoch [5/10], Step [245/303], Loss: 8.3426, Training-time: 4437.24
Epoch [5/10], Step [246/303], Loss: 8.3374, Training-time: 4440.28
Epoch [5/10], Step [247/303], Loss: 8.3321, Training-time: 4443.34
Epoch [5/10], Step [248/303], Loss: 8.3280, Training-time: 4446.39
Epoch [5/10], Step [249/303], Loss: 8.3231, Training-time: 4449.46
Epoch [5/10], Step [250/303], Loss: 8.3185, Training-time: 4452.52
Epoch [5/10], Step [251/303], Loss: 8.3136, Training-time: 4455.57
Epoch [5/10], Step [252/303], Loss: 8.3088, Training-time: 4458.62
Epoch [5/10], Step [253/303], Loss: 8.3476, Training-time: 4461.67
Epoch [5/10], Step [254/303], Loss: 8.3439, Training-time: 4464.73
Epoch [5/10], Step [255/303], Loss: 8.3401, Training-time: 4467.78
Epoch [5/10], Step [256/303], Loss: 8.3366, Training-time: 4470.82
Epoch [5/10], Step [257/303], Loss: 8.3320, Training-time: 4473.86
Epoch [5/10], Step [258/303], Loss: 8.3271, Training-time: 4476.91
Epoch [5/10], Step [259/303], Loss: 8.3228, Training-time: 4479.96
Epoch [5/10], Step [260/303], Loss: 8.3180, Training-time: 4483.01
Epoch [5/10], Step [261/303], Loss: 8.3148, Training-time: 4486.06
Epoch [5/10], Step [262/303], Loss: 8.3356, Training-time: 4489.11
Epoch [5/10], Step [263/303], Loss: 8.3305, Training-time: 4492.16
Epoch [5/10], Step [264/303], Loss: 8.3255, Training-time: 4495.22
Epoch [5/10], Step [265/303], Loss: 8.3271, Training-time: 4498.27
Epoch [5/10], Step [266/303], Loss: 8.3220, Training-time: 4501.33
Epoch [5/10], Step [267/303], Loss: 8.3175, Training-time: 4504.38
Epoch [5/10], Step [268/303], Loss: 8.3133, Training-time: 4507.44
Epoch [5/10], Step [269/303], Loss: 8.3085, Training-time: 4510.49
Epoch [5/10], Step [270/303], Loss: 8.3048, Training-time: 4513.54
Epoch [5/10], Step [271/303], Loss: 8.2998, Training-time: 4516.58
Epoch [5/10], Step [272/303], Loss: 8.2948, Training-time: 4519.64
Epoch [5/10], Step [273/303], Loss: 8.2900, Training-time: 4522.68
Epoch [5/10], Step [274/303], Loss: 8.2923, Training-time: 4525.73
Epoch [5/10], Step [275/303], Loss: 8.2916, Training-time: 4528.78
Epoch [5/10], Step [276/303], Loss: 8.2868, Training-time: 4531.83
Epoch [5/10], Step [277/303], Loss: 8.2818, Training-time: 4534.89
Epoch [5/10], Step [278/303], Loss: 8.2778, Training-time: 4537.94
Epoch [5/10], Step [279/303], Loss: 8.2727, Training-time: 4541.00
Epoch [5/10], Step [280/303], Loss: 8.2695, Training-time: 4544.05
Epoch [5/10], Step [281/303], Loss: 8.2646, Training-time: 4547.10
Epoch [5/10], Step [282/303], Loss: 8.2747, Training-time: 4550.15
Epoch [5/10], Step [283/303], Loss: 8.2711, Training-time: 4553.20
Epoch [5/10], Step [284/303], Loss: 8.2667, Training-time: 4556.26
Epoch [5/10], Step [285/303], Loss: 8.2623, Training-time: 4559.32
Epoch [5/10], Step [286/303], Loss: 8.2598, Training-time: 4562.37
Epoch [5/10], Step [287/303], Loss: 8.2548, Training-time: 4565.43
Epoch [5/10], Step [288/303], Loss: 8.2600, Training-time: 4568.48
Epoch [5/10], Step [289/303], Loss: 8.2599, Training-time: 4571.54
Epoch [5/10], Step [290/303], Loss: 8.2551, Training-time: 4574.58
Epoch [5/10], Step [291/303], Loss: 8.2506, Training-time: 4577.63
Epoch [5/10], Step [292/303], Loss: 8.2464, Training-time: 4580.68
Epoch [5/10], Step [293/303], Loss: 8.2484, Training-time: 4583.73
Epoch [5/10], Step [294/303], Loss: 8.2440, Training-time: 4586.77
Epoch [5/10], Step [295/303], Loss: 8.2406, Training-time: 4589.82
Epoch [5/10], Step [296/303], Loss: 8.2358, Training-time: 4592.87
Epoch [5/10], Step [297/303], Loss: 8.2364, Training-time: 4595.91
Epoch [5/10], Step [298/303], Loss: 8.2364, Training-time: 4598.93
Epoch [5/10], Step [299/303], Loss: 8.2331, Training-time: 4601.95
Epoch [5/10], Step [300/303], Loss: 8.2389, Training-time: 4604.97
Epoch [5/10], Step [301/303], Loss: 8.2341, Training-time: 4608.00
Epoch [5/10], Step [302/303], Loss: 8.2299, Training-time: 4611.01
Epoch [5/10], Step [303/303], Loss: 8.2252, Training-time: 4611.64
Epoch [6/10], Step [1/303], Loss: 8.2215, Training-time: 4615.02
Epoch [6/10], Step [2/303], Loss: 8.2192, Training-time: 4618.08
Epoch [6/10], Step [3/303], Loss: 8.2185, Training-time: 4621.12
Epoch [6/10], Step [4/303], Loss: 8.2139, Training-time: 4624.17
Epoch [6/10], Step [5/303], Loss: 8.2093, Training-time: 4627.22
Epoch [6/10], Step [6/303], Loss: 8.2063, Training-time: 4630.28
Epoch [6/10], Step [7/303], Loss: 8.2015, Training-time: 4633.32
Epoch [6/10], Step [8/303], Loss: 8.1973, Training-time: 4636.35
Epoch [6/10], Step [9/303], Loss: 8.1926, Training-time: 4639.39
Epoch [6/10], Step [10/303], Loss: 8.1926, Training-time: 4642.43
Epoch [6/10], Step [11/303], Loss: 8.1890, Training-time: 4645.48
Epoch [6/10], Step [12/303], Loss: 8.1942, Training-time: 4648.53
Epoch [6/10], Step [13/303], Loss: 8.1940, Training-time: 4651.58
Epoch [6/10], Step [14/303], Loss: 8.1900, Training-time: 4654.62
Epoch [6/10], Step [15/303], Loss: 8.1851, Training-time: 4657.67
Epoch [6/10], Step [16/303], Loss: 8.1805, Training-time: 4660.73
Epoch [6/10], Step [17/303], Loss: 8.1762, Training-time: 4663.76
Epoch [6/10], Step [18/303], Loss: 8.1727, Training-time: 4666.82
Epoch [6/10], Step [19/303], Loss: 8.1700, Training-time: 4669.87
Epoch [6/10], Step [20/303], Loss: 8.1697, Training-time: 4672.93
Epoch [6/10], Step [21/303], Loss: 8.1668, Training-time: 4675.98
Epoch [6/10], Step [22/303], Loss: 8.1723, Training-time: 4679.03
Epoch [6/10], Step [23/303], Loss: 8.1936, Training-time: 4682.10
Epoch [6/10], Step [24/303], Loss: 8.1893, Training-time: 4685.14
Epoch [6/10], Step [25/303], Loss: 8.1849, Training-time: 4688.20
Epoch [6/10], Step [26/303], Loss: 8.1808, Training-time: 4691.26
Epoch [6/10], Step [27/303], Loss: 8.1767, Training-time: 4694.32
Epoch [6/10], Step [28/303], Loss: 8.1732, Training-time: 4697.38
Epoch [6/10], Step [29/303], Loss: 8.1696, Training-time: 4700.43
Epoch [6/10], Step [30/303], Loss: 8.1649, Training-time: 4703.48
Epoch [6/10], Step [31/303], Loss: 8.1626, Training-time: 4706.53
Epoch [6/10], Step [32/303], Loss: 8.1652, Training-time: 4709.58
Epoch [6/10], Step [33/303], Loss: 8.1608, Training-time: 4712.62
Epoch [6/10], Step [34/303], Loss: 8.1563, Training-time: 4715.67
Epoch [6/10], Step [35/303], Loss: 8.1538, Training-time: 4718.71
Epoch [6/10], Step [36/303], Loss: 8.1505, Training-time: 4721.76
Epoch [6/10], Step [37/303], Loss: 8.1460, Training-time: 4724.81
Epoch [6/10], Step [38/303], Loss: 8.1411, Training-time: 4727.86
Epoch [6/10], Step [39/303], Loss: 8.1368, Training-time: 4730.91
Epoch [6/10], Step [40/303], Loss: 8.2243, Training-time: 4733.95
Epoch [6/10], Step [41/303], Loss: 8.2203, Training-time: 4737.01
Epoch [6/10], Step [42/303], Loss: 8.2154, Training-time: 4740.06
Epoch [6/10], Step [43/303], Loss: 8.2129, Training-time: 4743.12
Epoch [6/10], Step [44/303], Loss: 8.2080, Training-time: 4746.16
Epoch [6/10], Step [45/303], Loss: 8.2035, Training-time: 4749.21
Epoch [6/10], Step [46/303], Loss: 8.2024, Training-time: 4752.27
Epoch [6/10], Step [47/303], Loss: 8.1978, Training-time: 4755.31
Epoch [6/10], Step [48/303], Loss: 8.1934, Training-time: 4758.37
Epoch [6/10], Step [49/303], Loss: 8.1893, Training-time: 4761.43
Epoch [6/10], Step [50/303], Loss: 8.1858, Training-time: 4764.49
Epoch [6/10], Step [51/303], Loss: 8.1814, Training-time: 4767.54
Epoch [6/10], Step [52/303], Loss: 8.1778, Training-time: 4770.59
Epoch [6/10], Step [53/303], Loss: 8.1816, Training-time: 4773.63
Epoch [6/10], Step [54/303], Loss: 8.1775, Training-time: 4776.67
Epoch [6/10], Step [55/303], Loss: 8.1744, Training-time: 4779.72
Epoch [6/10], Step [56/303], Loss: 8.1703, Training-time: 4782.77
Epoch [6/10], Step [57/303], Loss: 8.1716, Training-time: 4785.80
Epoch [6/10], Step [58/303], Loss: 8.1676, Training-time: 4788.84
Epoch [6/10], Step [59/303], Loss: 8.1646, Training-time: 4791.90
Epoch [6/10], Step [60/303], Loss: 8.1608, Training-time: 4794.95
Epoch [6/10], Step [61/303], Loss: 8.1568, Training-time: 4798.01
Epoch [6/10], Step [62/303], Loss: 8.1927, Training-time: 4801.07
Epoch [6/10], Step [63/303], Loss: 8.1884, Training-time: 4804.11
Epoch [6/10], Step [64/303], Loss: 8.1856, Training-time: 4807.16
Epoch [6/10], Step [65/303], Loss: 8.1821, Training-time: 4810.20
Epoch [6/10], Step [66/303], Loss: 8.1780, Training-time: 4813.25
Epoch [6/10], Step [67/303], Loss: 8.1738, Training-time: 4816.29
Epoch [6/10], Step [68/303], Loss: 8.1744, Training-time: 4819.35
Epoch [6/10], Step [69/303], Loss: 8.1700, Training-time: 4822.41
Epoch [6/10], Step [70/303], Loss: 8.1656, Training-time: 4825.45
Epoch [6/10], Step [71/303], Loss: 8.1619, Training-time: 4828.51
Epoch [6/10], Step [72/303], Loss: 8.1575, Training-time: 4831.55
Epoch [6/10], Step [73/303], Loss: 8.1534, Training-time: 4834.60
Epoch [6/10], Step [74/303], Loss: 8.1496, Training-time: 4837.66
Epoch [6/10], Step [75/303], Loss: 8.1479, Training-time: 4840.71
Epoch [6/10], Step [76/303], Loss: 8.1434, Training-time: 4843.77
Epoch [6/10], Step [77/303], Loss: 8.1452, Training-time: 4846.82
Epoch [6/10], Step [78/303], Loss: 8.1409, Training-time: 4849.87
Epoch [6/10], Step [79/303], Loss: 8.1369, Training-time: 4852.92
Epoch [6/10], Step [80/303], Loss: 8.1346, Training-time: 4855.97
Epoch [6/10], Step [81/303], Loss: 8.1303, Training-time: 4859.01
Epoch [6/10], Step [82/303], Loss: 8.1272, Training-time: 4862.06
Epoch [6/10], Step [83/303], Loss: 8.1230, Training-time: 4865.11
Epoch [6/10], Step [84/303], Loss: 8.1192, Training-time: 4868.16
Epoch [6/10], Step [85/303], Loss: 8.1163, Training-time: 4871.22
Epoch [6/10], Step [86/303], Loss: 8.1124, Training-time: 4874.29
Epoch [6/10], Step [87/303], Loss: 8.1087, Training-time: 4877.34
Epoch [6/10], Step [88/303], Loss: 8.1042, Training-time: 4880.38
Epoch [6/10], Step [89/303], Loss: 8.1007, Training-time: 4883.43
Epoch [6/10], Step [90/303], Loss: 8.0964, Training-time: 4886.48
Epoch [6/10], Step [91/303], Loss: 8.0922, Training-time: 4889.54
Epoch [6/10], Step [92/303], Loss: 8.0876, Training-time: 4892.59
Epoch [6/10], Step [93/303], Loss: 8.0895, Training-time: 4895.64
Epoch [6/10], Step [94/303], Loss: 8.0884, Training-time: 4898.69
Epoch [6/10], Step [95/303], Loss: 8.0840, Training-time: 4901.75
Epoch [6/10], Step [96/303], Loss: 8.0822, Training-time: 4904.81
Epoch [6/10], Step [97/303], Loss: 8.0779, Training-time: 4907.86
Epoch [6/10], Step [98/303], Loss: 8.0736, Training-time: 4910.92
Epoch [6/10], Step [99/303], Loss: 8.0699, Training-time: 4913.97
Epoch [6/10], Step [100/303], Loss: 8.0654, Training-time: 4917.02
Epoch [6/10], Step [101/303], Loss: 8.0609, Training-time: 4920.07
Epoch [6/10], Step [102/303], Loss: 8.0567, Training-time: 4923.13
Epoch [6/10], Step [103/303], Loss: 8.0528, Training-time: 4926.17
Epoch [6/10], Step [104/303], Loss: 8.0483, Training-time: 4929.22
Epoch [6/10], Step [105/303], Loss: 8.0447, Training-time: 4932.27
Epoch [6/10], Step [106/303], Loss: 8.0410, Training-time: 4935.32
Epoch [6/10], Step [107/303], Loss: 8.0363, Training-time: 4938.37
Epoch [6/10], Step [108/303], Loss: 8.0321, Training-time: 4941.42
Epoch [6/10], Step [109/303], Loss: 8.0274, Training-time: 4944.46
Epoch [6/10], Step [110/303], Loss: 8.0231, Training-time: 4947.52
Epoch [6/10], Step [111/303], Loss: 8.0187, Training-time: 4950.56
Epoch [6/10], Step [112/303], Loss: 8.0158, Training-time: 4953.61
Epoch [6/10], Step [113/303], Loss: 8.0130, Training-time: 4956.66
Epoch [6/10], Step [114/303], Loss: 8.0089, Training-time: 4959.71
Epoch [6/10], Step [115/303], Loss: 8.0139, Training-time: 4962.77
Epoch [6/10], Step [116/303], Loss: 8.0097, Training-time: 4965.83
Epoch [6/10], Step [117/303], Loss: 8.0075, Training-time: 4968.88
Epoch [6/10], Step [118/303], Loss: 8.0030, Training-time: 4971.94
Epoch [6/10], Step [119/303], Loss: 8.0104, Training-time: 4974.99
Epoch [6/10], Step [120/303], Loss: 8.0067, Training-time: 4978.02
Epoch [6/10], Step [121/303], Loss: 8.0028, Training-time: 4981.07
Epoch [6/10], Step [122/303], Loss: 7.9985, Training-time: 4984.13
Epoch [6/10], Step [123/303], Loss: 7.9949, Training-time: 4987.19
Epoch [6/10], Step [124/303], Loss: 7.9911, Training-time: 4990.23
Epoch [6/10], Step [125/303], Loss: 7.9871, Training-time: 4993.27
Epoch [6/10], Step [126/303], Loss: 7.9828, Training-time: 4996.33
Epoch [6/10], Step [127/303], Loss: 8.0146, Training-time: 4999.39
Epoch [6/10], Step [128/303], Loss: 8.0112, Training-time: 5002.44
Epoch [6/10], Step [129/303], Loss: 8.0095, Training-time: 5005.48
Epoch [6/10], Step [130/303], Loss: 8.0079, Training-time: 5008.53
Epoch [6/10], Step [131/303], Loss: 8.0039, Training-time: 5011.58
Epoch [6/10], Step [132/303], Loss: 7.9998, Training-time: 5014.62
Epoch [6/10], Step [133/303], Loss: 7.9957, Training-time: 5017.67
Epoch [6/10], Step [134/303], Loss: 7.9913, Training-time: 5020.72
Epoch [6/10], Step [135/303], Loss: 7.9876, Training-time: 5023.78
Epoch [6/10], Step [136/303], Loss: 7.9831, Training-time: 5026.84
Epoch [6/10], Step [137/303], Loss: 7.9881, Training-time: 5029.89
Epoch [6/10], Step [138/303], Loss: 7.9840, Training-time: 5032.94
Epoch [6/10], Step [139/303], Loss: 7.9832, Training-time: 5036.00
Epoch [6/10], Step [140/303], Loss: 7.9883, Training-time: 5039.05
Epoch [6/10], Step [141/303], Loss: 7.9844, Training-time: 5042.09
Epoch [6/10], Step [142/303], Loss: 7.9803, Training-time: 5045.14
Epoch [6/10], Step [143/303], Loss: 7.9764, Training-time: 5048.20
Epoch [6/10], Step [144/303], Loss: 7.9743, Training-time: 5051.25
Epoch [6/10], Step [145/303], Loss: 7.9703, Training-time: 5054.30
Epoch [6/10], Step [146/303], Loss: 7.9681, Training-time: 5057.37
Epoch [6/10], Step [147/303], Loss: 7.9640, Training-time: 5060.41
Epoch [6/10], Step [148/303], Loss: 7.9655, Training-time: 5063.47
Epoch [6/10], Step [149/303], Loss: 7.9621, Training-time: 5066.51
Epoch [6/10], Step [150/303], Loss: 7.9614, Training-time: 5069.57
Epoch [6/10], Step [151/303], Loss: 7.9576, Training-time: 5072.60
Epoch [6/10], Step [152/303], Loss: 7.9536, Training-time: 5075.65
Epoch [6/10], Step [153/303], Loss: 7.9495, Training-time: 5078.69
Epoch [6/10], Step [154/303], Loss: 7.9457, Training-time: 5081.73
Epoch [6/10], Step [155/303], Loss: 7.9426, Training-time: 5084.79
Epoch [6/10], Step [156/303], Loss: 7.9392, Training-time: 5087.83
Epoch [6/10], Step [157/303], Loss: 7.9355, Training-time: 5090.88
Epoch [6/10], Step [158/303], Loss: 7.9804, Training-time: 5093.94
Epoch [6/10], Step [159/303], Loss: 7.9766, Training-time: 5096.99
Epoch [6/10], Step [160/303], Loss: 7.9736, Training-time: 5100.04
Epoch [6/10], Step [161/303], Loss: 7.9699, Training-time: 5103.09
Epoch [6/10], Step [162/303], Loss: 7.9829, Training-time: 5106.14
Epoch [6/10], Step [163/303], Loss: 7.9799, Training-time: 5109.18
Epoch [6/10], Step [164/303], Loss: 7.9835, Training-time: 5112.23
Epoch [6/10], Step [165/303], Loss: 7.9798, Training-time: 5115.27
Epoch [6/10], Step [166/303], Loss: 8.0009, Training-time: 5118.30
Epoch [6/10], Step [167/303], Loss: 7.9974, Training-time: 5121.35
Epoch [6/10], Step [168/303], Loss: 7.9946, Training-time: 5124.41
Epoch [6/10], Step [169/303], Loss: 7.9966, Training-time: 5127.46
Epoch [6/10], Step [170/303], Loss: 7.9927, Training-time: 5130.52
Epoch [6/10], Step [171/303], Loss: 7.9889, Training-time: 5133.57
Epoch [6/10], Step [172/303], Loss: 7.9893, Training-time: 5136.62
Epoch [6/10], Step [173/303], Loss: 7.9852, Training-time: 5139.68
Epoch [6/10], Step [174/303], Loss: 7.9845, Training-time: 5142.73
Epoch [6/10], Step [175/303], Loss: 7.9810, Training-time: 5145.77
Epoch [6/10], Step [176/303], Loss: 7.9775, Training-time: 5148.81
Epoch [6/10], Step [177/303], Loss: 7.9737, Training-time: 5151.85
Epoch [6/10], Step [178/303], Loss: 7.9734, Training-time: 5154.90
Epoch [6/10], Step [179/303], Loss: 7.9697, Training-time: 5157.95
Epoch [6/10], Step [180/303], Loss: 7.9679, Training-time: 5160.99
Epoch [6/10], Step [181/303], Loss: 7.9653, Training-time: 5164.04
Epoch [6/10], Step [182/303], Loss: 7.9615, Training-time: 5167.09
Epoch [6/10], Step [183/303], Loss: 7.9577, Training-time: 5170.13
Epoch [6/10], Step [184/303], Loss: 7.9567, Training-time: 5173.18
Epoch [6/10], Step [185/303], Loss: 7.9533, Training-time: 5176.22
Epoch [6/10], Step [186/303], Loss: 7.9494, Training-time: 5179.27
Epoch [6/10], Step [187/303], Loss: 7.9661, Training-time: 5182.31
Epoch [6/10], Step [188/303], Loss: 7.9624, Training-time: 5185.37
Epoch [6/10], Step [189/303], Loss: 7.9585, Training-time: 5188.43
Epoch [6/10], Step [190/303], Loss: 7.9549, Training-time: 5191.48
Epoch [6/10], Step [191/303], Loss: 7.9511, Training-time: 5194.53
Epoch [6/10], Step [192/303], Loss: 7.9476, Training-time: 5197.59
Epoch [6/10], Step [193/303], Loss: 7.9436, Training-time: 5200.65
Epoch [6/10], Step [194/303], Loss: 7.9408, Training-time: 5203.70
Epoch [6/10], Step [195/303], Loss: 7.9378, Training-time: 5206.74
Epoch [6/10], Step [196/303], Loss: 7.9357, Training-time: 5209.78
Epoch [6/10], Step [197/303], Loss: 7.9332, Training-time: 5212.83
Epoch [6/10], Step [198/303], Loss: 7.9343, Training-time: 5215.87
Epoch [6/10], Step [199/303], Loss: 8.4274, Training-time: 5218.93
Epoch [6/10], Step [200/303], Loss: 8.4234, Training-time: 5221.99
Epoch [6/10], Step [201/303], Loss: 8.4201, Training-time: 5225.04
Epoch [6/10], Step [202/303], Loss: 8.4174, Training-time: 5228.09
Epoch [6/10], Step [203/303], Loss: 8.4138, Training-time: 5231.14
Epoch [6/10], Step [204/303], Loss: 8.4149, Training-time: 5234.19
Epoch [6/10], Step [205/303], Loss: 8.4122, Training-time: 5237.23
Epoch [6/10], Step [206/303], Loss: 8.4092, Training-time: 5240.28
Epoch [6/10], Step [207/303], Loss: 8.4064, Training-time: 5243.34
Epoch [6/10], Step [208/303], Loss: 8.4036, Training-time: 5246.38
Epoch [6/10], Step [209/303], Loss: 8.4011, Training-time: 5249.44
Epoch [6/10], Step [210/303], Loss: 8.4021, Training-time: 5252.51
Epoch [6/10], Step [211/303], Loss: 8.3996, Training-time: 5255.56
Epoch [6/10], Step [212/303], Loss: 8.3974, Training-time: 5258.63
Epoch [6/10], Step [213/303], Loss: 8.3941, Training-time: 5261.68
Epoch [6/10], Step [214/303], Loss: 8.3908, Training-time: 5264.73
Epoch [6/10], Step [215/303], Loss: 8.3871, Training-time: 5267.78
Epoch [6/10], Step [216/303], Loss: 8.3832, Training-time: 5270.84
Epoch [6/10], Step [217/303], Loss: 8.3800, Training-time: 5273.89
Epoch [6/10], Step [218/303], Loss: 8.3763, Training-time: 5276.94
Epoch [6/10], Step [219/303], Loss: 8.3847, Training-time: 5279.99
Epoch [6/10], Step [220/303], Loss: 8.3869, Training-time: 5283.04
Epoch [6/10], Step [221/303], Loss: 8.3862, Training-time: 5286.09
Epoch [6/10], Step [222/303], Loss: 8.3824, Training-time: 5289.13
Epoch [6/10], Step [223/303], Loss: 8.3788, Training-time: 5292.19
Epoch [6/10], Step [224/303], Loss: 8.3746, Training-time: 5295.26
Epoch [6/10], Step [225/303], Loss: 8.3706, Training-time: 5298.30
Epoch [6/10], Step [226/303], Loss: 8.3663, Training-time: 5301.35
Epoch [6/10], Step [227/303], Loss: 8.3630, Training-time: 5304.40
Epoch [6/10], Step [228/303], Loss: 8.3589, Training-time: 5307.45
Epoch [6/10], Step [229/303], Loss: 8.3577, Training-time: 5310.51
Epoch [6/10], Step [230/303], Loss: 8.3727, Training-time: 5313.56
Epoch [6/10], Step [231/303], Loss: 8.3685, Training-time: 5316.61
Epoch [6/10], Step [232/303], Loss: 8.3647, Training-time: 5319.66
Epoch [6/10], Step [233/303], Loss: 8.3615, Training-time: 5322.71
Epoch [6/10], Step [234/303], Loss: 8.3579, Training-time: 5325.76
Epoch [6/10], Step [235/303], Loss: 8.3543, Training-time: 5328.82
Epoch [6/10], Step [236/303], Loss: 8.3502, Training-time: 5331.88
Epoch [6/10], Step [237/303], Loss: 8.3466, Training-time: 5334.93
Epoch [6/10], Step [238/303], Loss: 8.3428, Training-time: 5337.99
Epoch [6/10], Step [239/303], Loss: 8.3395, Training-time: 5341.05
Epoch [6/10], Step [240/303], Loss: 8.3370, Training-time: 5344.10
Epoch [6/10], Step [241/303], Loss: 8.3326, Training-time: 5347.15
Epoch [6/10], Step [242/303], Loss: 8.3298, Training-time: 5350.19
Epoch [6/10], Step [243/303], Loss: 8.3260, Training-time: 5353.25
Epoch [6/10], Step [244/303], Loss: 8.3218, Training-time: 5356.30
Epoch [6/10], Step [245/303], Loss: 8.3176, Training-time: 5359.36
Epoch [6/10], Step [246/303], Loss: 8.3137, Training-time: 5362.41
Epoch [6/10], Step [247/303], Loss: 8.3110, Training-time: 5365.46
Epoch [6/10], Step [248/303], Loss: 8.3079, Training-time: 5368.53
Epoch [6/10], Step [249/303], Loss: 8.3036, Training-time: 5371.58
Epoch [6/10], Step [250/303], Loss: 8.2992, Training-time: 5374.64
Epoch [6/10], Step [251/303], Loss: 8.2960, Training-time: 5377.69
Epoch [6/10], Step [252/303], Loss: 8.2928, Training-time: 5380.76
Epoch [6/10], Step [253/303], Loss: 8.2895, Training-time: 5383.82
Epoch [6/10], Step [254/303], Loss: 8.2865, Training-time: 5386.87
Epoch [6/10], Step [255/303], Loss: 8.2827, Training-time: 5389.92
Epoch [6/10], Step [256/303], Loss: 8.2795, Training-time: 5392.97
Epoch [6/10], Step [257/303], Loss: 8.2763, Training-time: 5396.02
Epoch [6/10], Step [258/303], Loss: 8.2748, Training-time: 5399.09
Epoch [6/10], Step [259/303], Loss: 8.2737, Training-time: 5402.15
Epoch [6/10], Step [260/303], Loss: 8.2697, Training-time: 5405.19
Epoch [6/10], Step [261/303], Loss: 8.2656, Training-time: 5408.24
Epoch [6/10], Step [262/303], Loss: 8.2623, Training-time: 5411.29
Epoch [6/10], Step [263/303], Loss: 8.2592, Training-time: 5414.35
Epoch [6/10], Step [264/303], Loss: 8.2565, Training-time: 5417.41
Epoch [6/10], Step [265/303], Loss: 8.2532, Training-time: 5420.46
Epoch [6/10], Step [266/303], Loss: 8.2493, Training-time: 5423.50
Epoch [6/10], Step [267/303], Loss: 8.2454, Training-time: 5426.56
Epoch [6/10], Step [268/303], Loss: 8.2432, Training-time: 5429.61
Epoch [6/10], Step [269/303], Loss: 8.2397, Training-time: 5432.67
Epoch [6/10], Step [270/303], Loss: 8.2355, Training-time: 5435.73
Epoch [6/10], Step [271/303], Loss: 8.2316, Training-time: 5438.77
Epoch [6/10], Step [272/303], Loss: 8.2278, Training-time: 5441.82
Epoch [6/10], Step [273/303], Loss: 8.2244, Training-time: 5444.87
Epoch [6/10], Step [274/303], Loss: 8.2208, Training-time: 5447.93
Epoch [6/10], Step [275/303], Loss: 8.2173, Training-time: 5450.99
Epoch [6/10], Step [276/303], Loss: 8.2131, Training-time: 5454.04
Epoch [6/10], Step [277/303], Loss: 8.2116, Training-time: 5457.09
Epoch [6/10], Step [278/303], Loss: 8.2092, Training-time: 5460.13
Epoch [6/10], Step [279/303], Loss: 8.2065, Training-time: 5463.19
Epoch [6/10], Step [280/303], Loss: 8.2064, Training-time: 5466.24
Epoch [6/10], Step [281/303], Loss: 8.2025, Training-time: 5469.29
Epoch [6/10], Step [282/303], Loss: 8.1992, Training-time: 5472.34
Epoch [6/10], Step [283/303], Loss: 8.1964, Training-time: 5475.38
Epoch [6/10], Step [284/303], Loss: 8.1936, Training-time: 5478.43
Epoch [6/10], Step [285/303], Loss: 8.1897, Training-time: 5481.48
Epoch [6/10], Step [286/303], Loss: 8.1858, Training-time: 5484.53
Epoch [6/10], Step [287/303], Loss: 8.1817, Training-time: 5487.58
Epoch [6/10], Step [288/303], Loss: 8.1790, Training-time: 5490.63
Epoch [6/10], Step [289/303], Loss: 8.1749, Training-time: 5493.68
Epoch [6/10], Step [290/303], Loss: 8.1718, Training-time: 5496.73
Epoch [6/10], Step [291/303], Loss: 8.1683, Training-time: 5499.77
Epoch [6/10], Step [292/303], Loss: 8.2189, Training-time: 5502.83
Epoch [6/10], Step [293/303], Loss: 8.2171, Training-time: 5505.88
Epoch [6/10], Step [294/303], Loss: 8.2154, Training-time: 5508.93
Epoch [6/10], Step [295/303], Loss: 8.2120, Training-time: 5511.98
Epoch [6/10], Step [296/303], Loss: 8.2081, Training-time: 5515.03
Epoch [6/10], Step [297/303], Loss: 8.2077, Training-time: 5518.08
Epoch [6/10], Step [298/303], Loss: 8.2074, Training-time: 5521.10
Epoch [6/10], Step [299/303], Loss: 8.2037, Training-time: 5524.12
Epoch [6/10], Step [300/303], Loss: 8.2105, Training-time: 5527.14
Epoch [6/10], Step [301/303], Loss: 8.2071, Training-time: 5530.17
Epoch [6/10], Step [302/303], Loss: 8.2034, Training-time: 5533.19
Epoch [6/10], Step [303/303], Loss: 8.1999, Training-time: 5533.83
Epoch [7/10], Step [1/303], Loss: 8.1959, Training-time: 5537.21
Epoch [7/10], Step [2/303], Loss: 8.1920, Training-time: 5540.27
Epoch [7/10], Step [3/303], Loss: 8.1883, Training-time: 5543.32
Epoch [7/10], Step [4/303], Loss: 8.1853, Training-time: 5546.37
Epoch [7/10], Step [5/303], Loss: 8.1813, Training-time: 5549.41
Epoch [7/10], Step [6/303], Loss: 8.1965, Training-time: 5552.46
Epoch [7/10], Step [7/303], Loss: 8.1925, Training-time: 5555.51
Epoch [7/10], Step [8/303], Loss: 8.1889, Training-time: 5558.56
Epoch [7/10], Step [9/303], Loss: 8.1897, Training-time: 5561.61
Epoch [7/10], Step [10/303], Loss: 8.2637, Training-time: 5564.65
Epoch [7/10], Step [11/303], Loss: 8.2610, Training-time: 5567.69
Epoch [7/10], Step [12/303], Loss: 8.2582, Training-time: 5570.76
Epoch [7/10], Step [13/303], Loss: 8.2574, Training-time: 5573.81
Epoch [7/10], Step [14/303], Loss: 8.2534, Training-time: 5576.85
Epoch [7/10], Step [15/303], Loss: 8.2503, Training-time: 5579.89
Epoch [7/10], Step [16/303], Loss: 8.2468, Training-time: 5582.94
Epoch [7/10], Step [17/303], Loss: 8.2428, Training-time: 5585.97
Epoch [7/10], Step [18/303], Loss: 8.2392, Training-time: 5589.02
Epoch [7/10], Step [19/303], Loss: 8.2367, Training-time: 5592.07
Epoch [7/10], Step [20/303], Loss: 8.2333, Training-time: 5595.12
Epoch [7/10], Step [21/303], Loss: 8.2326, Training-time: 5598.17
Epoch [7/10], Step [22/303], Loss: 8.2288, Training-time: 5601.21
Epoch [7/10], Step [23/303], Loss: 8.2256, Training-time: 5604.24
Epoch [7/10], Step [24/303], Loss: 8.2219, Training-time: 5607.29
Epoch [7/10], Step [25/303], Loss: 8.2181, Training-time: 5610.33
Epoch [7/10], Step [26/303], Loss: 8.2141, Training-time: 5613.39
Epoch [7/10], Step [27/303], Loss: 8.2100, Training-time: 5616.44
Epoch [7/10], Step [28/303], Loss: 8.2282, Training-time: 5619.50
Epoch [7/10], Step [29/303], Loss: 8.2252, Training-time: 5622.56
Epoch [7/10], Step [30/303], Loss: 8.2215, Training-time: 5625.61
Epoch [7/10], Step [31/303], Loss: 8.2183, Training-time: 5628.66
Epoch [7/10], Step [32/303], Loss: 8.2168, Training-time: 5631.71
Epoch [7/10], Step [33/303], Loss: 8.2186, Training-time: 5634.77
Epoch [7/10], Step [34/303], Loss: 8.2157, Training-time: 5637.82
Epoch [7/10], Step [35/303], Loss: 8.2127, Training-time: 5640.87
Epoch [7/10], Step [36/303], Loss: 8.2090, Training-time: 5643.93
Epoch [7/10], Step [37/303], Loss: 8.2055, Training-time: 5646.97
Epoch [7/10], Step [38/303], Loss: 8.2843, Training-time: 5650.02
Epoch [7/10], Step [39/303], Loss: 8.2808, Training-time: 5653.07
Epoch [7/10], Step [40/303], Loss: 8.2794, Training-time: 5656.12
Epoch [7/10], Step [41/303], Loss: 8.2759, Training-time: 5659.16
Epoch [7/10], Step [42/303], Loss: 8.2748, Training-time: 5662.21
Epoch [7/10], Step [43/303], Loss: 8.2711, Training-time: 5665.26
Epoch [7/10], Step [44/303], Loss: 8.2672, Training-time: 5668.31
Epoch [7/10], Step [45/303], Loss: 8.2703, Training-time: 5671.37
Epoch [7/10], Step [46/303], Loss: 8.2670, Training-time: 5674.42
Epoch [7/10], Step [47/303], Loss: 8.2644, Training-time: 5677.47
Epoch [7/10], Step [48/303], Loss: 8.3056, Training-time: 5680.52
Epoch [7/10], Step [49/303], Loss: 8.3025, Training-time: 5683.57
Epoch [7/10], Step [50/303], Loss: 8.3002, Training-time: 5686.62
Epoch [7/10], Step [51/303], Loss: 8.2976, Training-time: 5689.66
Epoch [7/10], Step [52/303], Loss: 8.2937, Training-time: 5692.71
Epoch [7/10], Step [53/303], Loss: 8.2900, Training-time: 5695.75
Epoch [7/10], Step [54/303], Loss: 8.2932, Training-time: 5698.80
Epoch [7/10], Step [55/303], Loss: 8.2904, Training-time: 5701.84
Epoch [7/10], Step [56/303], Loss: 8.2890, Training-time: 5704.91
Epoch [7/10], Step [57/303], Loss: 8.2854, Training-time: 5707.96
Epoch [7/10], Step [58/303], Loss: 8.2834, Training-time: 5711.02
Epoch [7/10], Step [59/303], Loss: 8.2795, Training-time: 5714.07
Epoch [7/10], Step [60/303], Loss: 8.2756, Training-time: 5717.11
Epoch [7/10], Step [61/303], Loss: 8.2725, Training-time: 5720.16
Epoch [7/10], Step [62/303], Loss: 8.2697, Training-time: 5723.20
Epoch [7/10], Step [63/303], Loss: 8.2661, Training-time: 5726.24
Epoch [7/10], Step [64/303], Loss: 8.2638, Training-time: 5729.29
Epoch [7/10], Step [65/303], Loss: 8.2611, Training-time: 5732.33
Epoch [7/10], Step [66/303], Loss: 8.2572, Training-time: 5735.37
Epoch [7/10], Step [67/303], Loss: 8.2538, Training-time: 5738.41
Epoch [7/10], Step [68/303], Loss: 8.2503, Training-time: 5741.48
Epoch [7/10], Step [69/303], Loss: 8.2467, Training-time: 5744.53
Epoch [7/10], Step [70/303], Loss: 8.2426, Training-time: 5747.58
Epoch [7/10], Step [71/303], Loss: 8.2393, Training-time: 5750.63
Epoch [7/10], Step [72/303], Loss: 8.2363, Training-time: 5753.69
Epoch [7/10], Step [73/303], Loss: 8.2323, Training-time: 5756.73
Epoch [7/10], Step [74/303], Loss: 8.2317, Training-time: 5759.78
Epoch [7/10], Step [75/303], Loss: 8.2277, Training-time: 5762.84
Epoch [7/10], Step [76/303], Loss: 8.2238, Training-time: 5765.89
Epoch [7/10], Step [77/303], Loss: 8.2200, Training-time: 5768.94
Epoch [7/10], Step [78/303], Loss: 8.2336, Training-time: 5771.99
Epoch [7/10], Step [79/303], Loss: 8.2301, Training-time: 5775.04
Epoch [7/10], Step [80/303], Loss: 8.2320, Training-time: 5778.09
Epoch [7/10], Step [81/303], Loss: 8.2286, Training-time: 5781.14
Epoch [7/10], Step [82/303], Loss: 8.2255, Training-time: 5784.18
Epoch [7/10], Step [83/303], Loss: 8.2240, Training-time: 5787.24
Epoch [7/10], Step [84/303], Loss: 8.2204, Training-time: 5790.30
Epoch [7/10], Step [85/303], Loss: 8.2170, Training-time: 5793.36
Epoch [7/10], Step [86/303], Loss: 8.2133, Training-time: 5796.41
Epoch [7/10], Step [87/303], Loss: 8.2096, Training-time: 5799.47
Epoch [7/10], Step [88/303], Loss: 8.2060, Training-time: 5802.52
Epoch [7/10], Step [89/303], Loss: 8.2027, Training-time: 5805.57
Epoch [7/10], Step [90/303], Loss: 8.2008, Training-time: 5808.63
Epoch [7/10], Step [91/303], Loss: 8.1976, Training-time: 5811.67
Epoch [7/10], Step [92/303], Loss: 8.1941, Training-time: 5814.72
Epoch [7/10], Step [93/303], Loss: 8.1909, Training-time: 5817.77
Epoch [7/10], Step [94/303], Loss: 8.1869, Training-time: 5820.82
Epoch [7/10], Step [95/303], Loss: 8.1833, Training-time: 5823.88
Epoch [7/10], Step [96/303], Loss: 8.1793, Training-time: 5826.94
Epoch [7/10], Step [97/303], Loss: 8.1774, Training-time: 5829.99
Epoch [7/10], Step [98/303], Loss: 8.1744, Training-time: 5833.03
Epoch [7/10], Step [99/303], Loss: 8.1790, Training-time: 5836.08
Epoch [7/10], Step [100/303], Loss: 8.1759, Training-time: 5839.13
Epoch [7/10], Step [101/303], Loss: 8.1727, Training-time: 5842.19
Epoch [7/10], Step [102/303], Loss: 8.1693, Training-time: 5845.23
Epoch [7/10], Step [103/303], Loss: 8.1654, Training-time: 5848.28
Epoch [7/10], Step [104/303], Loss: 8.1619, Training-time: 5851.32
Epoch [7/10], Step [105/303], Loss: 8.1583, Training-time: 5854.37
Epoch [7/10], Step [106/303], Loss: 8.1554, Training-time: 5857.43
Epoch [7/10], Step [107/303], Loss: 8.1518, Training-time: 5860.46
Epoch [7/10], Step [108/303], Loss: 8.1484, Training-time: 5863.50
Epoch [7/10], Step [109/303], Loss: 8.1459, Training-time: 5866.54
Epoch [7/10], Step [110/303], Loss: 8.1427, Training-time: 5869.59
Epoch [7/10], Step [111/303], Loss: 8.1396, Training-time: 5872.65
Epoch [7/10], Step [112/303], Loss: 8.1392, Training-time: 5875.69
Epoch [7/10], Step [113/303], Loss: 8.1354, Training-time: 5878.74
Epoch [7/10], Step [114/303], Loss: 8.1348, Training-time: 5881.79
Epoch [7/10], Step [115/303], Loss: 8.1379, Training-time: 5884.84
Epoch [7/10], Step [116/303], Loss: 8.1343, Training-time: 5887.90
Epoch [7/10], Step [117/303], Loss: 8.1488, Training-time: 5890.94
Epoch [7/10], Step [118/303], Loss: 8.1457, Training-time: 5893.99
Epoch [7/10], Step [119/303], Loss: 8.1422, Training-time: 5897.04
Epoch [7/10], Step [120/303], Loss: 8.1392, Training-time: 5900.09
Epoch [7/10], Step [121/303], Loss: 8.1360, Training-time: 5903.14
Epoch [7/10], Step [122/303], Loss: 8.1327, Training-time: 5906.18
Epoch [7/10], Step [123/303], Loss: 8.1298, Training-time: 5909.23
Epoch [7/10], Step [124/303], Loss: 8.1270, Training-time: 5912.28
Epoch [7/10], Step [125/303], Loss: 8.1241, Training-time: 5915.33
Epoch [7/10], Step [126/303], Loss: 8.1209, Training-time: 5918.39
Epoch [7/10], Step [127/303], Loss: 8.1175, Training-time: 5921.44
Epoch [7/10], Step [128/303], Loss: 8.1154, Training-time: 5924.48
Epoch [7/10], Step [129/303], Loss: 8.1121, Training-time: 5927.53
Epoch [7/10], Step [130/303], Loss: 8.1085, Training-time: 5930.57
Epoch [7/10], Step [131/303], Loss: 8.1065, Training-time: 5933.62
Epoch [7/10], Step [132/303], Loss: 8.1060, Training-time: 5936.67
Epoch [7/10], Step [133/303], Loss: 8.1032, Training-time: 5939.72
Epoch [7/10], Step [134/303], Loss: 8.1005, Training-time: 5942.78
Epoch [7/10], Step [135/303], Loss: 8.0971, Training-time: 5945.83
Epoch [7/10], Step [136/303], Loss: 8.0959, Training-time: 5948.88
Epoch [7/10], Step [137/303], Loss: 8.0977, Training-time: 5951.93
Epoch [7/10], Step [138/303], Loss: 8.0943, Training-time: 5954.97
Epoch [7/10], Step [139/303], Loss: 8.0916, Training-time: 5958.02
Epoch [7/10], Step [140/303], Loss: 8.0881, Training-time: 5961.08
Epoch [7/10], Step [141/303], Loss: 8.0846, Training-time: 5964.13
Epoch [7/10], Step [142/303], Loss: 8.0807, Training-time: 5967.18
Epoch [7/10], Step [143/303], Loss: 8.0789, Training-time: 5970.23
Epoch [7/10], Step [144/303], Loss: 8.0765, Training-time: 5973.28
Epoch [7/10], Step [145/303], Loss: 8.0737, Training-time: 5976.33
Epoch [7/10], Step [146/303], Loss: 8.0713, Training-time: 5979.37
Epoch [7/10], Step [147/303], Loss: 8.0726, Training-time: 5982.42
Epoch [7/10], Step [148/303], Loss: 8.1030, Training-time: 5985.47
Epoch [7/10], Step [149/303], Loss: 8.1001, Training-time: 5988.50
Epoch [7/10], Step [150/303], Loss: 8.0982, Training-time: 5991.55
Epoch [7/10], Step [151/303], Loss: 8.0949, Training-time: 5994.59
Epoch [7/10], Step [152/303], Loss: 8.0932, Training-time: 5997.63
Epoch [7/10], Step [153/303], Loss: 8.0911, Training-time: 6000.67
Epoch [7/10], Step [154/303], Loss: 8.0884, Training-time: 6003.72
Epoch [7/10], Step [155/303], Loss: 8.0850, Training-time: 6006.78
Epoch [7/10], Step [156/303], Loss: 8.0823, Training-time: 6009.82
Epoch [7/10], Step [157/303], Loss: 8.0788, Training-time: 6012.87
Epoch [7/10], Step [158/303], Loss: 8.0751, Training-time: 6015.93
Epoch [7/10], Step [159/303], Loss: 8.0729, Training-time: 6018.99
Epoch [7/10], Step [160/303], Loss: 8.0696, Training-time: 6022.04
Epoch [7/10], Step [161/303], Loss: 8.0664, Training-time: 6025.10
Epoch [7/10], Step [162/303], Loss: 8.0628, Training-time: 6028.16
Epoch [7/10], Step [163/303], Loss: 8.0599, Training-time: 6031.21
Epoch [7/10], Step [164/303], Loss: 8.0568, Training-time: 6034.27
Epoch [7/10], Step [165/303], Loss: 8.0535, Training-time: 6037.31
Epoch [7/10], Step [166/303], Loss: 8.0499, Training-time: 6040.36
Epoch [7/10], Step [167/303], Loss: 8.0468, Training-time: 6043.42
Epoch [7/10], Step [168/303], Loss: 8.0432, Training-time: 6046.46
Epoch [7/10], Step [169/303], Loss: 8.0400, Training-time: 6049.52
Epoch [7/10], Step [170/303], Loss: 8.0363, Training-time: 6052.58
Epoch [7/10], Step [171/303], Loss: 8.0390, Training-time: 6055.63
Epoch [7/10], Step [172/303], Loss: 8.0387, Training-time: 6058.70
Epoch [7/10], Step [173/303], Loss: 8.0381, Training-time: 6061.76
Epoch [7/10], Step [174/303], Loss: 8.0346, Training-time: 6064.80
Epoch [7/10], Step [175/303], Loss: 8.0310, Training-time: 6067.84
Epoch [7/10], Step [176/303], Loss: 8.0273, Training-time: 6070.89
Epoch [7/10], Step [177/303], Loss: 8.0241, Training-time: 6073.95
Epoch [7/10], Step [178/303], Loss: 8.0209, Training-time: 6077.01
Epoch [7/10], Step [179/303], Loss: 8.0217, Training-time: 6080.05
Epoch [7/10], Step [180/303], Loss: 8.0181, Training-time: 6083.11
Epoch [7/10], Step [181/303], Loss: 8.0155, Training-time: 6086.17
Epoch [7/10], Step [182/303], Loss: 8.0139, Training-time: 6089.22
Epoch [7/10], Step [183/303], Loss: 8.0108, Training-time: 6092.27
Epoch [7/10], Step [184/303], Loss: 8.0175, Training-time: 6095.32
Epoch [7/10], Step [185/303], Loss: 8.0139, Training-time: 6098.37
Epoch [7/10], Step [186/303], Loss: 8.0107, Training-time: 6101.43
Epoch [7/10], Step [187/303], Loss: 8.0117, Training-time: 6104.48
Epoch [7/10], Step [188/303], Loss: 8.0080, Training-time: 6107.53
Epoch [7/10], Step [189/303], Loss: 8.0121, Training-time: 6110.57
Epoch [7/10], Step [190/303], Loss: 8.0119, Training-time: 6113.62
Epoch [7/10], Step [191/303], Loss: 8.0091, Training-time: 6116.67
Epoch [7/10], Step [192/303], Loss: 8.0060, Training-time: 6119.72
Epoch [7/10], Step [193/303], Loss: 8.0031, Training-time: 6122.78
Epoch [7/10], Step [194/303], Loss: 7.9999, Training-time: 6125.83
Epoch [7/10], Step [195/303], Loss: 7.9968, Training-time: 6128.88
Epoch [7/10], Step [196/303], Loss: 7.9942, Training-time: 6131.92
Epoch [7/10], Step [197/303], Loss: 7.9905, Training-time: 6134.98
Epoch [7/10], Step [198/303], Loss: 7.9901, Training-time: 6138.04
Epoch [7/10], Step [199/303], Loss: 7.9893, Training-time: 6141.08
Epoch [7/10], Step [200/303], Loss: 7.9862, Training-time: 6144.13
Epoch [7/10], Step [201/303], Loss: 7.9890, Training-time: 6147.19
Epoch [7/10], Step [202/303], Loss: 7.9860, Training-time: 6150.23
Epoch [7/10], Step [203/303], Loss: 7.9836, Training-time: 6153.28
Epoch [7/10], Step [204/303], Loss: 7.9811, Training-time: 6156.32
Epoch [7/10], Step [205/303], Loss: 7.9791, Training-time: 6159.37
Epoch [7/10], Step [206/303], Loss: 7.9901, Training-time: 6162.42
Epoch [7/10], Step [207/303], Loss: 7.9872, Training-time: 6165.47
Epoch [7/10], Step [208/303], Loss: 8.4241, Training-time: 6168.52
Epoch [7/10], Step [209/303], Loss: 8.4206, Training-time: 6171.56
Epoch [7/10], Step [210/303], Loss: 8.4179, Training-time: 6174.62
Epoch [7/10], Step [211/303], Loss: 8.4160, Training-time: 6177.68
Epoch [7/10], Step [212/303], Loss: 8.4129, Training-time: 6180.73
Epoch [7/10], Step [213/303], Loss: 8.4097, Training-time: 6183.78
Epoch [7/10], Step [214/303], Loss: 8.4065, Training-time: 6186.84
Epoch [7/10], Step [215/303], Loss: 8.4038, Training-time: 6189.89
Epoch [7/10], Step [216/303], Loss: 8.4006, Training-time: 6192.94
Epoch [7/10], Step [217/303], Loss: 8.3987, Training-time: 6196.00
Epoch [7/10], Step [218/303], Loss: 8.3966, Training-time: 6199.05
Epoch [7/10], Step [219/303], Loss: 8.3934, Training-time: 6202.11
Epoch [7/10], Step [220/303], Loss: 8.3904, Training-time: 6205.15
Epoch [7/10], Step [221/303], Loss: 8.3883, Training-time: 6208.19
Epoch [7/10], Step [222/303], Loss: 8.3864, Training-time: 6211.25
Epoch [7/10], Step [223/303], Loss: 8.3847, Training-time: 6214.30
Epoch [7/10], Step [224/303], Loss: 8.3812, Training-time: 6217.34
Epoch [7/10], Step [225/303], Loss: 8.3778, Training-time: 6220.39
Epoch [7/10], Step [226/303], Loss: 8.3759, Training-time: 6223.44
Epoch [7/10], Step [227/303], Loss: 8.3753, Training-time: 6226.49
Epoch [7/10], Step [228/303], Loss: 8.3715, Training-time: 6229.53
Epoch [7/10], Step [229/303], Loss: 8.3682, Training-time: 6232.57
Epoch [7/10], Step [230/303], Loss: 8.3645, Training-time: 6235.62
Epoch [7/10], Step [231/303], Loss: 8.3648, Training-time: 6238.67
Epoch [7/10], Step [232/303], Loss: 8.3618, Training-time: 6241.73
Epoch [7/10], Step [233/303], Loss: 8.3580, Training-time: 6244.78
Epoch [7/10], Step [234/303], Loss: 8.3557, Training-time: 6247.83
Epoch [7/10], Step [235/303], Loss: 8.3520, Training-time: 6250.89
Epoch [7/10], Step [236/303], Loss: 8.3484, Training-time: 6253.94
Epoch [7/10], Step [237/303], Loss: 8.3449, Training-time: 6256.99
Epoch [7/10], Step [238/303], Loss: 8.3414, Training-time: 6260.04
Epoch [7/10], Step [239/303], Loss: 8.3378, Training-time: 6263.09
Epoch [7/10], Step [240/303], Loss: 8.3343, Training-time: 6266.13
Epoch [7/10], Step [241/303], Loss: 8.3308, Training-time: 6269.18
Epoch [7/10], Step [242/303], Loss: 8.3320, Training-time: 6272.23
Epoch [7/10], Step [243/303], Loss: 8.3294, Training-time: 6275.28
Epoch [7/10], Step [244/303], Loss: 8.3290, Training-time: 6278.33
Epoch [7/10], Step [245/303], Loss: 8.3268, Training-time: 6281.38
Epoch [7/10], Step [246/303], Loss: 8.3263, Training-time: 6284.43
Epoch [7/10], Step [247/303], Loss: 8.3227, Training-time: 6287.48
Epoch [7/10], Step [248/303], Loss: 8.3191, Training-time: 6290.52
Epoch [7/10], Step [249/303], Loss: 8.3155, Training-time: 6293.57
Epoch [7/10], Step [250/303], Loss: 8.3126, Training-time: 6296.63
Epoch [7/10], Step [251/303], Loss: 8.3091, Training-time: 6299.68
Epoch [7/10], Step [252/303], Loss: 8.3066, Training-time: 6302.73
Epoch [7/10], Step [253/303], Loss: 8.3031, Training-time: 6305.78
Epoch [7/10], Step [254/303], Loss: 8.3004, Training-time: 6308.83
Epoch [7/10], Step [255/303], Loss: 8.2966, Training-time: 6311.87
Epoch [7/10], Step [256/303], Loss: 8.2955, Training-time: 6314.93
Epoch [7/10], Step [257/303], Loss: 8.2962, Training-time: 6317.98
Epoch [7/10], Step [258/303], Loss: 8.2957, Training-time: 6321.04
Epoch [7/10], Step [259/303], Loss: 8.2927, Training-time: 6324.09
Epoch [7/10], Step [260/303], Loss: 8.2891, Training-time: 6327.14
Epoch [7/10], Step [261/303], Loss: 8.2854, Training-time: 6330.19
Epoch [7/10], Step [262/303], Loss: 8.2830, Training-time: 6333.24
Epoch [7/10], Step [263/303], Loss: 8.2802, Training-time: 6336.28
Epoch [7/10], Step [264/303], Loss: 8.2770, Training-time: 6339.33
Epoch [7/10], Step [265/303], Loss: 8.2735, Training-time: 6342.38
Epoch [7/10], Step [266/303], Loss: 8.2711, Training-time: 6345.43
Epoch [7/10], Step [267/303], Loss: 8.2675, Training-time: 6348.48
Epoch [7/10], Step [268/303], Loss: 8.2659, Training-time: 6351.54
Epoch [7/10], Step [269/303], Loss: 8.2623, Training-time: 6354.60
Epoch [7/10], Step [270/303], Loss: 8.2609, Training-time: 6357.65
Epoch [7/10], Step [271/303], Loss: 8.2581, Training-time: 6360.70
Epoch [7/10], Step [272/303], Loss: 8.2620, Training-time: 6363.75
Epoch [7/10], Step [273/303], Loss: 8.2591, Training-time: 6366.80
Epoch [7/10], Step [274/303], Loss: 8.2560, Training-time: 6369.84
Epoch [7/10], Step [275/303], Loss: 8.2541, Training-time: 6372.89
Epoch [7/10], Step [276/303], Loss: 8.2533, Training-time: 6375.94
Epoch [7/10], Step [277/303], Loss: 8.2523, Training-time: 6378.99
Epoch [7/10], Step [278/303], Loss: 8.2489, Training-time: 6382.04
Epoch [7/10], Step [279/303], Loss: 8.2453, Training-time: 6385.09
Epoch [7/10], Step [280/303], Loss: 8.2418, Training-time: 6388.14
Epoch [7/10], Step [281/303], Loss: 8.2391, Training-time: 6391.19
Epoch [7/10], Step [282/303], Loss: 8.2359, Training-time: 6394.24
Epoch [7/10], Step [283/303], Loss: 8.2324, Training-time: 6397.29
Epoch [7/10], Step [284/303], Loss: 8.2290, Training-time: 6400.34
Epoch [7/10], Step [285/303], Loss: 8.2255, Training-time: 6403.39
Epoch [7/10], Step [286/303], Loss: 8.2252, Training-time: 6406.43
Epoch [7/10], Step [287/303], Loss: 8.2225, Training-time: 6409.48
Epoch [7/10], Step [288/303], Loss: 8.2193, Training-time: 6412.53
Epoch [7/10], Step [289/303], Loss: 8.2158, Training-time: 6415.58
Epoch [7/10], Step [290/303], Loss: 8.2133, Training-time: 6418.63
Epoch [7/10], Step [291/303], Loss: 8.2125, Training-time: 6421.68
Epoch [7/10], Step [292/303], Loss: 8.2092, Training-time: 6424.73
Epoch [7/10], Step [293/303], Loss: 8.2056, Training-time: 6427.77
Epoch [7/10], Step [294/303], Loss: 8.2042, Training-time: 6430.83
Epoch [7/10], Step [295/303], Loss: 8.2014, Training-time: 6433.88
Epoch [7/10], Step [296/303], Loss: 8.1985, Training-time: 6436.94
Epoch [7/10], Step [297/303], Loss: 8.1956, Training-time: 6439.98
Epoch [7/10], Step [298/303], Loss: 8.1927, Training-time: 6443.01
Epoch [7/10], Step [299/303], Loss: 8.1907, Training-time: 6446.03
Epoch [7/10], Step [300/303], Loss: 8.1873, Training-time: 6449.05
Epoch [7/10], Step [301/303], Loss: 8.1848, Training-time: 6452.07
Epoch [7/10], Step [302/303], Loss: 8.1814, Training-time: 6455.09
Epoch [7/10], Step [303/303], Loss: 8.1777, Training-time: 6455.72
Epoch [8/10], Step [1/303], Loss: 8.1760, Training-time: 6459.09
Epoch [8/10], Step [2/303], Loss: 8.1728, Training-time: 6462.14
Epoch [8/10], Step [3/303], Loss: 8.1693, Training-time: 6465.19
Epoch [8/10], Step [4/303], Loss: 8.1668, Training-time: 6468.25
Epoch [8/10], Step [5/303], Loss: 8.1646, Training-time: 6471.28
Epoch [8/10], Step [6/303], Loss: 8.1631, Training-time: 6474.33
Epoch [8/10], Step [7/303], Loss: 8.1601, Training-time: 6477.39
Epoch [8/10], Step [8/303], Loss: 8.1569, Training-time: 6480.44
Epoch [8/10], Step [9/303], Loss: 8.1534, Training-time: 6483.47
Epoch [8/10], Step [10/303], Loss: 8.1502, Training-time: 6486.52
Epoch [8/10], Step [11/303], Loss: 8.1470, Training-time: 6489.56
Epoch [8/10], Step [12/303], Loss: 8.1462, Training-time: 6492.60
Epoch [8/10], Step [13/303], Loss: 8.1429, Training-time: 6495.65
Epoch [8/10], Step [14/303], Loss: 8.1396, Training-time: 6498.69
Epoch [8/10], Step [15/303], Loss: 8.1390, Training-time: 6501.74
Epoch [8/10], Step [16/303], Loss: 8.1357, Training-time: 6504.79
Epoch [8/10], Step [17/303], Loss: 8.1326, Training-time: 6507.85
Epoch [8/10], Step [18/303], Loss: 8.1293, Training-time: 6510.90
Epoch [8/10], Step [19/303], Loss: 8.1260, Training-time: 6513.95
Epoch [8/10], Step [20/303], Loss: 8.1295, Training-time: 6517.00
Epoch [8/10], Step [21/303], Loss: 8.1262, Training-time: 6520.04
Epoch [8/10], Step [22/303], Loss: 8.1234, Training-time: 6523.08
Epoch [8/10], Step [23/303], Loss: 8.1208, Training-time: 6526.13
Epoch [8/10], Step [24/303], Loss: 8.1175, Training-time: 6529.18
Epoch [8/10], Step [25/303], Loss: 8.1201, Training-time: 6532.23
Epoch [8/10], Step [26/303], Loss: 8.1177, Training-time: 6535.28
Epoch [8/10], Step [27/303], Loss: 8.1150, Training-time: 6538.33
Epoch [8/10], Step [28/303], Loss: 8.1116, Training-time: 6541.38
Epoch [8/10], Step [29/303], Loss: 8.1718, Training-time: 6544.42
Epoch [8/10], Step [30/303], Loss: 8.1821, Training-time: 6547.47
Epoch [8/10], Step [31/303], Loss: 8.1799, Training-time: 6550.52
Epoch [8/10], Step [32/303], Loss: 8.1834, Training-time: 6553.57
Epoch [8/10], Step [33/303], Loss: 8.1804, Training-time: 6556.60
Epoch [8/10], Step [34/303], Loss: 8.1773, Training-time: 6559.66
Epoch [8/10], Step [35/303], Loss: 8.1767, Training-time: 6562.69
Epoch [8/10], Step [36/303], Loss: 8.1743, Training-time: 6565.74
Epoch [8/10], Step [37/303], Loss: 8.1714, Training-time: 6568.78
Epoch [8/10], Step [38/303], Loss: 8.1687, Training-time: 6571.82
Epoch [8/10], Step [39/303], Loss: 8.2107, Training-time: 6574.87
Epoch [8/10], Step [40/303], Loss: 8.2232, Training-time: 6577.92
Epoch [8/10], Step [41/303], Loss: 8.2206, Training-time: 6580.97
Epoch [8/10], Step [42/303], Loss: 8.2181, Training-time: 6584.02
Epoch [8/10], Step [43/303], Loss: 8.2174, Training-time: 6587.08
Epoch [8/10], Step [44/303], Loss: 8.2145, Training-time: 6590.13
Epoch [8/10], Step [45/303], Loss: 8.2115, Training-time: 6593.17
Epoch [8/10], Step [46/303], Loss: 8.2086, Training-time: 6596.23
Epoch [8/10], Step [47/303], Loss: 8.2053, Training-time: 6599.29
Epoch [8/10], Step [48/303], Loss: 8.2033, Training-time: 6602.41
Epoch [8/10], Step [49/303], Loss: 8.2012, Training-time: 6605.45
Epoch [8/10], Step [50/303], Loss: 8.1983, Training-time: 6608.50
Epoch [8/10], Step [51/303], Loss: 8.1950, Training-time: 6611.57
Epoch [8/10], Step [52/303], Loss: 8.1916, Training-time: 6614.62
Epoch [8/10], Step [53/303], Loss: 8.1883, Training-time: 6617.66
Epoch [8/10], Step [54/303], Loss: 8.1852, Training-time: 6620.71
Epoch [8/10], Step [55/303], Loss: 8.1819, Training-time: 6623.75
Epoch [8/10], Step [56/303], Loss: 8.1785, Training-time: 6626.79
Epoch [8/10], Step [57/303], Loss: 8.1770, Training-time: 6629.83
Epoch [8/10], Step [58/303], Loss: 8.1737, Training-time: 6632.89
Epoch [8/10], Step [59/303], Loss: 8.1709, Training-time: 6635.93
Epoch [8/10], Step [60/303], Loss: 8.1727, Training-time: 6638.99
Epoch [8/10], Step [61/303], Loss: 8.1697, Training-time: 6642.04
Epoch [8/10], Step [62/303], Loss: 8.1668, Training-time: 6645.09
Epoch [8/10], Step [63/303], Loss: 8.1644, Training-time: 6648.15
Epoch [8/10], Step [64/303], Loss: 8.1614, Training-time: 6651.20
Epoch [8/10], Step [65/303], Loss: 8.1584, Training-time: 6654.25
Epoch [8/10], Step [66/303], Loss: 8.1582, Training-time: 6657.31
Epoch [8/10], Step [67/303], Loss: 8.1651, Training-time: 6660.35
Epoch [8/10], Step [68/303], Loss: 8.1665, Training-time: 6663.40
Epoch [8/10], Step [69/303], Loss: 8.1638, Training-time: 6666.45
Epoch [8/10], Step [70/303], Loss: 8.1608, Training-time: 6669.50
Epoch [8/10], Step [71/303], Loss: 8.1577, Training-time: 6672.54
Epoch [8/10], Step [72/303], Loss: 8.1546, Training-time: 6675.59
Epoch [8/10], Step [73/303], Loss: 8.1515, Training-time: 6678.64
Epoch [8/10], Step [74/303], Loss: 8.1494, Training-time: 6681.69
Epoch [8/10], Step [75/303], Loss: 8.1467, Training-time: 6684.74
Epoch [8/10], Step [76/303], Loss: 8.1435, Training-time: 6687.79
Epoch [8/10], Step [77/303], Loss: 8.1406, Training-time: 6690.83
Epoch [8/10], Step [78/303], Loss: 8.1387, Training-time: 6693.89
Epoch [8/10], Step [79/303], Loss: 8.1380, Training-time: 6696.94
Epoch [8/10], Step [80/303], Loss: 8.1354, Training-time: 6699.99
Epoch [8/10], Step [81/303], Loss: 8.1339, Training-time: 6703.04
Epoch [8/10], Step [82/303], Loss: 8.1305, Training-time: 6706.10
Epoch [8/10], Step [83/303], Loss: 8.1338, Training-time: 6709.15
Epoch [8/10], Step [84/303], Loss: 8.1306, Training-time: 6712.21
Epoch [8/10], Step [85/303], Loss: 8.1274, Training-time: 6715.25
Epoch [8/10], Step [86/303], Loss: 8.1247, Training-time: 6718.29
Epoch [8/10], Step [87/303], Loss: 8.1224, Training-time: 6721.34
Epoch [8/10], Step [88/303], Loss: 8.1194, Training-time: 6724.39
Epoch [8/10], Step [89/303], Loss: 8.1162, Training-time: 6727.44
Epoch [8/10], Step [90/303], Loss: 8.1130, Training-time: 6730.48
Epoch [8/10], Step [91/303], Loss: 8.1116, Training-time: 6733.53
Epoch [8/10], Step [92/303], Loss: 8.1094, Training-time: 6736.58
Epoch [8/10], Step [93/303], Loss: 8.1072, Training-time: 6739.62
Epoch [8/10], Step [94/303], Loss: 8.1046, Training-time: 6742.68
Epoch [8/10], Step [95/303], Loss: 8.1015, Training-time: 6745.73
Epoch [8/10], Step [96/303], Loss: 8.0987, Training-time: 6748.78
Epoch [8/10], Step [97/303], Loss: 8.0954, Training-time: 6751.84
Epoch [8/10], Step [98/303], Loss: 8.0922, Training-time: 6754.90
Epoch [8/10], Step [99/303], Loss: 8.0891, Training-time: 6757.94
Epoch [8/10], Step [100/303], Loss: 8.0869, Training-time: 6760.99
Epoch [8/10], Step [101/303], Loss: 8.0837, Training-time: 6764.03
Epoch [8/10], Step [102/303], Loss: 8.0807, Training-time: 6767.08
Epoch [8/10], Step [103/303], Loss: 8.0777, Training-time: 6770.13
Epoch [8/10], Step [104/303], Loss: 8.0835, Training-time: 6773.17
Epoch [8/10], Step [105/303], Loss: 8.0803, Training-time: 6776.23
Epoch [8/10], Step [106/303], Loss: 8.0768, Training-time: 6779.28
Epoch [8/10], Step [107/303], Loss: 8.0735, Training-time: 6782.33
Epoch [8/10], Step [108/303], Loss: 8.0732, Training-time: 6785.38
Epoch [8/10], Step [109/303], Loss: 8.0702, Training-time: 6788.43
Epoch [8/10], Step [110/303], Loss: 8.0680, Training-time: 6791.49
Epoch [8/10], Step [111/303], Loss: 8.0671, Training-time: 6794.54
Epoch [8/10], Step [112/303], Loss: 8.0643, Training-time: 6797.59
Epoch [8/10], Step [113/303], Loss: 8.0614, Training-time: 6800.63
Epoch [8/10], Step [114/303], Loss: 8.0602, Training-time: 6803.68
Epoch [8/10], Step [115/303], Loss: 8.0737, Training-time: 6806.73
Epoch [8/10], Step [116/303], Loss: 8.0708, Training-time: 6809.78
Epoch [8/10], Step [117/303], Loss: 8.0691, Training-time: 6812.84
Epoch [8/10], Step [118/303], Loss: 8.0670, Training-time: 6815.89
Epoch [8/10], Step [119/303], Loss: 8.0637, Training-time: 6818.93
Epoch [8/10], Step [120/303], Loss: 8.0649, Training-time: 6821.99
Epoch [8/10], Step [121/303], Loss: 8.0618, Training-time: 6825.03
Epoch [8/10], Step [122/303], Loss: 8.0586, Training-time: 6828.09
Epoch [8/10], Step [123/303], Loss: 8.0925, Training-time: 6831.12
Epoch [8/10], Step [124/303], Loss: 8.0900, Training-time: 6834.18
Epoch [8/10], Step [125/303], Loss: 8.0873, Training-time: 6837.23
Epoch [8/10], Step [126/303], Loss: 8.0841, Training-time: 6840.27
Epoch [8/10], Step [127/303], Loss: 8.0811, Training-time: 6843.32
Epoch [8/10], Step [128/303], Loss: 8.0784, Training-time: 6846.37
Epoch [8/10], Step [129/303], Loss: 8.0754, Training-time: 6849.42
Epoch [8/10], Step [130/303], Loss: 8.0769, Training-time: 6852.46
Epoch [8/10], Step [131/303], Loss: 8.0753, Training-time: 6855.51
Epoch [8/10], Step [132/303], Loss: 8.0724, Training-time: 6858.56
Epoch [8/10], Step [133/303], Loss: 8.0692, Training-time: 6861.60
Epoch [8/10], Step [134/303], Loss: 8.0663, Training-time: 6864.65
Epoch [8/10], Step [135/303], Loss: 8.0639, Training-time: 6867.70
Epoch [8/10], Step [136/303], Loss: 8.0633, Training-time: 6870.75
Epoch [8/10], Step [137/303], Loss: 8.0611, Training-time: 6873.81
Epoch [8/10], Step [138/303], Loss: 8.0581, Training-time: 6876.86
Epoch [8/10], Step [139/303], Loss: 8.0563, Training-time: 6879.91
Epoch [8/10], Step [140/303], Loss: 8.0535, Training-time: 6882.95
Epoch [8/10], Step [141/303], Loss: 8.0509, Training-time: 6886.01
Epoch [8/10], Step [142/303], Loss: 8.0762, Training-time: 6889.06
Epoch [8/10], Step [143/303], Loss: 8.0732, Training-time: 6892.10
Epoch [8/10], Step [144/303], Loss: 8.0707, Training-time: 6895.15
Epoch [8/10], Step [145/303], Loss: 8.0681, Training-time: 6898.19
Epoch [8/10], Step [146/303], Loss: 8.0705, Training-time: 6901.25
Epoch [8/10], Step [147/303], Loss: 8.0674, Training-time: 6904.29
Epoch [8/10], Step [148/303], Loss: 8.0645, Training-time: 6907.34
Epoch [8/10], Step [149/303], Loss: 8.0620, Training-time: 6910.39
Epoch [8/10], Step [150/303], Loss: 8.0593, Training-time: 6913.44
Epoch [8/10], Step [151/303], Loss: 8.0592, Training-time: 6916.49
Epoch [8/10], Step [152/303], Loss: 8.0561, Training-time: 6919.53
Epoch [8/10], Step [153/303], Loss: 8.0530, Training-time: 6922.56
Epoch [8/10], Step [154/303], Loss: 8.0533, Training-time: 6925.61
Epoch [8/10], Step [155/303], Loss: 8.0502, Training-time: 6928.66
Epoch [8/10], Step [156/303], Loss: 8.0471, Training-time: 6931.71
Epoch [8/10], Step [157/303], Loss: 8.0447, Training-time: 6934.76
Epoch [8/10], Step [158/303], Loss: 8.0416, Training-time: 6937.81
Epoch [8/10], Step [159/303], Loss: 8.0474, Training-time: 6940.86
Epoch [8/10], Step [160/303], Loss: 8.0445, Training-time: 6943.91
Epoch [8/10], Step [161/303], Loss: 8.0429, Training-time: 6946.96
Epoch [8/10], Step [162/303], Loss: 8.0397, Training-time: 6950.01
Epoch [8/10], Step [163/303], Loss: 8.0375, Training-time: 6953.07
Epoch [8/10], Step [164/303], Loss: 8.0346, Training-time: 6956.12
Epoch [8/10], Step [165/303], Loss: 8.0314, Training-time: 6959.18
Epoch [8/10], Step [166/303], Loss: 8.0283, Training-time: 6962.22
Epoch [8/10], Step [167/303], Loss: 8.0253, Training-time: 6965.27
Epoch [8/10], Step [168/303], Loss: 8.0222, Training-time: 6968.32
Epoch [8/10], Step [169/303], Loss: 8.0195, Training-time: 6971.37
Epoch [8/10], Step [170/303], Loss: 8.0170, Training-time: 6974.43
Epoch [8/10], Step [171/303], Loss: 8.0154, Training-time: 6977.47
Epoch [8/10], Step [172/303], Loss: 8.0123, Training-time: 6980.51
Epoch [8/10], Step [173/303], Loss: 8.0095, Training-time: 6983.57
Epoch [8/10], Step [174/303], Loss: 8.0080, Training-time: 6986.62
Epoch [8/10], Step [175/303], Loss: 8.0059, Training-time: 6989.68
Epoch [8/10], Step [176/303], Loss: 8.0028, Training-time: 6992.73
Epoch [8/10], Step [177/303], Loss: 7.9996, Training-time: 6995.78
Epoch [8/10], Step [178/303], Loss: 7.9969, Training-time: 6998.83
Epoch [8/10], Step [179/303], Loss: 7.9940, Training-time: 7001.88
Epoch [8/10], Step [180/303], Loss: 7.9913, Training-time: 7004.93
Epoch [8/10], Step [181/303], Loss: 7.9892, Training-time: 7007.98
Epoch [8/10], Step [182/303], Loss: 7.9866, Training-time: 7011.03
Epoch [8/10], Step [183/303], Loss: 7.9856, Training-time: 7014.07
Epoch [8/10], Step [184/303], Loss: 7.9852, Training-time: 7017.13
Epoch [8/10], Step [185/303], Loss: 7.9857, Training-time: 7020.17
Epoch [8/10], Step [186/303], Loss: 7.9826, Training-time: 7023.22
Epoch [8/10], Step [187/303], Loss: 7.9798, Training-time: 7026.27
Epoch [8/10], Step [188/303], Loss: 7.9767, Training-time: 7029.33
Epoch [8/10], Step [189/303], Loss: 7.9737, Training-time: 7032.37
Epoch [8/10], Step [190/303], Loss: 7.9718, Training-time: 7035.42
Epoch [8/10], Step [191/303], Loss: 7.9687, Training-time: 7038.47
Epoch [8/10], Step [192/303], Loss: 7.9671, Training-time: 7041.53
Epoch [8/10], Step [193/303], Loss: 7.9642, Training-time: 7044.58
Epoch [8/10], Step [194/303], Loss: 7.9611, Training-time: 7047.62
Epoch [8/10], Step [195/303], Loss: 7.9608, Training-time: 7050.68
Epoch [8/10], Step [196/303], Loss: 7.9582, Training-time: 7053.73
Epoch [8/10], Step [197/303], Loss: 7.9554, Training-time: 7056.78
Epoch [8/10], Step [198/303], Loss: 8.3253, Training-time: 7059.84
Epoch [8/10], Step [199/303], Loss: 8.3221, Training-time: 7062.90
Epoch [8/10], Step [200/303], Loss: 8.3216, Training-time: 7065.95
Epoch [8/10], Step [201/303], Loss: 8.3204, Training-time: 7069.00
Epoch [8/10], Step [202/303], Loss: 8.3173, Training-time: 7072.06
Epoch [8/10], Step [203/303], Loss: 8.3157, Training-time: 7075.12
Epoch [8/10], Step [204/303], Loss: 8.3138, Training-time: 7078.18
Epoch [8/10], Step [205/303], Loss: 8.3106, Training-time: 7081.23
Epoch [8/10], Step [206/303], Loss: 8.3077, Training-time: 7084.28
Epoch [8/10], Step [207/303], Loss: 8.3051, Training-time: 7087.33
Epoch [8/10], Step [208/303], Loss: 8.3028, Training-time: 7090.39
Epoch [8/10], Step [209/303], Loss: 8.3003, Training-time: 7093.44
Epoch [8/10], Step [210/303], Loss: 8.2978, Training-time: 7096.49
Epoch [8/10], Step [211/303], Loss: 8.2948, Training-time: 7099.54
Epoch [8/10], Step [212/303], Loss: 8.2916, Training-time: 7102.58
Epoch [8/10], Step [213/303], Loss: 8.2896, Training-time: 7105.63
Epoch [8/10], Step [214/303], Loss: 8.2871, Training-time: 7108.68
Epoch [8/10], Step [215/303], Loss: 8.2841, Training-time: 7111.72
Epoch [8/10], Step [216/303], Loss: 8.2813, Training-time: 7114.77
Epoch [8/10], Step [217/303], Loss: 8.2787, Training-time: 7117.83
Epoch [8/10], Step [218/303], Loss: 8.2757, Training-time: 7120.88
Epoch [8/10], Step [219/303], Loss: 8.2732, Training-time: 7123.93
Epoch [8/10], Step [220/303], Loss: 8.2746, Training-time: 7126.97
Epoch [8/10], Step [221/303], Loss: 8.2717, Training-time: 7130.03
Epoch [8/10], Step [222/303], Loss: 8.2706, Training-time: 7133.08
Epoch [8/10], Step [223/303], Loss: 8.2680, Training-time: 7136.12
Epoch [8/10], Step [224/303], Loss: 8.2648, Training-time: 7139.18
Epoch [8/10], Step [225/303], Loss: 8.2618, Training-time: 7142.24
Epoch [8/10], Step [226/303], Loss: 8.2590, Training-time: 7145.28
Epoch [8/10], Step [227/303], Loss: 8.2562, Training-time: 7148.34
Epoch [8/10], Step [228/303], Loss: 8.2535, Training-time: 7151.40
Epoch [8/10], Step [229/303], Loss: 8.2506, Training-time: 7154.45
Epoch [8/10], Step [230/303], Loss: 8.2485, Training-time: 7157.51
Epoch [8/10], Step [231/303], Loss: 8.2508, Training-time: 7160.56
Epoch [8/10], Step [232/303], Loss: 8.2493, Training-time: 7163.61
Epoch [8/10], Step [233/303], Loss: 8.2608, Training-time: 7166.67
Epoch [8/10], Step [234/303], Loss: 8.2587, Training-time: 7169.72
Epoch [8/10], Step [235/303], Loss: 8.2579, Training-time: 7172.78
Epoch [8/10], Step [236/303], Loss: 8.2559, Training-time: 7175.83
Epoch [8/10], Step [237/303], Loss: 8.2775, Training-time: 7178.89
Epoch [8/10], Step [238/303], Loss: 8.2767, Training-time: 7181.95
Epoch [8/10], Step [239/303], Loss: 8.2736, Training-time: 7185.00
Epoch [8/10], Step [240/303], Loss: 8.2727, Training-time: 7188.05
Epoch [8/10], Step [241/303], Loss: 8.2702, Training-time: 7191.10
Epoch [8/10], Step [242/303], Loss: 8.2675, Training-time: 7194.16
Epoch [8/10], Step [243/303], Loss: 8.2661, Training-time: 7197.20
Epoch [8/10], Step [244/303], Loss: 8.2636, Training-time: 7200.25
Epoch [8/10], Step [245/303], Loss: 8.2608, Training-time: 7203.30
Epoch [8/10], Step [246/303], Loss: 8.2716, Training-time: 7206.36
Epoch [8/10], Step [247/303], Loss: 8.2691, Training-time: 7209.42
Epoch [8/10], Step [248/303], Loss: 8.2664, Training-time: 7212.48
Epoch [8/10], Step [249/303], Loss: 8.2647, Training-time: 7215.54
Epoch [8/10], Step [250/303], Loss: 8.2629, Training-time: 7218.58
Epoch [8/10], Step [251/303], Loss: 8.2606, Training-time: 7221.64
Epoch [8/10], Step [252/303], Loss: 8.2577, Training-time: 7224.69
Epoch [8/10], Step [253/303], Loss: 8.2556, Training-time: 7227.74
Epoch [8/10], Step [254/303], Loss: 8.2550, Training-time: 7230.79
Epoch [8/10], Step [255/303], Loss: 8.2521, Training-time: 7233.85
Epoch [8/10], Step [256/303], Loss: 8.2497, Training-time: 7236.91
Epoch [8/10], Step [257/303], Loss: 8.2468, Training-time: 7239.96
Epoch [8/10], Step [258/303], Loss: 8.2450, Training-time: 7243.01
Epoch [8/10], Step [259/303], Loss: 8.2433, Training-time: 7246.07
Epoch [8/10], Step [260/303], Loss: 8.2409, Training-time: 7249.11
Epoch [8/10], Step [261/303], Loss: 8.2379, Training-time: 7252.16
Epoch [8/10], Step [262/303], Loss: 8.2347, Training-time: 7255.21
Epoch [8/10], Step [263/303], Loss: 8.2316, Training-time: 7258.26
Epoch [8/10], Step [264/303], Loss: 8.2290, Training-time: 7261.32
Epoch [8/10], Step [265/303], Loss: 8.2260, Training-time: 7264.37
Epoch [8/10], Step [266/303], Loss: 8.2235, Training-time: 7267.42
Epoch [8/10], Step [267/303], Loss: 8.2342, Training-time: 7270.47
Epoch [8/10], Step [268/303], Loss: 8.2312, Training-time: 7273.52
Epoch [8/10], Step [269/303], Loss: 8.2285, Training-time: 7276.57
Epoch [8/10], Step [270/303], Loss: 8.2275, Training-time: 7279.63
Epoch [8/10], Step [271/303], Loss: 8.2245, Training-time: 7282.68
Epoch [8/10], Step [272/303], Loss: 8.2227, Training-time: 7285.74
Epoch [8/10], Step [273/303], Loss: 8.2197, Training-time: 7288.79
Epoch [8/10], Step [274/303], Loss: 8.2173, Training-time: 7291.84
Epoch [8/10], Step [275/303], Loss: 8.2143, Training-time: 7294.88
Epoch [8/10], Step [276/303], Loss: 8.2120, Training-time: 7297.94
Epoch [8/10], Step [277/303], Loss: 8.2089, Training-time: 7301.00
Epoch [8/10], Step [278/303], Loss: 8.2058, Training-time: 7304.04
Epoch [8/10], Step [279/303], Loss: 8.2029, Training-time: 7307.08
Epoch [8/10], Step [280/303], Loss: 8.1998, Training-time: 7310.13
Epoch [8/10], Step [281/303], Loss: 8.1971, Training-time: 7313.18
Epoch [8/10], Step [282/303], Loss: 8.1950, Training-time: 7316.23
Epoch [8/10], Step [283/303], Loss: 8.1935, Training-time: 7319.29
Epoch [8/10], Step [284/303], Loss: 8.1907, Training-time: 7322.33
Epoch [8/10], Step [285/303], Loss: 8.1878, Training-time: 7325.39
Epoch [8/10], Step [286/303], Loss: 8.1865, Training-time: 7328.44
Epoch [8/10], Step [287/303], Loss: 8.1880, Training-time: 7331.48
Epoch [8/10], Step [288/303], Loss: 8.1854, Training-time: 7334.53
Epoch [8/10], Step [289/303], Loss: 8.1830, Training-time: 7337.58
Epoch [8/10], Step [290/303], Loss: 8.1803, Training-time: 7340.64
Epoch [8/10], Step [291/303], Loss: 8.1775, Training-time: 7343.68
Epoch [8/10], Step [292/303], Loss: 8.1779, Training-time: 7346.74
Epoch [8/10], Step [293/303], Loss: 8.1755, Training-time: 7349.79
Epoch [8/10], Step [294/303], Loss: 8.1732, Training-time: 7352.83
Epoch [8/10], Step [295/303], Loss: 8.1716, Training-time: 7355.88
Epoch [8/10], Step [296/303], Loss: 8.1687, Training-time: 7358.93
Epoch [8/10], Step [297/303], Loss: 8.1660, Training-time: 7361.97
Epoch [8/10], Step [298/303], Loss: 8.1690, Training-time: 7364.99
Epoch [8/10], Step [299/303], Loss: 8.1660, Training-time: 7368.02
Epoch [8/10], Step [300/303], Loss: 8.1629, Training-time: 7371.05
Epoch [8/10], Step [301/303], Loss: 8.1598, Training-time: 7374.07
Epoch [8/10], Step [302/303], Loss: 8.1595, Training-time: 7377.09
Epoch [8/10], Step [303/303], Loss: 8.1563, Training-time: 7377.72
Epoch [9/10], Step [1/303], Loss: 8.1534, Training-time: 7381.12
Epoch [9/10], Step [2/303], Loss: 8.1512, Training-time: 7384.19
Epoch [9/10], Step [3/303], Loss: 8.1483, Training-time: 7387.24
Epoch [9/10], Step [4/303], Loss: 8.1451, Training-time: 7390.28
Epoch [9/10], Step [5/303], Loss: 8.1443, Training-time: 7393.33
Epoch [9/10], Step [6/303], Loss: 8.1427, Training-time: 7396.38
Epoch [9/10], Step [7/303], Loss: 8.1399, Training-time: 7399.42
Epoch [9/10], Step [8/303], Loss: 8.1371, Training-time: 7402.47
Epoch [9/10], Step [9/303], Loss: 8.1341, Training-time: 7405.51
Epoch [9/10], Step [10/303], Loss: 8.1313, Training-time: 7408.53
Epoch [9/10], Step [11/303], Loss: 8.1297, Training-time: 7411.57
Epoch [9/10], Step [12/303], Loss: 8.1291, Training-time: 7414.60
Epoch [9/10], Step [13/303], Loss: 8.1266, Training-time: 7417.63
Epoch [9/10], Step [14/303], Loss: 8.1240, Training-time: 7420.68
Epoch [9/10], Step [15/303], Loss: 8.1210, Training-time: 7423.73
Epoch [9/10], Step [16/303], Loss: 8.1184, Training-time: 7426.76
Epoch [9/10], Step [17/303], Loss: 8.1155, Training-time: 7429.82
Epoch [9/10], Step [18/303], Loss: 8.1703, Training-time: 7432.85
Epoch [9/10], Step [19/303], Loss: 8.1674, Training-time: 7435.87
Epoch [9/10], Step [20/303], Loss: 8.1647, Training-time: 7438.93
Epoch [9/10], Step [21/303], Loss: 8.1658, Training-time: 7441.98
Epoch [9/10], Step [22/303], Loss: 8.1631, Training-time: 7445.02
Epoch [9/10], Step [23/303], Loss: 8.1603, Training-time: 7448.06
Epoch [9/10], Step [24/303], Loss: 8.1575, Training-time: 7451.10
Epoch [9/10], Step [25/303], Loss: 8.1545, Training-time: 7454.14
Epoch [9/10], Step [26/303], Loss: 8.1525, Training-time: 7457.20
Epoch [9/10], Step [27/303], Loss: 8.1658, Training-time: 7460.25
Epoch [9/10], Step [28/303], Loss: 8.1639, Training-time: 7463.28
Epoch [9/10], Step [29/303], Loss: 8.1614, Training-time: 7466.33
Epoch [9/10], Step [30/303], Loss: 8.1590, Training-time: 7469.37
Epoch [9/10], Step [31/303], Loss: 8.1562, Training-time: 7472.41
Epoch [9/10], Step [32/303], Loss: 8.1624, Training-time: 7475.47
Epoch [9/10], Step [33/303], Loss: 8.1976, Training-time: 7478.51
Epoch [9/10], Step [34/303], Loss: 8.1955, Training-time: 7481.54
Epoch [9/10], Step [35/303], Loss: 8.1927, Training-time: 7484.59
Epoch [9/10], Step [36/303], Loss: 8.1902, Training-time: 7487.64
Epoch [9/10], Step [37/303], Loss: 8.1877, Training-time: 7490.68
Epoch [9/10], Step [38/303], Loss: 8.1858, Training-time: 7493.73
Epoch [9/10], Step [39/303], Loss: 8.1833, Training-time: 7496.77
Epoch [9/10], Step [40/303], Loss: 8.1808, Training-time: 7499.81
Epoch [9/10], Step [41/303], Loss: 8.2022, Training-time: 7502.86
Epoch [9/10], Step [42/303], Loss: 8.1992, Training-time: 7505.90
Epoch [9/10], Step [43/303], Loss: 8.1963, Training-time: 7508.93
Epoch [9/10], Step [44/303], Loss: 8.1947, Training-time: 7511.97
Epoch [9/10], Step [45/303], Loss: 8.1917, Training-time: 7515.02
Epoch [9/10], Step [46/303], Loss: 8.1912, Training-time: 7518.05
Epoch [9/10], Step [47/303], Loss: 8.1891, Training-time: 7521.10
Epoch [9/10], Step [48/303], Loss: 8.1873, Training-time: 7524.16
Epoch [9/10], Step [49/303], Loss: 8.1844, Training-time: 7527.20
Epoch [9/10], Step [50/303], Loss: 8.1814, Training-time: 7530.25
Epoch [9/10], Step [51/303], Loss: 8.1785, Training-time: 7533.30
Epoch [9/10], Step [52/303], Loss: 8.1758, Training-time: 7536.34
Epoch [9/10], Step [53/303], Loss: 8.1743, Training-time: 7539.39
Epoch [9/10], Step [54/303], Loss: 8.1742, Training-time: 7542.44
Epoch [9/10], Step [55/303], Loss: 8.1724, Training-time: 7545.47
Epoch [9/10], Step [56/303], Loss: 8.1700, Training-time: 7548.51
Epoch [9/10], Step [57/303], Loss: 8.1673, Training-time: 7551.57
Epoch [9/10], Step [58/303], Loss: 8.1650, Training-time: 7554.60
Epoch [9/10], Step [59/303], Loss: 8.1621, Training-time: 7557.65
Epoch [9/10], Step [60/303], Loss: 8.1604, Training-time: 7560.69
Epoch [9/10], Step [61/303], Loss: 8.1590, Training-time: 7563.71
Epoch [9/10], Step [62/303], Loss: 8.1566, Training-time: 7566.76
Epoch [9/10], Step [63/303], Loss: 8.1549, Training-time: 7569.80
Epoch [9/10], Step [64/303], Loss: 8.1560, Training-time: 7572.83
Epoch [9/10], Step [65/303], Loss: 8.1533, Training-time: 7575.89
Epoch [9/10], Step [66/303], Loss: 8.1548, Training-time: 7578.94
Epoch [9/10], Step [67/303], Loss: 8.1559, Training-time: 7581.97
Epoch [9/10], Step [68/303], Loss: 8.1536, Training-time: 7585.01
Epoch [9/10], Step [69/303], Loss: 8.1507, Training-time: 7588.06
Epoch [9/10], Step [70/303], Loss: 8.1484, Training-time: 7591.10
Epoch [9/10], Step [71/303], Loss: 8.1493, Training-time: 7594.14
Epoch [9/10], Step [72/303], Loss: 8.1489, Training-time: 7597.20
Epoch [9/10], Step [73/303], Loss: 8.1469, Training-time: 7600.23
Epoch [9/10], Step [74/303], Loss: 8.1446, Training-time: 7603.28
Epoch [9/10], Step [75/303], Loss: 8.1420, Training-time: 7606.32
Epoch [9/10], Step [76/303], Loss: 8.1402, Training-time: 7609.34
Epoch [9/10], Step [77/303], Loss: 8.1372, Training-time: 7612.38
Epoch [9/10], Step [78/303], Loss: 8.1345, Training-time: 7615.42
Epoch [9/10], Step [79/303], Loss: 8.1318, Training-time: 7618.45
Epoch [9/10], Step [80/303], Loss: 8.1294, Training-time: 7621.50
Epoch [9/10], Step [81/303], Loss: 8.1274, Training-time: 7624.56
Epoch [9/10], Step [82/303], Loss: 8.1259, Training-time: 7627.59
Epoch [9/10], Step [83/303], Loss: 8.1235, Training-time: 7630.63
Epoch [9/10], Step [84/303], Loss: 8.1219, Training-time: 7633.67
Epoch [9/10], Step [85/303], Loss: 8.1196, Training-time: 7636.70
Epoch [9/10], Step [86/303], Loss: 8.1178, Training-time: 7639.73
Epoch [9/10], Step [87/303], Loss: 8.1156, Training-time: 7642.78
Epoch [9/10], Step [88/303], Loss: 8.1128, Training-time: 7645.80
Epoch [9/10], Step [89/303], Loss: 8.1105, Training-time: 7648.84
Epoch [9/10], Step [90/303], Loss: 8.1091, Training-time: 7651.89
Epoch [9/10], Step [91/303], Loss: 8.1068, Training-time: 7654.93
Epoch [9/10], Step [92/303], Loss: 8.1043, Training-time: 7657.98
Epoch [9/10], Step [93/303], Loss: 8.1013, Training-time: 7661.04
Epoch [9/10], Step [94/303], Loss: 8.0985, Training-time: 7664.07
Epoch [9/10], Step [95/303], Loss: 8.0967, Training-time: 7667.11
Epoch [9/10], Step [96/303], Loss: 8.0944, Training-time: 7670.17
Epoch [9/10], Step [97/303], Loss: 8.0916, Training-time: 7673.19
Epoch [9/10], Step [98/303], Loss: 8.0902, Training-time: 7676.24
Epoch [9/10], Step [99/303], Loss: 8.0876, Training-time: 7679.30
Epoch [9/10], Step [100/303], Loss: 8.0854, Training-time: 7682.31
Epoch [9/10], Step [101/303], Loss: 8.0968, Training-time: 7685.35
Epoch [9/10], Step [102/303], Loss: 8.0939, Training-time: 7688.39
Epoch [9/10], Step [103/303], Loss: 8.0968, Training-time: 7691.43
Epoch [9/10], Step [104/303], Loss: 8.0939, Training-time: 7694.48
Epoch [9/10], Step [105/303], Loss: 8.0911, Training-time: 7697.53
Epoch [9/10], Step [106/303], Loss: 8.0882, Training-time: 7700.57
Epoch [9/10], Step [107/303], Loss: 8.0857, Training-time: 7703.62
Epoch [9/10], Step [108/303], Loss: 8.0829, Training-time: 7706.66
Epoch [9/10], Step [109/303], Loss: 8.0804, Training-time: 7709.69
Epoch [9/10], Step [110/303], Loss: 8.0789, Training-time: 7712.75
Epoch [9/10], Step [111/303], Loss: 8.0760, Training-time: 7715.80
Epoch [9/10], Step [112/303], Loss: 8.0737, Training-time: 7718.82
Epoch [9/10], Step [113/303], Loss: 8.0711, Training-time: 7721.87
Epoch [9/10], Step [114/303], Loss: 8.0694, Training-time: 7724.91
Epoch [9/10], Step [115/303], Loss: 8.0672, Training-time: 7727.94
Epoch [9/10], Step [116/303], Loss: 8.0643, Training-time: 7730.99
Epoch [9/10], Step [117/303], Loss: 8.0616, Training-time: 7734.04
Epoch [9/10], Step [118/303], Loss: 8.0594, Training-time: 7737.06
Epoch [9/10], Step [119/303], Loss: 8.0589, Training-time: 7740.10
Epoch [9/10], Step [120/303], Loss: 8.0565, Training-time: 7743.15
Epoch [9/10], Step [121/303], Loss: 8.0539, Training-time: 7746.19
Epoch [9/10], Step [122/303], Loss: 8.0517, Training-time: 7749.25
Epoch [9/10], Step [123/303], Loss: 8.0494, Training-time: 7752.31
Epoch [9/10], Step [124/303], Loss: 8.0475, Training-time: 7755.33
Epoch [9/10], Step [125/303], Loss: 8.0455, Training-time: 7758.37
Epoch [9/10], Step [126/303], Loss: 8.0541, Training-time: 7761.41
Epoch [9/10], Step [127/303], Loss: 8.0512, Training-time: 7764.44
Epoch [9/10], Step [128/303], Loss: 8.0484, Training-time: 7767.48
Epoch [9/10], Step [129/303], Loss: 8.0457, Training-time: 7770.53
Epoch [9/10], Step [130/303], Loss: 8.0431, Training-time: 7773.56
Epoch [9/10], Step [131/303], Loss: 8.0411, Training-time: 7776.61
Epoch [9/10], Step [132/303], Loss: 8.0385, Training-time: 7779.66
Epoch [9/10], Step [133/303], Loss: 8.0358, Training-time: 7782.69
Epoch [9/10], Step [134/303], Loss: 8.0329, Training-time: 7785.74
Epoch [9/10], Step [135/303], Loss: 8.0312, Training-time: 7788.79
Epoch [9/10], Step [136/303], Loss: 8.0310, Training-time: 7791.82
Epoch [9/10], Step [137/303], Loss: 8.0319, Training-time: 7794.86
Epoch [9/10], Step [138/303], Loss: 8.0294, Training-time: 7797.90
Epoch [9/10], Step [139/303], Loss: 8.0266, Training-time: 7800.93
Epoch [9/10], Step [140/303], Loss: 8.0239, Training-time: 7803.98
Epoch [9/10], Step [141/303], Loss: 8.0213, Training-time: 7807.04
Epoch [9/10], Step [142/303], Loss: 8.0307, Training-time: 7810.07
Epoch [9/10], Step [143/303], Loss: 8.0282, Training-time: 7813.11
Epoch [9/10], Step [144/303], Loss: 8.0260, Training-time: 7816.15
Epoch [9/10], Step [145/303], Loss: 8.0251, Training-time: 7819.19
Epoch [9/10], Step [146/303], Loss: 8.0227, Training-time: 7822.23
Epoch [9/10], Step [147/303], Loss: 8.0210, Training-time: 7825.28
Epoch [9/10], Step [148/303], Loss: 8.0185, Training-time: 7828.31
Epoch [9/10], Step [149/303], Loss: 8.0160, Training-time: 7831.37
Epoch [9/10], Step [150/303], Loss: 8.0133, Training-time: 7834.42
Epoch [9/10], Step [151/303], Loss: 8.0106, Training-time: 7837.45
Epoch [9/10], Step [152/303], Loss: 8.0082, Training-time: 7840.50
Epoch [9/10], Step [153/303], Loss: 8.0055, Training-time: 7843.56
Epoch [9/10], Step [154/303], Loss: 8.0055, Training-time: 7846.59
Epoch [9/10], Step [155/303], Loss: 8.0033, Training-time: 7849.64
Epoch [9/10], Step [156/303], Loss: 8.0024, Training-time: 7852.69
Epoch [9/10], Step [157/303], Loss: 7.9999, Training-time: 7855.72
Epoch [9/10], Step [158/303], Loss: 7.9981, Training-time: 7858.77
Epoch [9/10], Step [159/303], Loss: 7.9955, Training-time: 7861.82
Epoch [9/10], Step [160/303], Loss: 7.9929, Training-time: 7864.86
Epoch [9/10], Step [161/303], Loss: 7.9901, Training-time: 7867.91
Epoch [9/10], Step [162/303], Loss: 7.9905, Training-time: 7870.96
Epoch [9/10], Step [163/303], Loss: 7.9879, Training-time: 7873.98
Epoch [9/10], Step [164/303], Loss: 7.9851, Training-time: 7877.04
Epoch [9/10], Step [165/303], Loss: 7.9849, Training-time: 7880.09
Epoch [9/10], Step [166/303], Loss: 7.9824, Training-time: 7883.11
Epoch [9/10], Step [167/303], Loss: 7.9800, Training-time: 7886.15
Epoch [9/10], Step [168/303], Loss: 7.9774, Training-time: 7889.19
Epoch [9/10], Step [169/303], Loss: 7.9748, Training-time: 7892.23
Epoch [9/10], Step [170/303], Loss: 7.9724, Training-time: 7895.27
Epoch [9/10], Step [171/303], Loss: 8.3026, Training-time: 7898.31
Epoch [9/10], Step [172/303], Loss: 8.2999, Training-time: 7901.34
Epoch [9/10], Step [173/303], Loss: 8.2973, Training-time: 7904.39
Epoch [9/10], Step [174/303], Loss: 8.2950, Training-time: 7907.44
Epoch [9/10], Step [175/303], Loss: 8.2934, Training-time: 7910.47
Epoch [9/10], Step [176/303], Loss: 8.2911, Training-time: 7913.52
Epoch [9/10], Step [177/303], Loss: 8.2886, Training-time: 7916.58
Epoch [9/10], Step [178/303], Loss: 8.2862, Training-time: 7919.60
Epoch [9/10], Step [179/303], Loss: 8.2838, Training-time: 7922.66
Epoch [9/10], Step [180/303], Loss: 8.2819, Training-time: 7925.70
Epoch [9/10], Step [181/303], Loss: 8.2798, Training-time: 7928.74
Epoch [9/10], Step [182/303], Loss: 8.2784, Training-time: 7931.79
Epoch [9/10], Step [183/303], Loss: 8.2763, Training-time: 7934.84
Epoch [9/10], Step [184/303], Loss: 8.2740, Training-time: 7937.88
Epoch [9/10], Step [185/303], Loss: 8.2722, Training-time: 7940.93
Epoch [9/10], Step [186/303], Loss: 8.2699, Training-time: 7943.99
Epoch [9/10], Step [187/303], Loss: 8.2672, Training-time: 7947.02
Epoch [9/10], Step [188/303], Loss: 8.2652, Training-time: 7950.07
Epoch [9/10], Step [189/303], Loss: 8.2699, Training-time: 7953.11
Epoch [9/10], Step [190/303], Loss: 8.2672, Training-time: 7956.14
Epoch [9/10], Step [191/303], Loss: 8.2666, Training-time: 7959.18
Epoch [9/10], Step [192/303], Loss: 8.2649, Training-time: 7962.23
Epoch [9/10], Step [193/303], Loss: 8.2623, Training-time: 7965.26
Epoch [9/10], Step [194/303], Loss: 8.2595, Training-time: 7968.31
Epoch [9/10], Step [195/303], Loss: 8.2576, Training-time: 7971.35
Epoch [9/10], Step [196/303], Loss: 8.2610, Training-time: 7974.37
Epoch [9/10], Step [197/303], Loss: 8.2585, Training-time: 7977.41
Epoch [9/10], Step [198/303], Loss: 8.2563, Training-time: 7980.46
Epoch [9/10], Step [199/303], Loss: 8.2536, Training-time: 7983.50
Epoch [9/10], Step [200/303], Loss: 8.2507, Training-time: 7986.55
Epoch [9/10], Step [201/303], Loss: 8.2479, Training-time: 7989.60
Epoch [9/10], Step [202/303], Loss: 8.2452, Training-time: 7992.62
Epoch [9/10], Step [203/303], Loss: 8.2442, Training-time: 7995.68
Epoch [9/10], Step [204/303], Loss: 8.2414, Training-time: 7998.73
Epoch [9/10], Step [205/303], Loss: 8.2388, Training-time: 8001.77
Epoch [9/10], Step [206/303], Loss: 8.2403, Training-time: 8004.83
Epoch [9/10], Step [207/303], Loss: 8.2385, Training-time: 8007.87
Epoch [9/10], Step [208/303], Loss: 8.2381, Training-time: 8010.90
Epoch [9/10], Step [209/303], Loss: 8.2369, Training-time: 8013.94
Epoch [9/10], Step [210/303], Loss: 8.2356, Training-time: 8016.99
Epoch [9/10], Step [211/303], Loss: 8.2424, Training-time: 8020.02
Epoch [9/10], Step [212/303], Loss: 8.2432, Training-time: 8023.06
Epoch [9/10], Step [213/303], Loss: 8.2411, Training-time: 8026.11
Epoch [9/10], Step [214/303], Loss: 8.2386, Training-time: 8029.13
Epoch [9/10], Step [215/303], Loss: 8.2360, Training-time: 8032.18
Epoch [9/10], Step [216/303], Loss: 8.2334, Training-time: 8035.23
Epoch [9/10], Step [217/303], Loss: 8.2308, Training-time: 8038.27
Epoch [9/10], Step [218/303], Loss: 8.2281, Training-time: 8041.31
Epoch [9/10], Step [219/303], Loss: 8.2254, Training-time: 8044.36
Epoch [9/10], Step [220/303], Loss: 8.2234, Training-time: 8047.39
Epoch [9/10], Step [221/303], Loss: 8.2205, Training-time: 8050.43
Epoch [9/10], Step [222/303], Loss: 8.2178, Training-time: 8053.47
Epoch [9/10], Step [223/303], Loss: 8.2191, Training-time: 8056.52
Epoch [9/10], Step [224/303], Loss: 8.2168, Training-time: 8059.56
Epoch [9/10], Step [225/303], Loss: 8.2152, Training-time: 8062.60
Epoch [9/10], Step [226/303], Loss: 8.2126, Training-time: 8065.62
Epoch [9/10], Step [227/303], Loss: 8.2101, Training-time: 8068.68
Epoch [9/10], Step [228/303], Loss: 8.2075, Training-time: 8071.72
Epoch [9/10], Step [229/303], Loss: 8.2048, Training-time: 8074.75
Epoch [9/10], Step [230/303], Loss: 8.2024, Training-time: 8077.79
Epoch [9/10], Step [231/303], Loss: 8.2001, Training-time: 8080.84
Epoch [9/10], Step [232/303], Loss: 8.2031, Training-time: 8083.87
Epoch [9/10], Step [233/303], Loss: 8.2003, Training-time: 8086.91
Epoch [9/10], Step [234/303], Loss: 8.1980, Training-time: 8089.96
Epoch [9/10], Step [235/303], Loss: 8.1958, Training-time: 8092.99
Epoch [9/10], Step [236/303], Loss: 8.1932, Training-time: 8096.04
Epoch [9/10], Step [237/303], Loss: 8.2259, Training-time: 8099.08
Epoch [9/10], Step [238/303], Loss: 8.2232, Training-time: 8102.12
Epoch [9/10], Step [239/303], Loss: 8.2208, Training-time: 8105.17
Epoch [9/10], Step [240/303], Loss: 8.2186, Training-time: 8108.23
Epoch [9/10], Step [241/303], Loss: 8.2166, Training-time: 8111.26
Epoch [9/10], Step [242/303], Loss: 8.2218, Training-time: 8114.32
Epoch [9/10], Step [243/303], Loss: 8.2191, Training-time: 8117.36
Epoch [9/10], Step [244/303], Loss: 8.2180, Training-time: 8120.39
Epoch [9/10], Step [245/303], Loss: 8.2160, Training-time: 8123.45
Epoch [9/10], Step [246/303], Loss: 8.2180, Training-time: 8126.50
Epoch [9/10], Step [247/303], Loss: 8.2156, Training-time: 8129.52
Epoch [9/10], Step [248/303], Loss: 8.2134, Training-time: 8132.56
Epoch [9/10], Step [249/303], Loss: 8.2107, Training-time: 8135.62
Epoch [9/10], Step [250/303], Loss: 8.2089, Training-time: 8138.65
Epoch [9/10], Step [251/303], Loss: 8.2061, Training-time: 8141.71
Epoch [9/10], Step [252/303], Loss: 8.2350, Training-time: 8144.76
Epoch [9/10], Step [253/303], Loss: 8.2324, Training-time: 8147.80
Epoch [9/10], Step [254/303], Loss: 8.2317, Training-time: 8150.85
Epoch [9/10], Step [255/303], Loss: 8.2290, Training-time: 8153.91
Epoch [9/10], Step [256/303], Loss: 8.2265, Training-time: 8156.94
Epoch [9/10], Step [257/303], Loss: 8.2263, Training-time: 8159.99
Epoch [9/10], Step [258/303], Loss: 8.2237, Training-time: 8163.04
Epoch [9/10], Step [259/303], Loss: 8.2217, Training-time: 8166.06
Epoch [9/10], Step [260/303], Loss: 8.2189, Training-time: 8169.11
Epoch [9/10], Step [261/303], Loss: 8.2175, Training-time: 8172.16
Epoch [9/10], Step [262/303], Loss: 8.2154, Training-time: 8175.20
Epoch [9/10], Step [263/303], Loss: 8.2128, Training-time: 8178.26
Epoch [9/10], Step [264/303], Loss: 8.2102, Training-time: 8181.31
Epoch [9/10], Step [265/303], Loss: 8.2083, Training-time: 8184.35
Epoch [9/10], Step [266/303], Loss: 8.2056, Training-time: 8187.41
Epoch [9/10], Step [267/303], Loss: 8.2034, Training-time: 8190.46
Epoch [9/10], Step [268/303], Loss: 8.2013, Training-time: 8193.48
Epoch [9/10], Step [269/303], Loss: 8.1993, Training-time: 8196.54
Epoch [9/10], Step [270/303], Loss: 8.1964, Training-time: 8199.59
Epoch [9/10], Step [271/303], Loss: 8.1949, Training-time: 8202.62
Epoch [9/10], Step [272/303], Loss: 8.1924, Training-time: 8205.66
Epoch [9/10], Step [273/303], Loss: 8.1895, Training-time: 8208.70
Epoch [9/10], Step [274/303], Loss: 8.1873, Training-time: 8211.73
Epoch [9/10], Step [275/303], Loss: 8.1849, Training-time: 8214.78
Epoch [9/10], Step [276/303], Loss: 8.1855, Training-time: 8217.82
Epoch [9/10], Step [277/303], Loss: 8.1827, Training-time: 8220.86
Epoch [9/10], Step [278/303], Loss: 8.1819, Training-time: 8223.91
Epoch [9/10], Step [279/303], Loss: 8.1805, Training-time: 8226.96
Epoch [9/10], Step [280/303], Loss: 8.1795, Training-time: 8229.99
Epoch [9/10], Step [281/303], Loss: 8.1798, Training-time: 8233.04
Epoch [9/10], Step [282/303], Loss: 8.1770, Training-time: 8236.09
Epoch [9/10], Step [283/303], Loss: 8.1761, Training-time: 8239.12
Epoch [9/10], Step [284/303], Loss: 8.1738, Training-time: 8242.17
Epoch [9/10], Step [285/303], Loss: 8.1713, Training-time: 8245.21
Epoch [9/10], Step [286/303], Loss: 8.1688, Training-time: 8248.24
Epoch [9/10], Step [287/303], Loss: 8.1664, Training-time: 8251.30
Epoch [9/10], Step [288/303], Loss: 8.1644, Training-time: 8254.34
Epoch [9/10], Step [289/303], Loss: 8.1617, Training-time: 8257.38
Epoch [9/10], Step [290/303], Loss: 8.1596, Training-time: 8260.43
Epoch [9/10], Step [291/303], Loss: 8.1576, Training-time: 8263.50
Epoch [9/10], Step [292/303], Loss: 8.1569, Training-time: 8266.53
Epoch [9/10], Step [293/303], Loss: 8.1589, Training-time: 8269.58
Epoch [9/10], Step [294/303], Loss: 8.1563, Training-time: 8272.64
Epoch [9/10], Step [295/303], Loss: 8.1536, Training-time: 8275.67
Epoch [9/10], Step [296/303], Loss: 8.1510, Training-time: 8278.72
Epoch [9/10], Step [297/303], Loss: 8.1483, Training-time: 8281.76
Epoch [9/10], Step [298/303], Loss: 8.1456, Training-time: 8284.76
Epoch [9/10], Step [299/303], Loss: 8.1432, Training-time: 8287.79
Epoch [9/10], Step [300/303], Loss: 8.1407, Training-time: 8290.82
Epoch [9/10], Step [301/303], Loss: 8.1381, Training-time: 8293.84
Epoch [9/10], Step [302/303], Loss: 8.1357, Training-time: 8296.86
Epoch [9/10], Step [303/303], Loss: 8.1328, Training-time: 8297.49
Epoch [10/10], Step [1/303], Loss: 8.1304, Training-time: 8300.87
Epoch [10/10], Step [2/303], Loss: 8.1290, Training-time: 8303.91
Epoch [10/10], Step [3/303], Loss: 8.1285, Training-time: 8306.95
Epoch [10/10], Step [4/303], Loss: 8.1258, Training-time: 8309.98
Epoch [10/10], Step [5/303], Loss: 8.1231, Training-time: 8313.04
Epoch [10/10], Step [6/303], Loss: 8.1208, Training-time: 8316.09
Epoch [10/10], Step [7/303], Loss: 8.1191, Training-time: 8319.12
Epoch [10/10], Step [8/303], Loss: 8.1166, Training-time: 8322.16
Epoch [10/10], Step [9/303], Loss: 8.1182, Training-time: 8325.21
Epoch [10/10], Step [10/303], Loss: 8.1155, Training-time: 8328.24
Epoch [10/10], Step [11/303], Loss: 8.1128, Training-time: 8331.27
Epoch [10/10], Step [12/303], Loss: 8.1105, Training-time: 8334.31
Epoch [10/10], Step [13/303], Loss: 8.1080, Training-time: 8337.34
Epoch [10/10], Step [14/303], Loss: 8.1053, Training-time: 8340.38
Epoch [10/10], Step [15/303], Loss: 8.1070, Training-time: 8343.42
Epoch [10/10], Step [16/303], Loss: 8.1055, Training-time: 8346.45
Epoch [10/10], Step [17/303], Loss: 8.1031, Training-time: 8349.49
Epoch [10/10], Step [18/303], Loss: 8.1006, Training-time: 8352.54
Epoch [10/10], Step [19/303], Loss: 8.0982, Training-time: 8355.57
Epoch [10/10], Step [20/303], Loss: 8.0966, Training-time: 8358.61
Epoch [10/10], Step [21/303], Loss: 8.0943, Training-time: 8361.66
Epoch [10/10], Step [22/303], Loss: 8.1264, Training-time: 8364.69
Epoch [10/10], Step [23/303], Loss: 8.1241, Training-time: 8367.75
Epoch [10/10], Step [24/303], Loss: 8.1222, Training-time: 8370.79
Epoch [10/10], Step [25/303], Loss: 8.1196, Training-time: 8373.82
Epoch [10/10], Step [26/303], Loss: 8.1180, Training-time: 8376.86
Epoch [10/10], Step [27/303], Loss: 8.1181, Training-time: 8379.92
Epoch [10/10], Step [28/303], Loss: 8.1157, Training-time: 8382.95
Epoch [10/10], Step [29/303], Loss: 8.1454, Training-time: 8386.00
Epoch [10/10], Step [30/303], Loss: 8.1440, Training-time: 8389.05
Epoch [10/10], Step [31/303], Loss: 8.1419, Training-time: 8392.08
Epoch [10/10], Step [32/303], Loss: 8.1396, Training-time: 8395.13
Epoch [10/10], Step [33/303], Loss: 8.1378, Training-time: 8398.17
Epoch [10/10], Step [34/303], Loss: 8.1358, Training-time: 8401.20
Epoch [10/10], Step [35/303], Loss: 8.1336, Training-time: 8404.25
Epoch [10/10], Step [36/303], Loss: 8.1311, Training-time: 8407.29
Epoch [10/10], Step [37/303], Loss: 8.1288, Training-time: 8410.32
Epoch [10/10], Step [38/303], Loss: 8.1264, Training-time: 8413.36
Epoch [10/10], Step [39/303], Loss: 8.1297, Training-time: 8416.40
Epoch [10/10], Step [40/303], Loss: 8.1270, Training-time: 8419.42
Epoch [10/10], Step [41/303], Loss: 8.1253, Training-time: 8422.46
Epoch [10/10], Step [42/303], Loss: 8.1229, Training-time: 8425.52
Epoch [10/10], Step [43/303], Loss: 8.1240, Training-time: 8428.54
Epoch [10/10], Step [44/303], Loss: 8.1215, Training-time: 8431.58
Epoch [10/10], Step [45/303], Loss: 8.1193, Training-time: 8434.63
Epoch [10/10], Step [46/303], Loss: 8.1173, Training-time: 8437.65
Epoch [10/10], Step [47/303], Loss: 8.1149, Training-time: 8440.70
Epoch [10/10], Step [48/303], Loss: 8.1128, Training-time: 8443.74
Epoch [10/10], Step [49/303], Loss: 8.1142, Training-time: 8446.78
Epoch [10/10], Step [50/303], Loss: 8.1124, Training-time: 8449.82
Epoch [10/10], Step [51/303], Loss: 8.1105, Training-time: 8452.86
Epoch [10/10], Step [52/303], Loss: 8.1090, Training-time: 8455.89
Epoch [10/10], Step [53/303], Loss: 8.1073, Training-time: 8458.93
Epoch [10/10], Step [54/303], Loss: 8.1052, Training-time: 8461.98
Epoch [10/10], Step [55/303], Loss: 8.1033, Training-time: 8465.00
Epoch [10/10], Step [56/303], Loss: 8.1010, Training-time: 8468.05
Epoch [10/10], Step [57/303], Loss: 8.0984, Training-time: 8471.10
Epoch [10/10], Step [58/303], Loss: 8.0962, Training-time: 8474.13
Epoch [10/10], Step [59/303], Loss: 8.0956, Training-time: 8477.18
Epoch [10/10], Step [60/303], Loss: 8.0997, Training-time: 8480.22
Epoch [10/10], Step [61/303], Loss: 8.0978, Training-time: 8483.26
Epoch [10/10], Step [62/303], Loss: 8.0980, Training-time: 8486.31
Epoch [10/10], Step [63/303], Loss: 8.0956, Training-time: 8489.36
Epoch [10/10], Step [64/303], Loss: 8.0931, Training-time: 8492.38
Epoch [10/10], Step [65/303], Loss: 8.0909, Training-time: 8495.43
Epoch [10/10], Step [66/303], Loss: 8.0888, Training-time: 8498.47
Epoch [10/10], Step [67/303], Loss: 8.0874, Training-time: 8501.50
Epoch [10/10], Step [68/303], Loss: 8.0852, Training-time: 8504.55
Epoch [10/10], Step [69/303], Loss: 8.0826, Training-time: 8507.60
Epoch [10/10], Step [70/303], Loss: 8.0802, Training-time: 8510.63
Epoch [10/10], Step [71/303], Loss: 8.0775, Training-time: 8513.67
Epoch [10/10], Step [72/303], Loss: 8.0752, Training-time: 8516.73
Epoch [10/10], Step [73/303], Loss: 8.0742, Training-time: 8519.76
Epoch [10/10], Step [74/303], Loss: 8.0728, Training-time: 8522.81
Epoch [10/10], Step [75/303], Loss: 8.0703, Training-time: 8525.85
Epoch [10/10], Step [76/303], Loss: 8.0679, Training-time: 8528.88
Epoch [10/10], Step [77/303], Loss: 8.0652, Training-time: 8531.93
Epoch [10/10], Step [78/303], Loss: 8.0631, Training-time: 8534.97
Epoch [10/10], Step [79/303], Loss: 8.0817, Training-time: 8537.99
Epoch [10/10], Step [80/303], Loss: 8.0800, Training-time: 8541.04
Epoch [10/10], Step [81/303], Loss: 8.0782, Training-time: 8544.09
Epoch [10/10], Step [82/303], Loss: 8.0755, Training-time: 8547.11
Epoch [10/10], Step [83/303], Loss: 8.0751, Training-time: 8550.16
Epoch [10/10], Step [84/303], Loss: 8.0733, Training-time: 8553.21
Epoch [10/10], Step [85/303], Loss: 8.0709, Training-time: 8556.24
Epoch [10/10], Step [86/303], Loss: 8.0895, Training-time: 8559.29
Epoch [10/10], Step [87/303], Loss: 8.0870, Training-time: 8562.34
Epoch [10/10], Step [88/303], Loss: 8.0845, Training-time: 8565.38
Epoch [10/10], Step [89/303], Loss: 8.0823, Training-time: 8568.43
Epoch [10/10], Step [90/303], Loss: 8.0858, Training-time: 8571.47
Epoch [10/10], Step [91/303], Loss: 8.0836, Training-time: 8574.48
Epoch [10/10], Step [92/303], Loss: 8.0811, Training-time: 8577.53
Epoch [10/10], Step [93/303], Loss: 8.0796, Training-time: 8580.58
Epoch [10/10], Step [94/303], Loss: 8.0775, Training-time: 8583.61
Epoch [10/10], Step [95/303], Loss: 8.0765, Training-time: 8586.66
Epoch [10/10], Step [96/303], Loss: 8.0745, Training-time: 8589.70
Epoch [10/10], Step [97/303], Loss: 8.0729, Training-time: 8592.74
Epoch [10/10], Step [98/303], Loss: 8.0715, Training-time: 8595.78
Epoch [10/10], Step [99/303], Loss: 8.0696, Training-time: 8598.82
Epoch [10/10], Step [100/303], Loss: 8.0683, Training-time: 8601.84
Epoch [10/10], Step [101/303], Loss: 8.0657, Training-time: 8604.89
Epoch [10/10], Step [102/303], Loss: 8.0641, Training-time: 8607.92
Epoch [10/10], Step [103/303], Loss: 8.0619, Training-time: 8610.93
Epoch [10/10], Step [104/303], Loss: 8.0596, Training-time: 8613.98
Epoch [10/10], Step [105/303], Loss: 8.0573, Training-time: 8617.03
Epoch [10/10], Step [106/303], Loss: 8.0546, Training-time: 8620.06
Epoch [10/10], Step [107/303], Loss: 8.0527, Training-time: 8623.11
Epoch [10/10], Step [108/303], Loss: 8.0501, Training-time: 8626.15
Epoch [10/10], Step [109/303], Loss: 8.0479, Training-time: 8629.18
Epoch [10/10], Step [110/303], Loss: 8.0473, Training-time: 8632.23
Epoch [10/10], Step [111/303], Loss: 8.0451, Training-time: 8635.27
Epoch [10/10], Step [112/303], Loss: 8.0427, Training-time: 8638.31
Epoch [10/10], Step [113/303], Loss: 8.0420, Training-time: 8641.35
Epoch [10/10], Step [114/303], Loss: 8.0401, Training-time: 8644.40
Epoch [10/10], Step [115/303], Loss: 8.0381, Training-time: 8647.44
Epoch [10/10], Step [116/303], Loss: 8.0356, Training-time: 8650.49
Epoch [10/10], Step [117/303], Loss: 8.0335, Training-time: 8653.54
Epoch [10/10], Step [118/303], Loss: 8.0313, Training-time: 8656.57
Epoch [10/10], Step [119/303], Loss: 8.0415, Training-time: 8659.62
Epoch [10/10], Step [120/303], Loss: 8.0417, Training-time: 8662.67
Epoch [10/10], Step [121/303], Loss: 8.0398, Training-time: 8665.71
Epoch [10/10], Step [122/303], Loss: 8.0385, Training-time: 8668.76
Epoch [10/10], Step [123/303], Loss: 8.0366, Training-time: 8671.81
Epoch [10/10], Step [124/303], Loss: 8.0342, Training-time: 8674.83
Epoch [10/10], Step [125/303], Loss: 8.0331, Training-time: 8677.88
Epoch [10/10], Step [126/303], Loss: 8.0307, Training-time: 8680.93
Epoch [10/10], Step [127/303], Loss: 8.0283, Training-time: 8683.96
Epoch [10/10], Step [128/303], Loss: 8.0261, Training-time: 8687.00
Epoch [10/10], Step [129/303], Loss: 8.0237, Training-time: 8690.06
Epoch [10/10], Step [130/303], Loss: 8.0214, Training-time: 8693.09
Epoch [10/10], Step [131/303], Loss: 8.0195, Training-time: 8696.13
Epoch [10/10], Step [132/303], Loss: 8.0172, Training-time: 8699.18
Epoch [10/10], Step [133/303], Loss: 8.0148, Training-time: 8702.21
Epoch [10/10], Step [134/303], Loss: 8.0253, Training-time: 8705.25
Epoch [10/10], Step [135/303], Loss: 8.0232, Training-time: 8708.28
Epoch [10/10], Step [136/303], Loss: 8.0208, Training-time: 8711.31
Epoch [10/10], Step [137/303], Loss: 8.0194, Training-time: 8714.34
Epoch [10/10], Step [138/303], Loss: 8.0170, Training-time: 8717.38
Epoch [10/10], Step [139/303], Loss: 8.0146, Training-time: 8720.42
Epoch [10/10], Step [140/303], Loss: 8.0123, Training-time: 8723.46
Epoch [10/10], Step [141/303], Loss: 8.0100, Training-time: 8726.50
Epoch [10/10], Step [142/303], Loss: 8.0122, Training-time: 8729.53
Epoch [10/10], Step [143/303], Loss: 8.0108, Training-time: 8732.58
Epoch [10/10], Step [144/303], Loss: 8.0088, Training-time: 8735.63
Epoch [10/10], Step [145/303], Loss: 8.0063, Training-time: 8738.65
Epoch [10/10], Step [146/303], Loss: 8.0040, Training-time: 8741.70
Epoch [10/10], Step [147/303], Loss: 8.0041, Training-time: 8744.77
Epoch [10/10], Step [148/303], Loss: 8.0031, Training-time: 8747.81
Epoch [10/10], Step [149/303], Loss: 8.0011, Training-time: 8750.86
Epoch [10/10], Step [150/303], Loss: 7.9987, Training-time: 8753.90
Epoch [10/10], Step [151/303], Loss: 7.9967, Training-time: 8756.94
Epoch [10/10], Step [152/303], Loss: 7.9947, Training-time: 8760.00
Epoch [10/10], Step [153/303], Loss: 7.9945, Training-time: 8763.05
Epoch [10/10], Step [154/303], Loss: 7.9923, Training-time: 8766.08
Epoch [10/10], Step [155/303], Loss: 7.9898, Training-time: 8769.13
Epoch [10/10], Step [156/303], Loss: 7.9882, Training-time: 8772.19
Epoch [10/10], Step [157/303], Loss: 7.9859, Training-time: 8775.21
Epoch [10/10], Step [158/303], Loss: 7.9834, Training-time: 8778.25
Epoch [10/10], Step [159/303], Loss: 7.9830, Training-time: 8781.30
Epoch [10/10], Step [160/303], Loss: 7.9807, Training-time: 8784.32
Epoch [10/10], Step [161/303], Loss: 7.9784, Training-time: 8787.38
Epoch [10/10], Step [162/303], Loss: 7.9765, Training-time: 8790.43
Epoch [10/10], Step [163/303], Loss: 7.9740, Training-time: 8793.45
Epoch [10/10], Step [164/303], Loss: 7.9720, Training-time: 8796.49
Epoch [10/10], Step [165/303], Loss: 7.9695, Training-time: 8799.53
Epoch [10/10], Step [166/303], Loss: 7.9680, Training-time: 8802.56
Epoch [10/10], Step [167/303], Loss: 7.9655, Training-time: 8805.61
Epoch [10/10], Step [168/303], Loss: 7.9670, Training-time: 8808.65
Epoch [10/10], Step [169/303], Loss: 7.9644, Training-time: 8811.69
Epoch [10/10], Step [170/303], Loss: 7.9622, Training-time: 8814.74
Epoch [10/10], Step [171/303], Loss: 7.9598, Training-time: 8817.79
Epoch [10/10], Step [172/303], Loss: 7.9577, Training-time: 8820.82
Epoch [10/10], Step [173/303], Loss: 7.9557, Training-time: 8823.87
Epoch [10/10], Step [174/303], Loss: 7.9534, Training-time: 8826.92
Epoch [10/10], Step [175/303], Loss: 7.9509, Training-time: 8829.95
Epoch [10/10], Step [176/303], Loss: 7.9486, Training-time: 8833.00
Epoch [10/10], Step [177/303], Loss: 7.9468, Training-time: 8836.05
Epoch [10/10], Step [178/303], Loss: 7.9533, Training-time: 8839.08
Epoch [10/10], Step [179/303], Loss: 7.9510, Training-time: 8842.12
Epoch [10/10], Step [180/303], Loss: 7.9491, Training-time: 8845.17
Epoch [10/10], Step [181/303], Loss: 7.9474, Training-time: 8848.18
Epoch [10/10], Step [182/303], Loss: 7.9449, Training-time: 8851.22
Epoch [10/10], Step [183/303], Loss: 7.9426, Training-time: 8854.26
Epoch [10/10], Step [184/303], Loss: 7.9406, Training-time: 8857.29
Epoch [10/10], Step [185/303], Loss: 7.9382, Training-time: 8860.33
Epoch [10/10], Step [186/303], Loss: 7.9357, Training-time: 8863.38
Epoch [10/10], Step [187/303], Loss: 7.9334, Training-time: 8866.41
Epoch [10/10], Step [188/303], Loss: 7.9311, Training-time: 8869.45
Epoch [10/10], Step [189/303], Loss: 7.9317, Training-time: 8872.50
Epoch [10/10], Step [190/303], Loss: 7.9293, Training-time: 8875.55
Epoch [10/10], Step [191/303], Loss: 7.9294, Training-time: 8878.61
Epoch [10/10], Step [192/303], Loss: 7.9282, Training-time: 8881.65
Epoch [10/10], Step [193/303], Loss: 7.9258, Training-time: 8884.69
Epoch [10/10], Step [194/303], Loss: 7.9235, Training-time: 8887.74
Epoch [10/10], Step [195/303], Loss: 7.9213, Training-time: 8890.79
Epoch [10/10], Step [196/303], Loss: 7.9191, Training-time: 8893.82
Epoch [10/10], Step [197/303], Loss: 7.9167, Training-time: 8896.88
Epoch [10/10], Step [198/303], Loss: 7.9142, Training-time: 8899.92
Epoch [10/10], Step [199/303], Loss: 7.9158, Training-time: 8902.95
Epoch [10/10], Step [200/303], Loss: 7.9133, Training-time: 8906.00
Epoch [10/10], Step [201/303], Loss: 7.9115, Training-time: 8909.05
Epoch [10/10], Step [202/303], Loss: 7.9094, Training-time: 8912.09
Epoch [10/10], Step [203/303], Loss: 7.9072, Training-time: 8915.14
Epoch [10/10], Step [204/303], Loss: 7.9062, Training-time: 8918.18
Epoch [10/10], Step [205/303], Loss: 7.9039, Training-time: 8921.21
Epoch [10/10], Step [206/303], Loss: 7.9017, Training-time: 8924.25
Epoch [10/10], Step [207/303], Loss: 7.8994, Training-time: 8927.30
Epoch [10/10], Step [208/303], Loss: 7.8969, Training-time: 8930.33
Epoch [10/10], Step [209/303], Loss: 7.8946, Training-time: 8933.38
Epoch [10/10], Step [210/303], Loss: 7.8931, Training-time: 8936.43
Epoch [10/10], Step [211/303], Loss: 7.8913, Training-time: 8939.46
Epoch [10/10], Step [212/303], Loss: 7.8891, Training-time: 8942.50
Epoch [10/10], Step [213/303], Loss: 7.8867, Training-time: 8945.55
Epoch [10/10], Step [214/303], Loss: 7.8847, Training-time: 8948.57
Epoch [10/10], Step [215/303], Loss: 7.8833, Training-time: 8951.62
Epoch [10/10], Step [216/303], Loss: 7.8809, Training-time: 8954.66
Epoch [10/10], Step [217/303], Loss: 7.8825, Training-time: 8957.69
Epoch [10/10], Step [218/303], Loss: 7.9287, Training-time: 8960.73
Epoch [10/10], Step [219/303], Loss: 7.9293, Training-time: 8963.79
Epoch [10/10], Step [220/303], Loss: 7.9276, Training-time: 8966.82
Epoch [10/10], Step [221/303], Loss: 7.9254, Training-time: 8969.88
Epoch [10/10], Step [222/303], Loss: 7.9233, Training-time: 8972.93
Epoch [10/10], Step [223/303], Loss: 7.9259, Training-time: 8975.97
Epoch [10/10], Step [224/303], Loss: 7.9236, Training-time: 8979.00
Epoch [10/10], Step [225/303], Loss: 7.9239, Training-time: 8982.05
Epoch [10/10], Step [226/303], Loss: 7.9255, Training-time: 8985.07
Epoch [10/10], Step [227/303], Loss: 7.9237, Training-time: 8988.13
Epoch [10/10], Step [228/303], Loss: 7.9214, Training-time: 8991.16
Epoch [10/10], Step [229/303], Loss: 7.9194, Training-time: 8994.18
Epoch [10/10], Step [230/303], Loss: 7.9172, Training-time: 8997.23
Epoch [10/10], Step [231/303], Loss: 7.9151, Training-time: 9000.28
Epoch [10/10], Step [232/303], Loss: 7.9130, Training-time: 9003.32
Epoch [10/10], Step [233/303], Loss: 7.9107, Training-time: 9006.36
Epoch [10/10], Step [234/303], Loss: 7.9084, Training-time: 9009.41
Epoch [10/10], Step [235/303], Loss: 7.9066, Training-time: 9012.44
Epoch [10/10], Step [236/303], Loss: 7.9042, Training-time: 9015.49
Epoch [10/10], Step [237/303], Loss: 7.9018, Training-time: 9018.52
Epoch [10/10], Step [238/303], Loss: 7.8996, Training-time: 9021.55
Epoch [10/10], Step [239/303], Loss: 7.8974, Training-time: 9024.61
Epoch [10/10], Step [240/303], Loss: 7.8967, Training-time: 9027.66
Epoch [10/10], Step [241/303], Loss: 7.8951, Training-time: 9030.69
Epoch [10/10], Step [242/303], Loss: 7.8962, Training-time: 9033.74
Epoch [10/10], Step [243/303], Loss: 7.9066, Training-time: 9036.79
Epoch [10/10], Step [244/303], Loss: 7.9042, Training-time: 9039.80
Epoch [10/10], Step [245/303], Loss: 7.9018, Training-time: 9042.85
Epoch [10/10], Step [246/303], Loss: 7.9001, Training-time: 9045.89
Epoch [10/10], Step [247/303], Loss: 7.8992, Training-time: 9048.92
Epoch [10/10], Step [248/303], Loss: 7.8968, Training-time: 9051.97
Epoch [10/10], Step [249/303], Loss: 7.8945, Training-time: 9055.02
Epoch [10/10], Step [250/303], Loss: 7.8925, Training-time: 9058.04
Epoch [10/10], Step [251/303], Loss: 7.8901, Training-time: 9061.08
Epoch [10/10], Step [252/303], Loss: 7.8881, Training-time: 9064.12
Epoch [10/10], Step [253/303], Loss: 7.8863, Training-time: 9067.14
Epoch [10/10], Step [254/303], Loss: 8.1720, Training-time: 9070.19
Epoch [10/10], Step [255/303], Loss: 8.1716, Training-time: 9073.24
Epoch [10/10], Step [256/303], Loss: 8.1696, Training-time: 9076.27
Epoch [10/10], Step [257/303], Loss: 8.1678, Training-time: 9079.33
Epoch [10/10], Step [258/303], Loss: 8.1669, Training-time: 9082.37
Epoch [10/10], Step [259/303], Loss: 8.1697, Training-time: 9085.41
Epoch [10/10], Step [260/303], Loss: 8.1684, Training-time: 9088.46
Epoch [10/10], Step [261/303], Loss: 8.1705, Training-time: 9091.51
Epoch [10/10], Step [262/303], Loss: 8.1684, Training-time: 9094.54
Epoch [10/10], Step [263/303], Loss: 8.1666, Training-time: 9097.58
Epoch [10/10], Step [264/303], Loss: 8.1650, Training-time: 9100.63
Epoch [10/10], Step [265/303], Loss: 8.1630, Training-time: 9103.67
Epoch [10/10], Step [266/303], Loss: 8.1637, Training-time: 9106.71
Epoch [10/10], Step [267/303], Loss: 8.1617, Training-time: 9109.76
Epoch [10/10], Step [268/303], Loss: 8.1599, Training-time: 9112.78
Epoch [10/10], Step [269/303], Loss: 8.1577, Training-time: 9115.81
Epoch [10/10], Step [270/303], Loss: 8.1557, Training-time: 9118.86
Epoch [10/10], Step [271/303], Loss: 8.1538, Training-time: 9121.89
Epoch [10/10], Step [272/303], Loss: 8.1513, Training-time: 9124.95
Epoch [10/10], Step [273/303], Loss: 8.1489, Training-time: 9127.99
Epoch [10/10], Step [274/303], Loss: 8.1463, Training-time: 9131.02
Epoch [10/10], Step [275/303], Loss: 8.1530, Training-time: 9134.06
Epoch [10/10], Step [276/303], Loss: 8.1506, Training-time: 9137.10
Epoch [10/10], Step [277/303], Loss: 8.1485, Training-time: 9140.12
Epoch [10/10], Step [278/303], Loss: 8.1470, Training-time: 9143.16
Epoch [10/10], Step [279/303], Loss: 8.1485, Training-time: 9146.21
Epoch [10/10], Step [280/303], Loss: 8.1466, Training-time: 9149.23
Epoch [10/10], Step [281/303], Loss: 8.1452, Training-time: 9152.27
Epoch [10/10], Step [282/303], Loss: 8.1428, Training-time: 9155.32
Epoch [10/10], Step [283/303], Loss: 8.1405, Training-time: 9158.35
Epoch [10/10], Step [284/303], Loss: 8.1384, Training-time: 9161.40
Epoch [10/10], Step [285/303], Loss: 8.1361, Training-time: 9164.45
Epoch [10/10], Step [286/303], Loss: 8.1337, Training-time: 9167.48
Epoch [10/10], Step [287/303], Loss: 8.1312, Training-time: 9170.54
Epoch [10/10], Step [288/303], Loss: 8.1293, Training-time: 9173.58
Epoch [10/10], Step [289/303], Loss: 8.1268, Training-time: 9176.61
Epoch [10/10], Step [290/303], Loss: 8.1249, Training-time: 9179.67
Epoch [10/10], Step [291/303], Loss: 8.1226, Training-time: 9182.72
Epoch [10/10], Step [292/303], Loss: 8.1207, Training-time: 9185.74
Epoch [10/10], Step [293/303], Loss: 8.1204, Training-time: 9188.79
Epoch [10/10], Step [294/303], Loss: 8.1183, Training-time: 9191.84
Epoch [10/10], Step [295/303], Loss: 8.1164, Training-time: 9194.86
Epoch [10/10], Step [296/303], Loss: 8.1147, Training-time: 9197.90
Epoch [10/10], Step [297/303], Loss: 8.1138, Training-time: 9200.94
Epoch [10/10], Step [298/303], Loss: 8.1116, Training-time: 9203.94
Epoch [10/10], Step [299/303], Loss: 8.1095, Training-time: 9206.96
Epoch [10/10], Step [300/303], Loss: 8.1074, Training-time: 9209.98
Epoch [10/10], Step [301/303], Loss: 8.1050, Training-time: 9212.99
Epoch [10/10], Step [302/303], Loss: 8.1115, Training-time: 9216.00
Epoch [10/10], Step [303/303], Loss: 8.1090, Training-time: 9216.62
Evaluating Model ...
Step Loss: 2.1528241634368896
Step Loss: 19.346370697021484
Step Loss: 1.7697250843048096
Step Loss: 1.0425798892974854
Step Loss: 11.93083667755127
Step Loss: 1.5218995809555054
Step Loss: 1.3257108926773071
Step Loss: 1.5572148561477661
Step Loss: 9.679187774658203
Step Loss: 1.8114995956420898
Step Loss: 1.1162973642349243
Step Loss: 2.3321783542633057
Step Loss: 0.663948655128479
Step Loss: 6.113627910614014
Step Loss: 1.1303867101669312
Step Loss: 147.78756713867188
Step Loss: 1.790205717086792
Step Loss: 2.884108304977417
Step Loss: 7.110249042510986
Step Loss: 1.088211178779602
Step Loss: 0.8258019089698792
Step Loss: 1.1327399015426636
Step Loss: 31.668888092041016
Step Loss: 13.129786491394043
Step Loss: 1.2468560934066772
Step Loss: 1.632592797279358
Step Loss: 3.1683030128479004
Step Loss: 1.3282064199447632
Step Loss: 1.827469825744629
Step Loss: 10.846097946166992
Step Loss: 0.9099940657615662
Step Loss: 3.3106439113616943
Step Loss: 1.1665114164352417
Step Loss: 8.084633827209473
Step Loss: 19.20889663696289
Step Loss: 3.5502195358276367
Step Loss: 3.667585849761963
Step Loss: 24.097578048706055
Step Loss: 1.6689372062683105
Step Loss: 6.187789440155029
Step Loss: 3.551708936691284
Step Loss: 1.7934291362762451
Step Loss: 1.781532645225525
Step Loss: 1.7557395696640015
Step Loss: 15.39774227142334
Step Loss: 2.1921238899230957
Step Loss: 7.176568031311035
Step Loss: 0.7511482238769531
Step Loss: 3.157618999481201
Step Loss: 1.6735553741455078
Step Loss: 2.1719725131988525
Step Loss: 1.3090713024139404
Step Loss: 1.7298204898834229
Step Loss: 2.573180675506592
Step Loss: 2.2506675720214844
Step Loss: 11.71263313293457
Step Loss: 1.8434687852859497
Step Loss: 1.4522842168807983
Step Loss: 7.863732814788818
Step Loss: 1.012374997138977
Step Loss: 1.9984853267669678
Step Loss: 2.1645612716674805
Step Loss: 77.40140533447266
Step Loss: 1.3591352701187134
Step Loss: 1.335523009300232
Step Loss: 2.470109701156616
Step Loss: 1.9976880550384521
Step Loss: 1.5734719038009644
Step Loss: 0.8449053168296814
Step Loss: 21.202199935913086
Step Loss: 2.2648115158081055
Step Loss: 1.45783269405365
Step Loss: 1.5086276531219482
Step Loss: 13.011063575744629
Step Loss: 1.2494789361953735
Step Loss: 1.6613502502441406
Total Loss on 3778 images: 569.4651853442192
Saving Model ...
Task Complete ...
len X 3030
